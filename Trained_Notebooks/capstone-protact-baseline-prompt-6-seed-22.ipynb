{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-10-30T03:07:03.865334Z","iopub.execute_input":"2024-10-30T03:07:03.865728Z","iopub.status.idle":"2024-10-30T03:07:16.492086Z","shell.execute_reply.started":"2024-10-30T03:07:03.865687Z","shell.execute_reply":"2024-10-30T03:07:16.490938Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/ishreya09/ProTACT.git","metadata":{"execution":{"iopub.status.busy":"2024-10-30T03:07:16.494490Z","iopub.execute_input":"2024-10-30T03:07:16.494899Z","iopub.status.idle":"2024-10-30T03:07:25.612763Z","shell.execute_reply.started":"2024-10-30T03:07:16.494835Z","shell.execute_reply":"2024-10-30T03:07:25.611796Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'ProTACT'...\nremote: Enumerating objects: 318, done.\u001b[K\nremote: Counting objects: 100% (7/7), done.\u001b[K\nremote: Compressing objects: 100% (7/7), done.\u001b[K\nremote: Total 318 (delta 0), reused 6 (delta 0), pack-reused 311 (from 1)\u001b[K\nReceiving objects: 100% (318/318), 146.60 MiB | 40.63 MiB/s, done.\nResolving deltas: 100% (173/173), done.\nUpdating files: 100% (136/136), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!cp -r /kaggle/working/ProTACT/* /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-10-30T03:07:25.614074Z","iopub.execute_input":"2024-10-30T03:07:25.614374Z","iopub.status.idle":"2024-10-30T03:07:27.103026Z","shell.execute_reply.started":"2024-10-30T03:07:25.614342Z","shell.execute_reply":"2024-10-30T03:07:27.101979Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!mkdir trained_model","metadata":{"execution":{"iopub.status.busy":"2024-10-30T03:07:27.105147Z","iopub.execute_input":"2024-10-30T03:07:27.105450Z","iopub.status.idle":"2024-10-30T03:07:28.108886Z","shell.execute_reply.started":"2024-10-30T03:07:27.105418Z","shell.execute_reply":"2024-10-30T03:07:28.107950Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'trained_model': File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"import gdown\nimport os\n\n# Create directory if it doesn't exist\nos.makedirs('embeddings', exist_ok=True)\n\n# https://drive.google.com/file/d/1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ/view?usp=sharing\n\n# Google Drive file ID\nfile_id = \"1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ\"\n\n# Download file to the specified directory\ngdown.download(f\"https://drive.google.com/uc?id={file_id}\", 'embeddings/glove.6B.50d.txt', quiet=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T03:07:28.110240Z","iopub.execute_input":"2024-10-30T03:07:28.110553Z","iopub.status.idle":"2024-10-30T03:07:35.386825Z","shell.execute_reply.started":"2024-10-30T03:07:28.110520Z","shell.execute_reply":"2024-10-30T03:07:35.385891Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ\nFrom (redirected): https://drive.google.com/uc?id=1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ&confirm=t&uuid=2e291ccf-2ed8-4a47-b4fc-12af1b36f30f\nTo: /kaggle/working/embeddings/glove.6B.50d.txt\n100%|██████████| 171M/171M [00:02<00:00, 61.3MB/s] \n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'embeddings/glove.6B.50d.txt'"},"metadata":{}}]},{"cell_type":"code","source":"!bash /kaggle/working/train_prompt6_seed22.sh ","metadata":{"execution":{"iopub.status.busy":"2024-10-30T03:07:35.388970Z","iopub.execute_input":"2024-10-30T03:07:35.389914Z","iopub.status.idle":"2024-10-30T06:30:33.288203Z","shell.execute_reply.started":"2024-10-30T03:07:35.389842Z","shell.execute_reply":"2024-10-30T06:30:33.287254Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Test prompt id is 6 of type <class 'int'>\nSeed: 22\nNumhead :  2  | Features :  data/LDA/hand_crafted_final_6.csv  | Pos_emb :  50\n prompt_pos size: 8\n prompt_words size: 8\n pos_x size: 9498\n readability_x size: 9498\n pos_x size: 1678\n readability_x size: 1678\n pos_x size: 1800\n readability_x size: 1800\nLoading GloVe ...\nOOV number =204, OOV ratio = 0.051013\nmax sent length: 50\nmax sent num: 97\nmax prompt sent length: 18\nmax prompt sent num: 8\n================================\nX_train_pos:  (9498, 4850)\nX_train_prompt_words:  (9498, 4850)\nX_train_prompt_pos:  (9498, 4850)\nX_train_readability:  (9498, 35)\nX_train_ling:  (9498, 52)\nX_train_attribute_rel:  (9498, 9)\nY_train:  (9498, 9)\n================================\nX_dev_pos:  (1678, 4850)\nX_dev_prompt_words:  (1678, 4850)\nX_dev_prompt_pos:  (1678, 4850)\nX_dev_readability:  (1678, 35)\nX_dev_ling:  (1678, 52)\nX_dev_attribute_rel:  (1678, 9)\nY_dev:  (1678, 9)\n================================\nX_test_pos:  (1800, 4850)\nX_test_prompt_words:  (1800, 4850)\nX_test_prompt_pos:  (1800, 4850)\nX_test_readability:  (1800, 35)\nX_test_ling:  (1800, 52)\nX_test_attribute_rel:  (1800, 9)\nY_test:  (1800, 9)\n================================\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n\u001b[1mModel: \"functional_1\"\u001b[0m\n┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ prompt_word_input   │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_input    │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_input           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt (\u001b[94mEmbedding\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │    \u001b[32m200,000\u001b[0m │ prompt_word_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_1         │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ prompt_word_inpu… │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_prompt          │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │      \u001b[32m1,950\u001b[0m │ prompt_pos_input… │\n│ (\u001b[94mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_2         │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ prompt_pos_input… │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x (\u001b[94mEmbedding\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │      \u001b[32m1,950\u001b[0m │ pos_input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ pos_input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_maskedout    │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ prompt[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_maskedo… │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_prompt[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x_maskedout     │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_x[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (\u001b[94mAdd\u001b[0m)           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ prompt_maskedout… │\n│                     │                   │            │ prompt_pos_maske… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_drop_x          │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_x_maskedout[\u001b[32m…\u001b[0m │\n│ (\u001b[94mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_drop_x       │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ add[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]         │\n│ (\u001b[94mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_resh_W          │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m50\u001b[0m,    │          \u001b[32m0\u001b[0m │ pos_drop_x[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]  │\n│ (\u001b[94mReshape\u001b[0m)           │ \u001b[32m50\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_resh_W       │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m50\u001b[0m,    │          \u001b[32m0\u001b[0m │ prompt_drop_x[\u001b[32m0\u001b[0m]… │\n│ (\u001b[94mReshape\u001b[0m)           │ \u001b[32m50\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_zcnn            │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m46\u001b[0m,    │     \u001b[32m25,100\u001b[0m │ pos_resh_W[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]  │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │ \u001b[32m100\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_zcnn         │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m46\u001b[0m,    │     \u001b[32m25,100\u001b[0m │ prompt_resh_W[\u001b[32m0\u001b[0m]… │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │ \u001b[32m100\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_avg_zcnn        │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m100\u001b[0m)   │          \u001b[32m0\u001b[0m │ pos_zcnn[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_avg_zcnn     │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m100\u001b[0m)   │          \u001b[32m0\u001b[0m │ prompt_zcnn[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ prompt_avg_zcnn[\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (\u001b[94mLSTM\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_9 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_4 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_5 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_6 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_7 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_8 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_1         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]        │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_11        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_2         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_3         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_4         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_5         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_6         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_7         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_8         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_9         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_10 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_11 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_12 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_13 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_14 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_15 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_16 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_17 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_18 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_12        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_10[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ linguistic_input    │ (\u001b[96mNone\u001b[0m, \u001b[32m52\u001b[0m)        │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ readability_input   │ (\u001b[96mNone\u001b[0m, \u001b[32m35\u001b[0m)        │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_13        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_11[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_14        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_12[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_15        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_13[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_16        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_14[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_17        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_15[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_18        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_16[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_19        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_17[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_20        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_18[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_12[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_13[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_14[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_15[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_4       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_16[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_5       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_17[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_6       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_18[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_7       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_19[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_8       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_20[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (\u001b[94mLambda\u001b[0m)     │ (\u001b[96mNone\u001b[0m, \u001b[32m9\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ concatenate[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│                     │                   │            │ concatenate_1[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_2[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_3[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_4[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_5[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_6[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_7[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_8[\u001b[32m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (\u001b[94mGetItem\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_1 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_1          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_2 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_2          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_3 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_3          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_4 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_4          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_5 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_5          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_6 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_6          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_7 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_7          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_8 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_8          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_9 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_21        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_22        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_23        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_24        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_25        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_26        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_27        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_28        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_29        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_9       │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_21[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_10      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_22[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_11      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_23[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_12      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_24[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_13      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_25[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_14      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_26[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_15      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_27[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_16      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_28[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_17      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_29[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (\u001b[94mFlatten\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_9[\u001b[32m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_10[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_2 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_11[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_3 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_12[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_4 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_13[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_5 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_14[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_6 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_15[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_7 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_16[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_8 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_17[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_76 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_77 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_78 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_79 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_80 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_81 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_82 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_83 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_84 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_18      │ (\u001b[96mNone\u001b[0m, \u001b[32m9\u001b[0m)         │          \u001b[32m0\u001b[0m │ dense_76[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ dense_77[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_78[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_79[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_80[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_81[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_82[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_83[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_84[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n\u001b[1m Total params: \u001b[0m\u001b[32m2,552,675\u001b[0m (9.74 MB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,552,675\u001b[0m (9.74 MB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 397ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\n/kaggle/working/metrics/metrics.py:190: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  ret_score = pearsonr(y_true, y_pred)[0]\n/kaggle/working/metrics/metrics.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  ret_score = spearmanr(y_true, y_pred)[0]\nCURRENT EPOCH: -1\n[DEV] AVG QWK: 0.022\n[DEV] score QWK: -0.058\n[DEV] content QWK: -0.036\n[DEV] organization QWK: 0.094\n[DEV] word_choice QWK: 0.095\n[DEV] sentence_fluency QWK: 0.062\n[DEV] conventions QWK: 0.038\n[DEV] prompt_adherence QWK: 0.066\n[DEV] language QWK: -0.049\n[DEV] narrativity QWK: -0.01\n------------------------\n[TEST] AVG QWK: -0.015\n[TEST] score QWK: 0.0\n[TEST] content QWK: -0.027\n[TEST] prompt_adherence QWK: 0.0\n[TEST] language QWK: -0.048\n[TEST] narrativity QWK: -0.002\n------------------------\n[BEST TEST] AVG QWK: -0.015, {epoch}: -1\n[BEST TEST] score QWK: 0.0\n[BEST TEST] content QWK: -0.027\n[BEST TEST] prompt_adherence QWK: 0.0\n[BEST TEST] language QWK: -0.048\n[BEST TEST] narrativity QWK: -0.002\n--------------------------------------------------------------------------------------------------------------------------\nEpoch 1/50\ntrait num:  9\ntrait num:  9\ntrait num:  9\nTraining one epoch in 366.226 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 1\n[DEV] AVG QWK: 0.601\n[DEV] score QWK: 0.712\n[DEV] content QWK: 0.589\n[DEV] organization QWK: 0.608\n[DEV] word_choice QWK: 0.597\n[DEV] sentence_fluency QWK: 0.563\n[DEV] conventions QWK: 0.564\n[DEV] prompt_adherence QWK: 0.587\n[DEV] language QWK: 0.583\n[DEV] narrativity QWK: 0.606\n------------------------\n[TEST] AVG QWK: 0.49\n[TEST] score QWK: 0.575\n[TEST] content QWK: 0.418\n[TEST] prompt_adherence QWK: 0.458\n[TEST] language QWK: 0.468\n[TEST] narrativity QWK: 0.532\n------------------------\n[BEST TEST] AVG QWK: 0.49, {epoch}: 1\n[BEST TEST] score QWK: 0.575\n[BEST TEST] content QWK: 0.418\n[BEST TEST] prompt_adherence QWK: 0.458\n[BEST TEST] language QWK: 0.468\n[BEST TEST] narrativity QWK: 0.532\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.016700398176908493 || Val Loss:  0.014150304719805717\nEpoch 2/50\nTraining one epoch in 227.908 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 2\n[DEV] AVG QWK: 0.638\n[DEV] score QWK: 0.729\n[DEV] content QWK: 0.627\n[DEV] organization QWK: 0.654\n[DEV] word_choice QWK: 0.63\n[DEV] sentence_fluency QWK: 0.598\n[DEV] conventions QWK: 0.628\n[DEV] prompt_adherence QWK: 0.621\n[DEV] language QWK: 0.619\n[DEV] narrativity QWK: 0.636\n------------------------\n[TEST] AVG QWK: 0.51\n[TEST] score QWK: 0.584\n[TEST] content QWK: 0.452\n[TEST] prompt_adherence QWK: 0.475\n[TEST] language QWK: 0.497\n[TEST] narrativity QWK: 0.542\n------------------------\n[BEST TEST] AVG QWK: 0.51, {epoch}: 2\n[BEST TEST] score QWK: 0.584\n[BEST TEST] content QWK: 0.452\n[BEST TEST] prompt_adherence QWK: 0.475\n[BEST TEST] language QWK: 0.497\n[BEST TEST] narrativity QWK: 0.542\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.013734159991145134 || Val Loss:  0.013309748843312263\nEpoch 3/50\nTraining one epoch in 227.221 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 3\n[DEV] AVG QWK: 0.654\n[DEV] score QWK: 0.737\n[DEV] content QWK: 0.644\n[DEV] organization QWK: 0.672\n[DEV] word_choice QWK: 0.642\n[DEV] sentence_fluency QWK: 0.614\n[DEV] conventions QWK: 0.654\n[DEV] prompt_adherence QWK: 0.636\n[DEV] language QWK: 0.636\n[DEV] narrativity QWK: 0.647\n------------------------\n[TEST] AVG QWK: 0.524\n[TEST] score QWK: 0.594\n[TEST] content QWK: 0.47\n[TEST] prompt_adherence QWK: 0.489\n[TEST] language QWK: 0.515\n[TEST] narrativity QWK: 0.551\n------------------------\n[BEST TEST] AVG QWK: 0.524, {epoch}: 3\n[BEST TEST] score QWK: 0.594\n[BEST TEST] content QWK: 0.47\n[BEST TEST] prompt_adherence QWK: 0.489\n[BEST TEST] language QWK: 0.515\n[BEST TEST] narrativity QWK: 0.551\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.013156037777662277 || Val Loss:  0.012882694602012634\nEpoch 4/50\nTraining one epoch in 227.482 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 4\n[DEV] AVG QWK: 0.663\n[DEV] score QWK: 0.743\n[DEV] content QWK: 0.654\n[DEV] organization QWK: 0.683\n[DEV] word_choice QWK: 0.65\n[DEV] sentence_fluency QWK: 0.623\n[DEV] conventions QWK: 0.671\n[DEV] prompt_adherence QWK: 0.645\n[DEV] language QWK: 0.645\n[DEV] narrativity QWK: 0.655\n------------------------\n[TEST] AVG QWK: 0.53\n[TEST] score QWK: 0.596\n[TEST] content QWK: 0.478\n[TEST] prompt_adherence QWK: 0.495\n[TEST] language QWK: 0.524\n[TEST] narrativity QWK: 0.555\n------------------------\n[BEST TEST] AVG QWK: 0.53, {epoch}: 4\n[BEST TEST] score QWK: 0.596\n[BEST TEST] content QWK: 0.478\n[BEST TEST] prompt_adherence QWK: 0.495\n[BEST TEST] language QWK: 0.524\n[BEST TEST] narrativity QWK: 0.555\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012832005508244038 || Val Loss:  0.012611022219061852\nEpoch 5/50\nTraining one epoch in 228.123 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 5\n[DEV] AVG QWK: 0.67\n[DEV] score QWK: 0.747\n[DEV] content QWK: 0.661\n[DEV] organization QWK: 0.69\n[DEV] word_choice QWK: 0.656\n[DEV] sentence_fluency QWK: 0.63\n[DEV] conventions QWK: 0.681\n[DEV] prompt_adherence QWK: 0.652\n[DEV] language QWK: 0.652\n[DEV] narrativity QWK: 0.661\n------------------------\n[TEST] AVG QWK: 0.535\n[TEST] score QWK: 0.602\n[TEST] content QWK: 0.484\n[TEST] prompt_adherence QWK: 0.504\n[TEST] language QWK: 0.527\n[TEST] narrativity QWK: 0.557\n------------------------\n[BEST TEST] AVG QWK: 0.535, {epoch}: 5\n[BEST TEST] score QWK: 0.602\n[BEST TEST] content QWK: 0.484\n[BEST TEST] prompt_adherence QWK: 0.504\n[BEST TEST] language QWK: 0.527\n[BEST TEST] narrativity QWK: 0.557\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012616482563316822 || Val Loss:  0.012419371865689754\nEpoch 6/50\nTraining one epoch in 227.482 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 6\n[DEV] AVG QWK: 0.675\n[DEV] score QWK: 0.75\n[DEV] content QWK: 0.667\n[DEV] organization QWK: 0.696\n[DEV] word_choice QWK: 0.661\n[DEV] sentence_fluency QWK: 0.635\n[DEV] conventions QWK: 0.689\n[DEV] prompt_adherence QWK: 0.658\n[DEV] language QWK: 0.658\n[DEV] narrativity QWK: 0.667\n------------------------\n[TEST] AVG QWK: 0.539\n[TEST] score QWK: 0.602\n[TEST] content QWK: 0.485\n[TEST] prompt_adherence QWK: 0.513\n[TEST] language QWK: 0.529\n[TEST] narrativity QWK: 0.565\n------------------------\n[BEST TEST] AVG QWK: 0.539, {epoch}: 6\n[BEST TEST] score QWK: 0.602\n[BEST TEST] content QWK: 0.485\n[BEST TEST] prompt_adherence QWK: 0.513\n[BEST TEST] language QWK: 0.529\n[BEST TEST] narrativity QWK: 0.565\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01245965901762247 || Val Loss:  0.01227517519146204\nEpoch 7/50\nTraining one epoch in 227.208 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 7\n[DEV] AVG QWK: 0.679\n[DEV] score QWK: 0.753\n[DEV] content QWK: 0.671\n[DEV] organization QWK: 0.699\n[DEV] word_choice QWK: 0.664\n[DEV] sentence_fluency QWK: 0.64\n[DEV] conventions QWK: 0.694\n[DEV] prompt_adherence QWK: 0.662\n[DEV] language QWK: 0.662\n[DEV] narrativity QWK: 0.67\n------------------------\n[TEST] AVG QWK: 0.546\n[TEST] score QWK: 0.608\n[TEST] content QWK: 0.491\n[TEST] prompt_adherence QWK: 0.519\n[TEST] language QWK: 0.538\n[TEST] narrativity QWK: 0.573\n------------------------\n[BEST TEST] AVG QWK: 0.546, {epoch}: 7\n[BEST TEST] score QWK: 0.608\n[BEST TEST] content QWK: 0.491\n[BEST TEST] prompt_adherence QWK: 0.519\n[BEST TEST] language QWK: 0.538\n[BEST TEST] narrativity QWK: 0.573\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012338866479694843 || Val Loss:  0.012161691673099995\nEpoch 8/50\nTraining one epoch in 227.403 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 8\n[DEV] AVG QWK: 0.683\n[DEV] score QWK: 0.755\n[DEV] content QWK: 0.674\n[DEV] organization QWK: 0.702\n[DEV] word_choice QWK: 0.668\n[DEV] sentence_fluency QWK: 0.641\n[DEV] conventions QWK: 0.699\n[DEV] prompt_adherence QWK: 0.667\n[DEV] language QWK: 0.665\n[DEV] narrativity QWK: 0.673\n------------------------\n[TEST] AVG QWK: 0.55\n[TEST] score QWK: 0.611\n[TEST] content QWK: 0.497\n[TEST] prompt_adherence QWK: 0.523\n[TEST] language QWK: 0.543\n[TEST] narrativity QWK: 0.574\n------------------------\n[BEST TEST] AVG QWK: 0.55, {epoch}: 8\n[BEST TEST] score QWK: 0.611\n[BEST TEST] content QWK: 0.497\n[BEST TEST] prompt_adherence QWK: 0.523\n[BEST TEST] language QWK: 0.543\n[BEST TEST] narrativity QWK: 0.574\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012242102064192295 || Val Loss:  0.012069391086697578\nEpoch 9/50\nTraining one epoch in 227.167 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 9\n[DEV] AVG QWK: 0.685\n[DEV] score QWK: 0.757\n[DEV] content QWK: 0.677\n[DEV] organization QWK: 0.705\n[DEV] word_choice QWK: 0.669\n[DEV] sentence_fluency QWK: 0.645\n[DEV] conventions QWK: 0.703\n[DEV] prompt_adherence QWK: 0.67\n[DEV] language QWK: 0.668\n[DEV] narrativity QWK: 0.676\n------------------------\n[TEST] AVG QWK: 0.554\n[TEST] score QWK: 0.615\n[TEST] content QWK: 0.501\n[TEST] prompt_adherence QWK: 0.527\n[TEST] language QWK: 0.551\n[TEST] narrativity QWK: 0.577\n------------------------\n[BEST TEST] AVG QWK: 0.554, {epoch}: 9\n[BEST TEST] score QWK: 0.615\n[BEST TEST] content QWK: 0.501\n[BEST TEST] prompt_adherence QWK: 0.527\n[BEST TEST] language QWK: 0.551\n[BEST TEST] narrativity QWK: 0.577\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012162338010966778 || Val Loss:  0.011992428451776505\nEpoch 10/50\nTraining one epoch in 227.769 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 10\n[DEV] AVG QWK: 0.688\n[DEV] score QWK: 0.758\n[DEV] content QWK: 0.68\n[DEV] organization QWK: 0.707\n[DEV] word_choice QWK: 0.671\n[DEV] sentence_fluency QWK: 0.648\n[DEV] conventions QWK: 0.706\n[DEV] prompt_adherence QWK: 0.672\n[DEV] language QWK: 0.671\n[DEV] narrativity QWK: 0.679\n------------------------\n[TEST] AVG QWK: 0.556\n[TEST] score QWK: 0.615\n[TEST] content QWK: 0.502\n[TEST] prompt_adherence QWK: 0.528\n[TEST] language QWK: 0.551\n[TEST] narrativity QWK: 0.581\n------------------------\n[BEST TEST] AVG QWK: 0.556, {epoch}: 10\n[BEST TEST] score QWK: 0.615\n[BEST TEST] content QWK: 0.502\n[BEST TEST] prompt_adherence QWK: 0.528\n[BEST TEST] language QWK: 0.551\n[BEST TEST] narrativity QWK: 0.581\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012095166370272636 || Val Loss:  0.011927027255296707\nEpoch 11/50\nTraining one epoch in 227.883 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 11\n[DEV] AVG QWK: 0.69\n[DEV] score QWK: 0.759\n[DEV] content QWK: 0.682\n[DEV] organization QWK: 0.708\n[DEV] word_choice QWK: 0.673\n[DEV] sentence_fluency QWK: 0.65\n[DEV] conventions QWK: 0.708\n[DEV] prompt_adherence QWK: 0.674\n[DEV] language QWK: 0.673\n[DEV] narrativity QWK: 0.681\n------------------------\n[TEST] AVG QWK: 0.558\n[TEST] score QWK: 0.617\n[TEST] content QWK: 0.505\n[TEST] prompt_adherence QWK: 0.533\n[TEST] language QWK: 0.551\n[TEST] narrativity QWK: 0.585\n------------------------\n[BEST TEST] AVG QWK: 0.558, {epoch}: 11\n[BEST TEST] score QWK: 0.617\n[BEST TEST] content QWK: 0.505\n[BEST TEST] prompt_adherence QWK: 0.533\n[BEST TEST] language QWK: 0.551\n[BEST TEST] narrativity QWK: 0.585\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012037668377161026 || Val Loss:  0.011870590969920158\nEpoch 12/50\nTraining one epoch in 228.750 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 12\n[DEV] AVG QWK: 0.692\n[DEV] score QWK: 0.76\n[DEV] content QWK: 0.683\n[DEV] organization QWK: 0.71\n[DEV] word_choice QWK: 0.675\n[DEV] sentence_fluency QWK: 0.651\n[DEV] conventions QWK: 0.711\n[DEV] prompt_adherence QWK: 0.677\n[DEV] language QWK: 0.675\n[DEV] narrativity QWK: 0.682\n------------------------\n[TEST] AVG QWK: 0.562\n[TEST] score QWK: 0.617\n[TEST] content QWK: 0.508\n[TEST] prompt_adherence QWK: 0.537\n[TEST] language QWK: 0.56\n[TEST] narrativity QWK: 0.587\n------------------------\n[BEST TEST] AVG QWK: 0.562, {epoch}: 12\n[BEST TEST] score QWK: 0.617\n[BEST TEST] content QWK: 0.508\n[BEST TEST] prompt_adherence QWK: 0.537\n[BEST TEST] language QWK: 0.56\n[BEST TEST] narrativity QWK: 0.587\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011987815611064434 || Val Loss:  0.011821324937045574\nEpoch 13/50\nTraining one epoch in 227.410 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 13\n[DEV] AVG QWK: 0.693\n[DEV] score QWK: 0.761\n[DEV] content QWK: 0.685\n[DEV] organization QWK: 0.711\n[DEV] word_choice QWK: 0.677\n[DEV] sentence_fluency QWK: 0.653\n[DEV] conventions QWK: 0.712\n[DEV] prompt_adherence QWK: 0.678\n[DEV] language QWK: 0.677\n[DEV] narrativity QWK: 0.684\n------------------------\n[TEST] AVG QWK: 0.563\n[TEST] score QWK: 0.617\n[TEST] content QWK: 0.51\n[TEST] prompt_adherence QWK: 0.541\n[TEST] language QWK: 0.56\n[TEST] narrativity QWK: 0.586\n------------------------\n[BEST TEST] AVG QWK: 0.563, {epoch}: 13\n[BEST TEST] score QWK: 0.617\n[BEST TEST] content QWK: 0.51\n[BEST TEST] prompt_adherence QWK: 0.541\n[BEST TEST] language QWK: 0.56\n[BEST TEST] narrativity QWK: 0.586\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011944114230573177 || Val Loss:  0.011777888983488083\nEpoch 14/50\nTraining one epoch in 227.404 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 14\n[DEV] AVG QWK: 0.695\n[DEV] score QWK: 0.762\n[DEV] content QWK: 0.686\n[DEV] organization QWK: 0.713\n[DEV] word_choice QWK: 0.679\n[DEV] sentence_fluency QWK: 0.654\n[DEV] conventions QWK: 0.714\n[DEV] prompt_adherence QWK: 0.68\n[DEV] language QWK: 0.678\n[DEV] narrativity QWK: 0.685\n------------------------\n[TEST] AVG QWK: 0.564\n[TEST] score QWK: 0.617\n[TEST] content QWK: 0.512\n[TEST] prompt_adherence QWK: 0.543\n[TEST] language QWK: 0.565\n[TEST] narrativity QWK: 0.584\n------------------------\n[BEST TEST] AVG QWK: 0.564, {epoch}: 14\n[BEST TEST] score QWK: 0.617\n[BEST TEST] content QWK: 0.512\n[BEST TEST] prompt_adherence QWK: 0.543\n[BEST TEST] language QWK: 0.565\n[BEST TEST] narrativity QWK: 0.584\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011905498802661896 || Val Loss:  0.011739279143512249\nEpoch 15/50\nTraining one epoch in 227.193 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 15\n[DEV] AVG QWK: 0.696\n[DEV] score QWK: 0.763\n[DEV] content QWK: 0.687\n[DEV] organization QWK: 0.714\n[DEV] word_choice QWK: 0.68\n[DEV] sentence_fluency QWK: 0.655\n[DEV] conventions QWK: 0.715\n[DEV] prompt_adherence QWK: 0.681\n[DEV] language QWK: 0.679\n[DEV] narrativity QWK: 0.687\n------------------------\n[TEST] AVG QWK: 0.564\n[TEST] score QWK: 0.618\n[TEST] content QWK: 0.516\n[TEST] prompt_adherence QWK: 0.541\n[TEST] language QWK: 0.564\n[TEST] narrativity QWK: 0.583\n------------------------\n[BEST TEST] AVG QWK: 0.564, {epoch}: 15\n[BEST TEST] score QWK: 0.618\n[BEST TEST] content QWK: 0.516\n[BEST TEST] prompt_adherence QWK: 0.541\n[BEST TEST] language QWK: 0.564\n[BEST TEST] narrativity QWK: 0.583\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011871122755110264 || Val Loss:  0.011704724282026291\nEpoch 16/50\nTraining one epoch in 227.168 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 16\n[DEV] AVG QWK: 0.697\n[DEV] score QWK: 0.763\n[DEV] content QWK: 0.689\n[DEV] organization QWK: 0.715\n[DEV] word_choice QWK: 0.681\n[DEV] sentence_fluency QWK: 0.657\n[DEV] conventions QWK: 0.716\n[DEV] prompt_adherence QWK: 0.682\n[DEV] language QWK: 0.68\n[DEV] narrativity QWK: 0.688\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.618\n[TEST] content QWK: 0.517\n[TEST] prompt_adherence QWK: 0.542\n[TEST] language QWK: 0.562\n[TEST] narrativity QWK: 0.582\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 16\n[BEST TEST] score QWK: 0.618\n[BEST TEST] content QWK: 0.517\n[BEST TEST] prompt_adherence QWK: 0.542\n[BEST TEST] language QWK: 0.562\n[BEST TEST] narrativity QWK: 0.582\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011840320192277431 || Val Loss:  0.011673632077872753\nEpoch 17/50\nTraining one epoch in 227.356 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 17\n[DEV] AVG QWK: 0.698\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.69\n[DEV] organization QWK: 0.715\n[DEV] word_choice QWK: 0.681\n[DEV] sentence_fluency QWK: 0.659\n[DEV] conventions QWK: 0.717\n[DEV] prompt_adherence QWK: 0.683\n[DEV] language QWK: 0.681\n[DEV] narrativity QWK: 0.689\n------------------------\n[TEST] AVG QWK: 0.567\n[TEST] score QWK: 0.622\n[TEST] content QWK: 0.517\n[TEST] prompt_adherence QWK: 0.547\n[TEST] language QWK: 0.563\n[TEST] narrativity QWK: 0.584\n------------------------\n[BEST TEST] AVG QWK: 0.567, {epoch}: 17\n[BEST TEST] score QWK: 0.622\n[BEST TEST] content QWK: 0.517\n[BEST TEST] prompt_adherence QWK: 0.547\n[BEST TEST] language QWK: 0.563\n[BEST TEST] narrativity QWK: 0.584\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011812564916908741 || Val Loss:  0.011645513586699963\nEpoch 18/50\nTraining one epoch in 226.835 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\nCURRENT EPOCH: 18\n[DEV] AVG QWK: 0.698\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.691\n[DEV] organization QWK: 0.716\n[DEV] word_choice QWK: 0.681\n[DEV] sentence_fluency QWK: 0.659\n[DEV] conventions QWK: 0.719\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.682\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.567\n[TEST] score QWK: 0.622\n[TEST] content QWK: 0.519\n[TEST] prompt_adherence QWK: 0.548\n[TEST] language QWK: 0.563\n[TEST] narrativity QWK: 0.583\n------------------------\n[BEST TEST] AVG QWK: 0.567, {epoch}: 18\n[BEST TEST] score QWK: 0.622\n[BEST TEST] content QWK: 0.519\n[BEST TEST] prompt_adherence QWK: 0.548\n[BEST TEST] language QWK: 0.563\n[BEST TEST] narrativity QWK: 0.583\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011787454597651958 || Val Loss:  0.011619956232607365\nEpoch 19/50\nTraining one epoch in 227.028 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 19\n[DEV] AVG QWK: 0.699\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.691\n[DEV] organization QWK: 0.717\n[DEV] word_choice QWK: 0.683\n[DEV] sentence_fluency QWK: 0.661\n[DEV] conventions QWK: 0.719\n[DEV] prompt_adherence QWK: 0.685\n[DEV] language QWK: 0.683\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.567\n[TEST] score QWK: 0.622\n[TEST] content QWK: 0.52\n[TEST] prompt_adherence QWK: 0.547\n[TEST] language QWK: 0.566\n[TEST] narrativity QWK: 0.583\n------------------------\n[BEST TEST] AVG QWK: 0.567, {epoch}: 19\n[BEST TEST] score QWK: 0.622\n[BEST TEST] content QWK: 0.52\n[BEST TEST] prompt_adherence QWK: 0.547\n[BEST TEST] language QWK: 0.566\n[BEST TEST] narrativity QWK: 0.583\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011764610186219215 || Val Loss:  0.011596650816500187\nEpoch 20/50\nTraining one epoch in 226.883 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 20\n[DEV] AVG QWK: 0.7\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.692\n[DEV] organization QWK: 0.718\n[DEV] word_choice QWK: 0.683\n[DEV] sentence_fluency QWK: 0.662\n[DEV] conventions QWK: 0.721\n[DEV] prompt_adherence QWK: 0.686\n[DEV] language QWK: 0.684\n[DEV] narrativity QWK: 0.691\n------------------------\n[TEST] AVG QWK: 0.569\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.52\n[TEST] prompt_adherence QWK: 0.55\n[TEST] language QWK: 0.568\n[TEST] narrativity QWK: 0.583\n------------------------\n[BEST TEST] AVG QWK: 0.569, {epoch}: 20\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.52\n[BEST TEST] prompt_adherence QWK: 0.55\n[BEST TEST] language QWK: 0.568\n[BEST TEST] narrativity QWK: 0.583\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011743780225515366 || Val Loss:  0.011575316078960896\nEpoch 21/50\nTraining one epoch in 226.666 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\nCURRENT EPOCH: 21\n[DEV] AVG QWK: 0.701\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.693\n[DEV] organization QWK: 0.719\n[DEV] word_choice QWK: 0.685\n[DEV] sentence_fluency QWK: 0.663\n[DEV] conventions QWK: 0.721\n[DEV] prompt_adherence QWK: 0.687\n[DEV] language QWK: 0.685\n[DEV] narrativity QWK: 0.692\n------------------------\n[TEST] AVG QWK: 0.569\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.52\n[TEST] prompt_adherence QWK: 0.55\n[TEST] language QWK: 0.569\n[TEST] narrativity QWK: 0.583\n------------------------\n[BEST TEST] AVG QWK: 0.569, {epoch}: 21\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.52\n[BEST TEST] prompt_adherence QWK: 0.55\n[BEST TEST] language QWK: 0.569\n[BEST TEST] narrativity QWK: 0.583\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011724685318768024 || Val Loss:  0.01155572198331356\nEpoch 22/50\nTraining one epoch in 226.599 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 22\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.694\n[DEV] organization QWK: 0.719\n[DEV] word_choice QWK: 0.685\n[DEV] sentence_fluency QWK: 0.664\n[DEV] conventions QWK: 0.722\n[DEV] prompt_adherence QWK: 0.688\n[DEV] language QWK: 0.686\n[DEV] narrativity QWK: 0.693\n------------------------\n[TEST] AVG QWK: 0.568\n[TEST] score QWK: 0.622\n[TEST] content QWK: 0.52\n[TEST] prompt_adherence QWK: 0.55\n[TEST] language QWK: 0.568\n[TEST] narrativity QWK: 0.582\n------------------------\n[BEST TEST] AVG QWK: 0.568, {epoch}: 22\n[BEST TEST] score QWK: 0.622\n[BEST TEST] content QWK: 0.52\n[BEST TEST] prompt_adherence QWK: 0.55\n[BEST TEST] language QWK: 0.568\n[BEST TEST] narrativity QWK: 0.582\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01170714758336544 || Val Loss:  0.011537675745785236\nEpoch 23/50\nTraining one epoch in 224.367 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 23\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.694\n[DEV] organization QWK: 0.72\n[DEV] word_choice QWK: 0.686\n[DEV] sentence_fluency QWK: 0.664\n[DEV] conventions QWK: 0.723\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.687\n[DEV] narrativity QWK: 0.694\n------------------------\n[TEST] AVG QWK: 0.569\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.521\n[TEST] prompt_adherence QWK: 0.552\n[TEST] language QWK: 0.567\n[TEST] narrativity QWK: 0.584\n------------------------\n[BEST TEST] AVG QWK: 0.569, {epoch}: 23\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.521\n[BEST TEST] prompt_adherence QWK: 0.552\n[BEST TEST] language QWK: 0.567\n[BEST TEST] narrativity QWK: 0.584\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01169098075479269 || Val Loss:  0.011521009728312492\nEpoch 24/50\nTraining one epoch in 221.907 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 24\n[DEV] AVG QWK: 0.703\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.694\n[DEV] organization QWK: 0.72\n[DEV] word_choice QWK: 0.687\n[DEV] sentence_fluency QWK: 0.666\n[DEV] conventions QWK: 0.724\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.687\n[DEV] narrativity QWK: 0.694\n------------------------\n[TEST] AVG QWK: 0.57\n[TEST] score QWK: 0.62\n[TEST] content QWK: 0.521\n[TEST] prompt_adherence QWK: 0.553\n[TEST] language QWK: 0.569\n[TEST] narrativity QWK: 0.585\n------------------------\n[BEST TEST] AVG QWK: 0.57, {epoch}: 24\n[BEST TEST] score QWK: 0.62\n[BEST TEST] content QWK: 0.521\n[BEST TEST] prompt_adherence QWK: 0.553\n[BEST TEST] language QWK: 0.569\n[BEST TEST] narrativity QWK: 0.585\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011676034890115261 || Val Loss:  0.011505582369863987\nEpoch 25/50\nTraining one epoch in 222.666 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\nCURRENT EPOCH: 25\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.695\n[DEV] organization QWK: 0.721\n[DEV] word_choice QWK: 0.688\n[DEV] sentence_fluency QWK: 0.666\n[DEV] conventions QWK: 0.725\n[DEV] prompt_adherence QWK: 0.69\n[DEV] language QWK: 0.687\n[DEV] narrativity QWK: 0.695\n------------------------\n[TEST] AVG QWK: 0.57\n[TEST] score QWK: 0.62\n[TEST] content QWK: 0.523\n[TEST] prompt_adherence QWK: 0.553\n[TEST] language QWK: 0.57\n[TEST] narrativity QWK: 0.584\n------------------------\n[BEST TEST] AVG QWK: 0.57, {epoch}: 25\n[BEST TEST] score QWK: 0.62\n[BEST TEST] content QWK: 0.523\n[BEST TEST] prompt_adherence QWK: 0.553\n[BEST TEST] language QWK: 0.57\n[BEST TEST] narrativity QWK: 0.584\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011662192642688751 || Val Loss:  0.011491259559988976\nEpoch 26/50\nTraining one epoch in 222.045 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 26\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.696\n[DEV] organization QWK: 0.722\n[DEV] word_choice QWK: 0.688\n[DEV] sentence_fluency QWK: 0.667\n[DEV] conventions QWK: 0.726\n[DEV] prompt_adherence QWK: 0.69\n[DEV] language QWK: 0.688\n[DEV] narrativity QWK: 0.696\n------------------------\n[TEST] AVG QWK: 0.571\n[TEST] score QWK: 0.62\n[TEST] content QWK: 0.523\n[TEST] prompt_adherence QWK: 0.553\n[TEST] language QWK: 0.571\n[TEST] narrativity QWK: 0.585\n------------------------\n[BEST TEST] AVG QWK: 0.571, {epoch}: 26\n[BEST TEST] score QWK: 0.62\n[BEST TEST] content QWK: 0.523\n[BEST TEST] prompt_adherence QWK: 0.553\n[BEST TEST] language QWK: 0.571\n[BEST TEST] narrativity QWK: 0.585\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01164933480322361 || Val Loss:  0.011477944441139698\nEpoch 27/50\nTraining one epoch in 222.746 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\nCURRENT EPOCH: 27\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.696\n[DEV] organization QWK: 0.722\n[DEV] word_choice QWK: 0.689\n[DEV] sentence_fluency QWK: 0.667\n[DEV] conventions QWK: 0.726\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.689\n[DEV] narrativity QWK: 0.696\n------------------------\n[TEST] AVG QWK: 0.572\n[TEST] score QWK: 0.623\n[TEST] content QWK: 0.523\n[TEST] prompt_adherence QWK: 0.554\n[TEST] language QWK: 0.571\n[TEST] narrativity QWK: 0.587\n------------------------\n[BEST TEST] AVG QWK: 0.572, {epoch}: 27\n[BEST TEST] score QWK: 0.623\n[BEST TEST] content QWK: 0.523\n[BEST TEST] prompt_adherence QWK: 0.554\n[BEST TEST] language QWK: 0.571\n[BEST TEST] narrativity QWK: 0.587\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01163734495639801 || Val Loss:  0.011465531773865223\nEpoch 28/50\nTraining one epoch in 222.074 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\nCURRENT EPOCH: 28\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.696\n[DEV] organization QWK: 0.723\n[DEV] word_choice QWK: 0.689\n[DEV] sentence_fluency QWK: 0.668\n[DEV] conventions QWK: 0.726\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.689\n[DEV] narrativity QWK: 0.696\n------------------------\n[TEST] AVG QWK: 0.572\n[TEST] score QWK: 0.623\n[TEST] content QWK: 0.523\n[TEST] prompt_adherence QWK: 0.556\n[TEST] language QWK: 0.573\n[TEST] narrativity QWK: 0.587\n------------------------\n[BEST TEST] AVG QWK: 0.572, {epoch}: 28\n[BEST TEST] score QWK: 0.623\n[BEST TEST] content QWK: 0.523\n[BEST TEST] prompt_adherence QWK: 0.556\n[BEST TEST] language QWK: 0.573\n[BEST TEST] narrativity QWK: 0.587\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.0116261662915349 || Val Loss:  0.011453956365585327\nEpoch 29/50\nTraining one epoch in 221.687 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 29\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.697\n[DEV] organization QWK: 0.723\n[DEV] word_choice QWK: 0.69\n[DEV] sentence_fluency QWK: 0.668\n[DEV] conventions QWK: 0.726\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.689\n[DEV] narrativity QWK: 0.696\n------------------------\n[TEST] AVG QWK: 0.573\n[TEST] score QWK: 0.624\n[TEST] content QWK: 0.523\n[TEST] prompt_adherence QWK: 0.557\n[TEST] language QWK: 0.572\n[TEST] narrativity QWK: 0.587\n------------------------\n[BEST TEST] AVG QWK: 0.573, {epoch}: 29\n[BEST TEST] score QWK: 0.624\n[BEST TEST] content QWK: 0.523\n[BEST TEST] prompt_adherence QWK: 0.557\n[BEST TEST] language QWK: 0.572\n[BEST TEST] narrativity QWK: 0.587\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011615706607699394 || Val Loss:  0.01144311111420393\nEpoch 30/50\nTraining one epoch in 222.091 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 30\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.697\n[DEV] organization QWK: 0.723\n[DEV] word_choice QWK: 0.691\n[DEV] sentence_fluency QWK: 0.67\n[DEV] conventions QWK: 0.727\n[DEV] prompt_adherence QWK: 0.692\n[DEV] language QWK: 0.689\n[DEV] narrativity QWK: 0.697\n------------------------\n[TEST] AVG QWK: 0.573\n[TEST] score QWK: 0.624\n[TEST] content QWK: 0.525\n[TEST] prompt_adherence QWK: 0.557\n[TEST] language QWK: 0.571\n[TEST] narrativity QWK: 0.587\n------------------------\n[BEST TEST] AVG QWK: 0.573, {epoch}: 30\n[BEST TEST] score QWK: 0.624\n[BEST TEST] content QWK: 0.525\n[BEST TEST] prompt_adherence QWK: 0.557\n[BEST TEST] language QWK: 0.571\n[BEST TEST] narrativity QWK: 0.587\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011605898849666119 || Val Loss:  0.011432952247560024\nEpoch 31/50\nTraining one epoch in 222.280 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 31\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.724\n[DEV] word_choice QWK: 0.692\n[DEV] sentence_fluency QWK: 0.669\n[DEV] conventions QWK: 0.727\n[DEV] prompt_adherence QWK: 0.692\n[DEV] language QWK: 0.689\n[DEV] narrativity QWK: 0.697\n------------------------\n[TEST] AVG QWK: 0.573\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.526\n[TEST] prompt_adherence QWK: 0.559\n[TEST] language QWK: 0.571\n[TEST] narrativity QWK: 0.585\n------------------------\n[BEST TEST] AVG QWK: 0.573, {epoch}: 31\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.526\n[BEST TEST] prompt_adherence QWK: 0.559\n[BEST TEST] language QWK: 0.571\n[BEST TEST] narrativity QWK: 0.585\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011596700176596642 || Val Loss:  0.011423420161008835\nEpoch 32/50\nTraining one epoch in 221.762 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\nCURRENT EPOCH: 32\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.724\n[DEV] word_choice QWK: 0.692\n[DEV] sentence_fluency QWK: 0.671\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.693\n[DEV] language QWK: 0.69\n[DEV] narrativity QWK: 0.697\n------------------------\n[TEST] AVG QWK: 0.575\n[TEST] score QWK: 0.624\n[TEST] content QWK: 0.526\n[TEST] prompt_adherence QWK: 0.56\n[TEST] language QWK: 0.574\n[TEST] narrativity QWK: 0.589\n------------------------\n[BEST TEST] AVG QWK: 0.575, {epoch}: 32\n[BEST TEST] score QWK: 0.624\n[BEST TEST] content QWK: 0.526\n[BEST TEST] prompt_adherence QWK: 0.56\n[BEST TEST] language QWK: 0.574\n[BEST TEST] narrativity QWK: 0.589\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01158805750310421 || Val Loss:  0.011414465494453907\nEpoch 33/50\nTraining one epoch in 221.980 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\nCURRENT EPOCH: 33\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.725\n[DEV] word_choice QWK: 0.692\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.693\n[DEV] language QWK: 0.69\n[DEV] narrativity QWK: 0.698\n------------------------\n[TEST] AVG QWK: 0.575\n[TEST] score QWK: 0.624\n[TEST] content QWK: 0.527\n[TEST] prompt_adherence QWK: 0.561\n[TEST] language QWK: 0.576\n[TEST] narrativity QWK: 0.588\n------------------------\n[BEST TEST] AVG QWK: 0.575, {epoch}: 33\n[BEST TEST] score QWK: 0.624\n[BEST TEST] content QWK: 0.527\n[BEST TEST] prompt_adherence QWK: 0.561\n[BEST TEST] language QWK: 0.576\n[BEST TEST] narrativity QWK: 0.588\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011579927057027817 || Val Loss:  0.011406037956476212\nEpoch 34/50\nTraining one epoch in 222.052 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 34\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.725\n[DEV] word_choice QWK: 0.692\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.694\n[DEV] language QWK: 0.691\n[DEV] narrativity QWK: 0.699\n------------------------\n[TEST] AVG QWK: 0.576\n[TEST] score QWK: 0.627\n[TEST] content QWK: 0.529\n[TEST] prompt_adherence QWK: 0.56\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.59\n------------------------\n[BEST TEST] AVG QWK: 0.576, {epoch}: 34\n[BEST TEST] score QWK: 0.627\n[BEST TEST] content QWK: 0.529\n[BEST TEST] prompt_adherence QWK: 0.56\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.59\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011572238057851791 || Val Loss:  0.01139809563755989\nEpoch 35/50\nTraining one epoch in 222.274 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 35\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.725\n[DEV] word_choice QWK: 0.693\n[DEV] sentence_fluency QWK: 0.673\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.694\n[DEV] language QWK: 0.691\n[DEV] narrativity QWK: 0.699\n------------------------\n[TEST] AVG QWK: 0.577\n[TEST] score QWK: 0.626\n[TEST] content QWK: 0.532\n[TEST] prompt_adherence QWK: 0.562\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.589\n------------------------\n[BEST TEST] AVG QWK: 0.577, {epoch}: 35\n[BEST TEST] score QWK: 0.626\n[BEST TEST] content QWK: 0.532\n[BEST TEST] prompt_adherence QWK: 0.562\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.589\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011564978398382664 || Val Loss:  0.011390594765543938\nEpoch 36/50\nTraining one epoch in 222.174 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 36\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.725\n[DEV] word_choice QWK: 0.692\n[DEV] sentence_fluency QWK: 0.673\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.694\n[DEV] language QWK: 0.692\n[DEV] narrativity QWK: 0.699\n------------------------\n[TEST] AVG QWK: 0.578\n[TEST] score QWK: 0.626\n[TEST] content QWK: 0.533\n[TEST] prompt_adherence QWK: 0.565\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.59\n------------------------\n[BEST TEST] AVG QWK: 0.578, {epoch}: 36\n[BEST TEST] score QWK: 0.626\n[BEST TEST] content QWK: 0.533\n[BEST TEST] prompt_adherence QWK: 0.565\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.59\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011558124795556068 || Val Loss:  0.011383513920009136\nEpoch 37/50\nTraining one epoch in 221.669 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\nCURRENT EPOCH: 37\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.693\n[DEV] sentence_fluency QWK: 0.673\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.694\n[DEV] language QWK: 0.692\n[DEV] narrativity QWK: 0.699\n------------------------\n[TEST] AVG QWK: 0.579\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.535\n[TEST] prompt_adherence QWK: 0.568\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.59\n------------------------\n[BEST TEST] AVG QWK: 0.579, {epoch}: 37\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.535\n[BEST TEST] prompt_adherence QWK: 0.568\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.59\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.0115516297519207 || Val Loss:  0.011376818642020226\nEpoch 38/50\nTraining one epoch in 221.843 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 38\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.674\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.695\n[DEV] language QWK: 0.692\n[DEV] narrativity QWK: 0.699\n------------------------\n[TEST] AVG QWK: 0.579\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.536\n[TEST] prompt_adherence QWK: 0.565\n[TEST] language QWK: 0.578\n[TEST] narrativity QWK: 0.591\n------------------------\n[BEST TEST] AVG QWK: 0.579, {epoch}: 38\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.536\n[BEST TEST] prompt_adherence QWK: 0.565\n[BEST TEST] language QWK: 0.578\n[BEST TEST] narrativity QWK: 0.591\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011545458808541298 || Val Loss:  0.011370480060577393\nEpoch 39/50\nTraining one epoch in 221.931 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\nCURRENT EPOCH: 39\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.7\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.695\n[DEV] sentence_fluency QWK: 0.674\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.695\n[DEV] language QWK: 0.692\n[DEV] narrativity QWK: 0.7\n------------------------\n[TEST] AVG QWK: 0.579\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.538\n[TEST] prompt_adherence QWK: 0.566\n[TEST] language QWK: 0.578\n[TEST] narrativity QWK: 0.59\n------------------------\n[BEST TEST] AVG QWK: 0.579, {epoch}: 39\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.538\n[BEST TEST] prompt_adherence QWK: 0.566\n[BEST TEST] language QWK: 0.578\n[BEST TEST] narrativity QWK: 0.59\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011539611034095287 || Val Loss:  0.011364473961293697\nEpoch 40/50\nTraining one epoch in 222.031 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 40\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.7\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.696\n[DEV] sentence_fluency QWK: 0.675\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.695\n[DEV] language QWK: 0.692\n[DEV] narrativity QWK: 0.7\n------------------------\n[TEST] AVG QWK: 0.579\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.538\n[TEST] prompt_adherence QWK: 0.567\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.589\n------------------------\n[BEST TEST] AVG QWK: 0.579, {epoch}: 40\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.538\n[BEST TEST] prompt_adherence QWK: 0.567\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.589\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011534052900969982 || Val Loss:  0.011358771473169327\nEpoch 41/50\nTraining one epoch in 221.963 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 41\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.7\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.696\n[DEV] sentence_fluency QWK: 0.675\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.696\n[DEV] language QWK: 0.693\n[DEV] narrativity QWK: 0.7\n------------------------\n[TEST] AVG QWK: 0.581\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.54\n[TEST] prompt_adherence QWK: 0.567\n[TEST] language QWK: 0.58\n[TEST] narrativity QWK: 0.591\n------------------------\n[BEST TEST] AVG QWK: 0.581, {epoch}: 41\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.54\n[BEST TEST] prompt_adherence QWK: 0.567\n[BEST TEST] language QWK: 0.58\n[BEST TEST] narrativity QWK: 0.591\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011528749018907547 || Val Loss:  0.011353357695043087\nEpoch 42/50\nTraining one epoch in 221.913 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 42\n[DEV] AVG QWK: 0.71\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.7\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.696\n[DEV] sentence_fluency QWK: 0.675\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.696\n[DEV] language QWK: 0.693\n[DEV] narrativity QWK: 0.701\n------------------------\n[TEST] AVG QWK: 0.581\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.54\n[TEST] prompt_adherence QWK: 0.569\n[TEST] language QWK: 0.582\n[TEST] narrativity QWK: 0.591\n------------------------\n[BEST TEST] AVG QWK: 0.581, {epoch}: 42\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.54\n[BEST TEST] prompt_adherence QWK: 0.569\n[BEST TEST] language QWK: 0.582\n[BEST TEST] narrativity QWK: 0.591\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011523708701133728 || Val Loss:  0.011348213069140911\nEpoch 43/50\nTraining one epoch in 222.090 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 43\n[DEV] AVG QWK: 0.71\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.696\n[DEV] sentence_fluency QWK: 0.675\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.696\n[DEV] language QWK: 0.693\n[DEV] narrativity QWK: 0.702\n------------------------\n[TEST] AVG QWK: 0.582\n[TEST] score QWK: 0.626\n[TEST] content QWK: 0.542\n[TEST] prompt_adherence QWK: 0.57\n[TEST] language QWK: 0.582\n[TEST] narrativity QWK: 0.59\n------------------------\n[BEST TEST] AVG QWK: 0.582, {epoch}: 43\n[BEST TEST] score QWK: 0.626\n[BEST TEST] content QWK: 0.542\n[BEST TEST] prompt_adherence QWK: 0.57\n[BEST TEST] language QWK: 0.582\n[BEST TEST] narrativity QWK: 0.59\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011518912389874458 || Val Loss:  0.01134332362562418\nEpoch 44/50\nTraining one epoch in 222.436 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 44\n[DEV] AVG QWK: 0.71\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.696\n[DEV] sentence_fluency QWK: 0.676\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.697\n[DEV] language QWK: 0.693\n[DEV] narrativity QWK: 0.702\n------------------------\n[TEST] AVG QWK: 0.583\n[TEST] score QWK: 0.626\n[TEST] content QWK: 0.542\n[TEST] prompt_adherence QWK: 0.573\n[TEST] language QWK: 0.583\n[TEST] narrativity QWK: 0.588\n------------------------\n[BEST TEST] AVG QWK: 0.583, {epoch}: 44\n[BEST TEST] score QWK: 0.626\n[BEST TEST] content QWK: 0.542\n[BEST TEST] prompt_adherence QWK: 0.573\n[BEST TEST] language QWK: 0.583\n[BEST TEST] narrativity QWK: 0.588\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011514328420162201 || Val Loss:  0.011338671669363976\nEpoch 45/50\nTraining one epoch in 222.092 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\nCURRENT EPOCH: 45\n[DEV] AVG QWK: 0.71\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.696\n[DEV] sentence_fluency QWK: 0.676\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.696\n[DEV] language QWK: 0.693\n[DEV] narrativity QWK: 0.702\n------------------------\n[TEST] AVG QWK: 0.583\n[TEST] score QWK: 0.626\n[TEST] content QWK: 0.542\n[TEST] prompt_adherence QWK: 0.575\n[TEST] language QWK: 0.582\n[TEST] narrativity QWK: 0.588\n------------------------\n[BEST TEST] AVG QWK: 0.583, {epoch}: 45\n[BEST TEST] score QWK: 0.626\n[BEST TEST] content QWK: 0.542\n[BEST TEST] prompt_adherence QWK: 0.575\n[BEST TEST] language QWK: 0.582\n[BEST TEST] narrativity QWK: 0.588\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011509956791996956 || Val Loss:  0.01133423950523138\nEpoch 46/50\nTraining one epoch in 223.058 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 46\n[DEV] AVG QWK: 0.71\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.696\n[DEV] sentence_fluency QWK: 0.677\n[DEV] conventions QWK: 0.731\n[DEV] prompt_adherence QWK: 0.697\n[DEV] language QWK: 0.694\n[DEV] narrativity QWK: 0.702\n------------------------\n[TEST] AVG QWK: 0.583\n[TEST] score QWK: 0.627\n[TEST] content QWK: 0.544\n[TEST] prompt_adherence QWK: 0.575\n[TEST] language QWK: 0.582\n[TEST] narrativity QWK: 0.588\n------------------------\n[BEST TEST] AVG QWK: 0.583, {epoch}: 46\n[BEST TEST] score QWK: 0.627\n[BEST TEST] content QWK: 0.544\n[BEST TEST] prompt_adherence QWK: 0.575\n[BEST TEST] language QWK: 0.582\n[BEST TEST] narrativity QWK: 0.588\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011505775153636932 || Val Loss:  0.011330010369420052\nEpoch 47/50\nTraining one epoch in 221.652 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 47\n[DEV] AVG QWK: 0.711\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.677\n[DEV] conventions QWK: 0.731\n[DEV] prompt_adherence QWK: 0.697\n[DEV] language QWK: 0.694\n[DEV] narrativity QWK: 0.702\n------------------------\n[TEST] AVG QWK: 0.583\n[TEST] score QWK: 0.627\n[TEST] content QWK: 0.543\n[TEST] prompt_adherence QWK: 0.577\n[TEST] language QWK: 0.582\n[TEST] narrativity QWK: 0.589\n------------------------\n[BEST TEST] AVG QWK: 0.583, {epoch}: 47\n[BEST TEST] score QWK: 0.627\n[BEST TEST] content QWK: 0.543\n[BEST TEST] prompt_adherence QWK: 0.577\n[BEST TEST] language QWK: 0.582\n[BEST TEST] narrativity QWK: 0.589\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011501768603920937 || Val Loss:  0.01132598053663969\nEpoch 48/50\nTraining one epoch in 221.738 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step\nCURRENT EPOCH: 48\n[DEV] AVG QWK: 0.711\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.678\n[DEV] conventions QWK: 0.732\n[DEV] prompt_adherence QWK: 0.697\n[DEV] language QWK: 0.694\n[DEV] narrativity QWK: 0.702\n------------------------\n[TEST] AVG QWK: 0.584\n[TEST] score QWK: 0.627\n[TEST] content QWK: 0.543\n[TEST] prompt_adherence QWK: 0.577\n[TEST] language QWK: 0.582\n[TEST] narrativity QWK: 0.59\n------------------------\n[BEST TEST] AVG QWK: 0.584, {epoch}: 48\n[BEST TEST] score QWK: 0.627\n[BEST TEST] content QWK: 0.543\n[BEST TEST] prompt_adherence QWK: 0.577\n[BEST TEST] language QWK: 0.582\n[BEST TEST] narrativity QWK: 0.59\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011497934348881245 || Val Loss:  0.011322136037051678\nEpoch 49/50\nTraining one epoch in 221.813 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 49\n[DEV] AVG QWK: 0.711\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.678\n[DEV] conventions QWK: 0.732\n[DEV] prompt_adherence QWK: 0.697\n[DEV] language QWK: 0.695\n[DEV] narrativity QWK: 0.703\n------------------------\n[TEST] AVG QWK: 0.583\n[TEST] score QWK: 0.626\n[TEST] content QWK: 0.543\n[TEST] prompt_adherence QWK: 0.575\n[TEST] language QWK: 0.583\n[TEST] narrativity QWK: 0.589\n------------------------\n[BEST TEST] AVG QWK: 0.583, {epoch}: 49\n[BEST TEST] score QWK: 0.626\n[BEST TEST] content QWK: 0.543\n[BEST TEST] prompt_adherence QWK: 0.575\n[BEST TEST] language QWK: 0.583\n[BEST TEST] narrativity QWK: 0.589\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01149427518248558 || Val Loss:  0.011318462900817394\nEpoch 50/50\nTraining one epoch in 222.375 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 50\n[DEV] AVG QWK: 0.711\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.678\n[DEV] conventions QWK: 0.732\n[DEV] prompt_adherence QWK: 0.697\n[DEV] language QWK: 0.695\n[DEV] narrativity QWK: 0.703\n------------------------\n[TEST] AVG QWK: 0.584\n[TEST] score QWK: 0.627\n[TEST] content QWK: 0.543\n[TEST] prompt_adherence QWK: 0.576\n[TEST] language QWK: 0.582\n[TEST] narrativity QWK: 0.591\n------------------------\n[BEST TEST] AVG QWK: 0.584, {epoch}: 50\n[BEST TEST] score QWK: 0.627\n[BEST TEST] content QWK: 0.543\n[BEST TEST] prompt_adherence QWK: 0.576\n[BEST TEST] language QWK: 0.582\n[BEST TEST] narrativity QWK: 0.591\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011490752920508385 || Val Loss:  0.01131495088338852\n[BEST TEST] AVG QWK: 0.584, {epoch}: 50\n[BEST TEST] score QWK: 0.627\n[BEST TEST] content QWK: 0.543\n[BEST TEST] prompt_adherence QWK: 0.576\n[BEST TEST] language QWK: 0.582\n[BEST TEST] narrativity QWK: 0.591\n--------------------------------------------------------------------------------------------------------------------------\nModel saved as 'trained_model/protact_model_prompt_6_seed_22.h5'\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}