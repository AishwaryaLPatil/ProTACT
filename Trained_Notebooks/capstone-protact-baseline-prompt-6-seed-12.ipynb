{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-29T11:16:42.883811Z","iopub.execute_input":"2024-10-29T11:16:42.884321Z","iopub.status.idle":"2024-10-29T11:16:43.308475Z","shell.execute_reply.started":"2024-10-29T11:16:42.884249Z","shell.execute_reply":"2024-10-29T11:16:43.307571Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-10-29T11:16:43.310864Z","iopub.execute_input":"2024-10-29T11:16:43.311399Z","iopub.status.idle":"2024-10-29T11:16:56.311619Z","shell.execute_reply.started":"2024-10-29T11:16:43.311357Z","shell.execute_reply":"2024-10-29T11:16:56.310343Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/ishreya09/ProTACT.git","metadata":{"execution":{"iopub.status.busy":"2024-10-29T11:16:56.313205Z","iopub.execute_input":"2024-10-29T11:16:56.313632Z","iopub.status.idle":"2024-10-29T11:17:12.140637Z","shell.execute_reply.started":"2024-10-29T11:16:56.313575Z","shell.execute_reply":"2024-10-29T11:17:12.139656Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Cloning into 'ProTACT'...\nremote: Enumerating objects: 318, done.\u001b[K\nremote: Counting objects: 100% (7/7), done.\u001b[K\nremote: Compressing objects: 100% (7/7), done.\u001b[K\nremote: Total 318 (delta 0), reused 6 (delta 0), pack-reused 311 (from 1)\u001b[K\nReceiving objects: 100% (318/318), 146.60 MiB | 13.33 MiB/s, done.\nResolving deltas: 100% (173/173), done.\nUpdating files: 100% (136/136), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!cp -r /kaggle/working/ProTACT/* /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-10-29T11:17:12.142145Z","iopub.execute_input":"2024-10-29T11:17:12.142522Z","iopub.status.idle":"2024-10-29T11:17:13.656875Z","shell.execute_reply.started":"2024-10-29T11:17:12.142483Z","shell.execute_reply":"2024-10-29T11:17:13.655818Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"!mkdir trained_model","metadata":{"execution":{"iopub.status.busy":"2024-10-29T11:17:13.659464Z","iopub.execute_input":"2024-10-29T11:17:13.659787Z","iopub.status.idle":"2024-10-29T11:17:14.697482Z","shell.execute_reply.started":"2024-10-29T11:17:13.659753Z","shell.execute_reply":"2024-10-29T11:17:14.696194Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'trained_model': File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"import gdown\nimport os\n\n# Create directory if it doesn't exist\nos.makedirs('embeddings', exist_ok=True)\n\n# https://drive.google.com/file/d/1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ/view?usp=sharing\n\n# Google Drive file ID\nfile_id = \"1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ\"\n\n# Download file to the specified directory\ngdown.download(f\"https://drive.google.com/uc?id={file_id}\", 'embeddings/glove.6B.50d.txt', quiet=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T11:17:14.699278Z","iopub.execute_input":"2024-10-29T11:17:14.699702Z","iopub.status.idle":"2024-10-29T11:17:21.700744Z","shell.execute_reply.started":"2024-10-29T11:17:14.699656Z","shell.execute_reply":"2024-10-29T11:17:21.699818Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ\nFrom (redirected): https://drive.google.com/uc?id=1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ&confirm=t&uuid=3c9e30be-df0b-45cc-b447-ae31be7809b7\nTo: /kaggle/working/embeddings/glove.6B.50d.txt\n100%|██████████| 171M/171M [00:02<00:00, 63.0MB/s] \n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'embeddings/glove.6B.50d.txt'"},"metadata":{}}]},{"cell_type":"code","source":"!bash /kaggle/working/train_prompt6_seed12.sh ","metadata":{"execution":{"iopub.status.busy":"2024-10-29T11:17:21.701970Z","iopub.execute_input":"2024-10-29T11:17:21.702447Z","iopub.status.idle":"2024-10-29T14:42:38.278669Z","shell.execute_reply.started":"2024-10-29T11:17:21.702414Z","shell.execute_reply":"2024-10-29T14:42:38.277548Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Test prompt id is 6 of type <class 'int'>\nSeed: 12\nNumhead :  2  | Features :  data/LDA/hand_crafted_final_6.csv  | Pos_emb :  50\n prompt_pos size: 8\n prompt_words size: 8\n pos_x size: 9498\n readability_x size: 9498\n pos_x size: 1678\n readability_x size: 1678\n pos_x size: 1800\n readability_x size: 1800\nLoading GloVe ...\nOOV number =204, OOV ratio = 0.051013\nmax sent length: 50\nmax sent num: 97\nmax prompt sent length: 18\nmax prompt sent num: 8\n================================\nX_train_pos:  (9498, 4850)\nX_train_prompt_words:  (9498, 4850)\nX_train_prompt_pos:  (9498, 4850)\nX_train_readability:  (9498, 35)\nX_train_ling:  (9498, 52)\nX_train_attribute_rel:  (9498, 9)\nY_train:  (9498, 9)\n================================\nX_dev_pos:  (1678, 4850)\nX_dev_prompt_words:  (1678, 4850)\nX_dev_prompt_pos:  (1678, 4850)\nX_dev_readability:  (1678, 35)\nX_dev_ling:  (1678, 52)\nX_dev_attribute_rel:  (1678, 9)\nY_dev:  (1678, 9)\n================================\nX_test_pos:  (1800, 4850)\nX_test_prompt_words:  (1800, 4850)\nX_test_prompt_pos:  (1800, 4850)\nX_test_readability:  (1800, 35)\nX_test_ling:  (1800, 52)\nX_test_attribute_rel:  (1800, 9)\nY_test:  (1800, 9)\n================================\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n\u001b[1mModel: \"functional_1\"\u001b[0m\n┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ prompt_word_input   │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_input    │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_input           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt (\u001b[94mEmbedding\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │    \u001b[32m200,000\u001b[0m │ prompt_word_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_1         │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ prompt_word_inpu… │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_prompt          │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │      \u001b[32m1,950\u001b[0m │ prompt_pos_input… │\n│ (\u001b[94mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_2         │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ prompt_pos_input… │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x (\u001b[94mEmbedding\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │      \u001b[32m1,950\u001b[0m │ pos_input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ pos_input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_maskedout    │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ prompt[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_maskedo… │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_prompt[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x_maskedout     │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_x[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (\u001b[94mAdd\u001b[0m)           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ prompt_maskedout… │\n│                     │                   │            │ prompt_pos_maske… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_drop_x          │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_x_maskedout[\u001b[32m…\u001b[0m │\n│ (\u001b[94mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_drop_x       │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ add[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]         │\n│ (\u001b[94mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_resh_W          │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m50\u001b[0m,    │          \u001b[32m0\u001b[0m │ pos_drop_x[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]  │\n│ (\u001b[94mReshape\u001b[0m)           │ \u001b[32m50\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_resh_W       │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m50\u001b[0m,    │          \u001b[32m0\u001b[0m │ prompt_drop_x[\u001b[32m0\u001b[0m]… │\n│ (\u001b[94mReshape\u001b[0m)           │ \u001b[32m50\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_zcnn            │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m46\u001b[0m,    │     \u001b[32m25,100\u001b[0m │ pos_resh_W[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]  │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │ \u001b[32m100\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_zcnn         │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m46\u001b[0m,    │     \u001b[32m25,100\u001b[0m │ prompt_resh_W[\u001b[32m0\u001b[0m]… │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │ \u001b[32m100\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_avg_zcnn        │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m100\u001b[0m)   │          \u001b[32m0\u001b[0m │ pos_zcnn[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_avg_zcnn     │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m100\u001b[0m)   │          \u001b[32m0\u001b[0m │ prompt_zcnn[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ prompt_avg_zcnn[\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (\u001b[94mLSTM\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_9 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_4 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_5 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_6 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_7 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_8 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_1         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]        │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_11        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_2         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_3         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_4         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_5         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_6         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_7         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_8         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_9         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_10 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_11 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_12 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_13 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_14 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_15 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_16 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_17 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_18 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_12        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_10[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ linguistic_input    │ (\u001b[96mNone\u001b[0m, \u001b[32m52\u001b[0m)        │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ readability_input   │ (\u001b[96mNone\u001b[0m, \u001b[32m35\u001b[0m)        │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_13        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_11[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_14        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_12[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_15        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_13[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_16        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_14[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_17        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_15[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_18        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_16[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_19        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_17[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_20        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_18[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_12[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_13[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_14[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_15[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_4       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_16[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_5       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_17[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_6       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_18[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_7       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_19[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_8       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_20[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (\u001b[94mLambda\u001b[0m)     │ (\u001b[96mNone\u001b[0m, \u001b[32m9\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ concatenate[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│                     │                   │            │ concatenate_1[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_2[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_3[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_4[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_5[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_6[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_7[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_8[\u001b[32m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (\u001b[94mGetItem\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_1 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_1          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_2 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_2          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_3 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_3          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_4 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_4          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_5 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_5          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_6 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_6          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_7 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_7          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_8 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_8          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_9 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_21        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_22        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_23        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_24        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_25        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_26        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_27        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_28        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_29        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_9       │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_21[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_10      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_22[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_11      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_23[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_12      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_24[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_13      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_25[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_14      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_26[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_15      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_27[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_16      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_28[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_17      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_29[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (\u001b[94mFlatten\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_9[\u001b[32m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_10[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_2 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_11[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_3 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_12[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_4 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_13[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_5 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_14[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_6 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_15[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_7 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_16[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_8 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_17[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_76 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_77 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_78 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_79 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_80 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_81 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_82 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_83 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_84 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_18      │ (\u001b[96mNone\u001b[0m, \u001b[32m9\u001b[0m)         │          \u001b[32m0\u001b[0m │ dense_76[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ dense_77[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_78[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_79[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_80[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_81[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_82[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_83[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_84[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n\u001b[1m Total params: \u001b[0m\u001b[32m2,552,675\u001b[0m (9.74 MB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,552,675\u001b[0m (9.74 MB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 409ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n/kaggle/working/metrics/metrics.py:190: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  ret_score = pearsonr(y_true, y_pred)[0]\n/kaggle/working/metrics/metrics.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  ret_score = spearmanr(y_true, y_pred)[0]\nCURRENT EPOCH: -1\n[DEV] AVG QWK: 0.035\n[DEV] score QWK: 0.028\n[DEV] content QWK: 0.045\n[DEV] organization QWK: 0.046\n[DEV] word_choice QWK: 0.07\n[DEV] sentence_fluency QWK: 0.043\n[DEV] conventions QWK: 0.004\n[DEV] prompt_adherence QWK: 0.025\n[DEV] language QWK: -0.04\n[DEV] narrativity QWK: 0.092\n------------------------\n[TEST] AVG QWK: 0.01\n[TEST] score QWK: 0.0\n[TEST] content QWK: 0.045\n[TEST] prompt_adherence QWK: -0.003\n[TEST] language QWK: 0.009\n[TEST] narrativity QWK: 0.0\n------------------------\n[BEST TEST] AVG QWK: 0.01, {epoch}: -1\n[BEST TEST] score QWK: 0.0\n[BEST TEST] content QWK: 0.045\n[BEST TEST] prompt_adherence QWK: -0.003\n[BEST TEST] language QWK: 0.009\n[BEST TEST] narrativity QWK: 0.0\n--------------------------------------------------------------------------------------------------------------------------\nEpoch 1/50\ntrait num:  9\ntrait num:  9\ntrait num:  9\nTraining one epoch in 369.416 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 1\n[DEV] AVG QWK: 0.598\n[DEV] score QWK: 0.713\n[DEV] content QWK: 0.586\n[DEV] organization QWK: 0.613\n[DEV] word_choice QWK: 0.595\n[DEV] sentence_fluency QWK: 0.551\n[DEV] conventions QWK: 0.572\n[DEV] prompt_adherence QWK: 0.582\n[DEV] language QWK: 0.579\n[DEV] narrativity QWK: 0.595\n------------------------\n[TEST] AVG QWK: 0.471\n[TEST] score QWK: 0.583\n[TEST] content QWK: 0.437\n[TEST] prompt_adherence QWK: 0.398\n[TEST] language QWK: 0.468\n[TEST] narrativity QWK: 0.468\n------------------------\n[BEST TEST] AVG QWK: 0.471, {epoch}: 1\n[BEST TEST] score QWK: 0.583\n[BEST TEST] content QWK: 0.437\n[BEST TEST] prompt_adherence QWK: 0.398\n[BEST TEST] language QWK: 0.468\n[BEST TEST] narrativity QWK: 0.468\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.016390947625041008 || Val Loss:  0.014300519600510597\nEpoch 2/50\nTraining one epoch in 230.633 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 2\n[DEV] AVG QWK: 0.636\n[DEV] score QWK: 0.729\n[DEV] content QWK: 0.624\n[DEV] organization QWK: 0.658\n[DEV] word_choice QWK: 0.631\n[DEV] sentence_fluency QWK: 0.591\n[DEV] conventions QWK: 0.632\n[DEV] prompt_adherence QWK: 0.617\n[DEV] language QWK: 0.616\n[DEV] narrativity QWK: 0.626\n------------------------\n[TEST] AVG QWK: 0.491\n[TEST] score QWK: 0.595\n[TEST] content QWK: 0.46\n[TEST] prompt_adherence QWK: 0.421\n[TEST] language QWK: 0.491\n[TEST] narrativity QWK: 0.49\n------------------------\n[BEST TEST] AVG QWK: 0.491, {epoch}: 2\n[BEST TEST] score QWK: 0.595\n[BEST TEST] content QWK: 0.46\n[BEST TEST] prompt_adherence QWK: 0.421\n[BEST TEST] language QWK: 0.491\n[BEST TEST] narrativity QWK: 0.49\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.013616702519357204 || Val Loss:  0.01347722765058279\nEpoch 3/50\nTraining one epoch in 228.237 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 3\n[DEV] AVG QWK: 0.651\n[DEV] score QWK: 0.737\n[DEV] content QWK: 0.64\n[DEV] organization QWK: 0.675\n[DEV] word_choice QWK: 0.643\n[DEV] sentence_fluency QWK: 0.608\n[DEV] conventions QWK: 0.658\n[DEV] prompt_adherence QWK: 0.631\n[DEV] language QWK: 0.631\n[DEV] narrativity QWK: 0.639\n------------------------\n[TEST] AVG QWK: 0.504\n[TEST] score QWK: 0.601\n[TEST] content QWK: 0.478\n[TEST] prompt_adherence QWK: 0.436\n[TEST] language QWK: 0.506\n[TEST] narrativity QWK: 0.497\n------------------------\n[BEST TEST] AVG QWK: 0.504, {epoch}: 3\n[BEST TEST] score QWK: 0.601\n[BEST TEST] content QWK: 0.478\n[BEST TEST] prompt_adherence QWK: 0.436\n[BEST TEST] language QWK: 0.506\n[BEST TEST] narrativity QWK: 0.497\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01306825503706932 || Val Loss:  0.01306201983243227\nEpoch 4/50\nTraining one epoch in 227.264 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step\nCURRENT EPOCH: 4\n[DEV] AVG QWK: 0.661\n[DEV] score QWK: 0.742\n[DEV] content QWK: 0.65\n[DEV] organization QWK: 0.685\n[DEV] word_choice QWK: 0.651\n[DEV] sentence_fluency QWK: 0.619\n[DEV] conventions QWK: 0.672\n[DEV] prompt_adherence QWK: 0.641\n[DEV] language QWK: 0.642\n[DEV] narrativity QWK: 0.647\n------------------------\n[TEST] AVG QWK: 0.51\n[TEST] score QWK: 0.602\n[TEST] content QWK: 0.48\n[TEST] prompt_adherence QWK: 0.448\n[TEST] language QWK: 0.514\n[TEST] narrativity QWK: 0.507\n------------------------\n[BEST TEST] AVG QWK: 0.51, {epoch}: 4\n[BEST TEST] score QWK: 0.602\n[BEST TEST] content QWK: 0.48\n[BEST TEST] prompt_adherence QWK: 0.448\n[BEST TEST] language QWK: 0.514\n[BEST TEST] narrativity QWK: 0.507\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012761291116476059 || Val Loss:  0.012798109091818333\nEpoch 5/50\nTraining one epoch in 227.700 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 5\n[DEV] AVG QWK: 0.668\n[DEV] score QWK: 0.746\n[DEV] content QWK: 0.658\n[DEV] organization QWK: 0.693\n[DEV] word_choice QWK: 0.656\n[DEV] sentence_fluency QWK: 0.625\n[DEV] conventions QWK: 0.682\n[DEV] prompt_adherence QWK: 0.649\n[DEV] language QWK: 0.649\n[DEV] narrativity QWK: 0.655\n------------------------\n[TEST] AVG QWK: 0.517\n[TEST] score QWK: 0.604\n[TEST] content QWK: 0.489\n[TEST] prompt_adherence QWK: 0.454\n[TEST] language QWK: 0.523\n[TEST] narrativity QWK: 0.513\n------------------------\n[BEST TEST] AVG QWK: 0.517, {epoch}: 5\n[BEST TEST] score QWK: 0.604\n[BEST TEST] content QWK: 0.489\n[BEST TEST] prompt_adherence QWK: 0.454\n[BEST TEST] language QWK: 0.523\n[BEST TEST] narrativity QWK: 0.513\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012556797824800014 || Val Loss:  0.012611748650670052\nEpoch 6/50\nTraining one epoch in 227.821 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 6\n[DEV] AVG QWK: 0.673\n[DEV] score QWK: 0.749\n[DEV] content QWK: 0.664\n[DEV] organization QWK: 0.697\n[DEV] word_choice QWK: 0.66\n[DEV] sentence_fluency QWK: 0.63\n[DEV] conventions QWK: 0.689\n[DEV] prompt_adherence QWK: 0.654\n[DEV] language QWK: 0.654\n[DEV] narrativity QWK: 0.659\n------------------------\n[TEST] AVG QWK: 0.521\n[TEST] score QWK: 0.606\n[TEST] content QWK: 0.49\n[TEST] prompt_adherence QWK: 0.462\n[TEST] language QWK: 0.529\n[TEST] narrativity QWK: 0.52\n------------------------\n[BEST TEST] AVG QWK: 0.521, {epoch}: 6\n[BEST TEST] score QWK: 0.606\n[BEST TEST] content QWK: 0.49\n[BEST TEST] prompt_adherence QWK: 0.462\n[BEST TEST] language QWK: 0.529\n[BEST TEST] narrativity QWK: 0.52\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012407814152538776 || Val Loss:  0.012471513822674751\nEpoch 7/50\nTraining one epoch in 227.881 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 7\n[DEV] AVG QWK: 0.677\n[DEV] score QWK: 0.751\n[DEV] content QWK: 0.667\n[DEV] organization QWK: 0.7\n[DEV] word_choice QWK: 0.664\n[DEV] sentence_fluency QWK: 0.634\n[DEV] conventions QWK: 0.694\n[DEV] prompt_adherence QWK: 0.658\n[DEV] language QWK: 0.659\n[DEV] narrativity QWK: 0.663\n------------------------\n[TEST] AVG QWK: 0.527\n[TEST] score QWK: 0.611\n[TEST] content QWK: 0.496\n[TEST] prompt_adherence QWK: 0.468\n[TEST] language QWK: 0.532\n[TEST] narrativity QWK: 0.528\n------------------------\n[BEST TEST] AVG QWK: 0.527, {epoch}: 7\n[BEST TEST] score QWK: 0.611\n[BEST TEST] content QWK: 0.496\n[BEST TEST] prompt_adherence QWK: 0.468\n[BEST TEST] language QWK: 0.532\n[BEST TEST] narrativity QWK: 0.528\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012292931787669659 || Val Loss:  0.012361305765807629\nEpoch 8/50\nTraining one epoch in 227.376 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step\nCURRENT EPOCH: 8\n[DEV] AVG QWK: 0.68\n[DEV] score QWK: 0.753\n[DEV] content QWK: 0.671\n[DEV] organization QWK: 0.703\n[DEV] word_choice QWK: 0.665\n[DEV] sentence_fluency QWK: 0.637\n[DEV] conventions QWK: 0.698\n[DEV] prompt_adherence QWK: 0.662\n[DEV] language QWK: 0.662\n[DEV] narrativity QWK: 0.666\n------------------------\n[TEST] AVG QWK: 0.531\n[TEST] score QWK: 0.613\n[TEST] content QWK: 0.5\n[TEST] prompt_adherence QWK: 0.474\n[TEST] language QWK: 0.534\n[TEST] narrativity QWK: 0.532\n------------------------\n[BEST TEST] AVG QWK: 0.531, {epoch}: 8\n[BEST TEST] score QWK: 0.613\n[BEST TEST] content QWK: 0.5\n[BEST TEST] prompt_adherence QWK: 0.474\n[BEST TEST] language QWK: 0.534\n[BEST TEST] narrativity QWK: 0.532\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012200800701975822 || Val Loss:  0.012271911837160587\nEpoch 9/50\nTraining one epoch in 226.735 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 9\n[DEV] AVG QWK: 0.682\n[DEV] score QWK: 0.755\n[DEV] content QWK: 0.673\n[DEV] organization QWK: 0.705\n[DEV] word_choice QWK: 0.669\n[DEV] sentence_fluency QWK: 0.639\n[DEV] conventions QWK: 0.701\n[DEV] prompt_adherence QWK: 0.665\n[DEV] language QWK: 0.665\n[DEV] narrativity QWK: 0.669\n------------------------\n[TEST] AVG QWK: 0.533\n[TEST] score QWK: 0.616\n[TEST] content QWK: 0.501\n[TEST] prompt_adherence QWK: 0.48\n[TEST] language QWK: 0.535\n[TEST] narrativity QWK: 0.534\n------------------------\n[BEST TEST] AVG QWK: 0.533, {epoch}: 9\n[BEST TEST] score QWK: 0.616\n[BEST TEST] content QWK: 0.501\n[BEST TEST] prompt_adherence QWK: 0.48\n[BEST TEST] language QWK: 0.535\n[BEST TEST] narrativity QWK: 0.534\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012124786153435707 || Val Loss:  0.012197657488286495\nEpoch 10/50\nTraining one epoch in 227.841 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 10\n[DEV] AVG QWK: 0.685\n[DEV] score QWK: 0.756\n[DEV] content QWK: 0.676\n[DEV] organization QWK: 0.707\n[DEV] word_choice QWK: 0.67\n[DEV] sentence_fluency QWK: 0.643\n[DEV] conventions QWK: 0.704\n[DEV] prompt_adherence QWK: 0.667\n[DEV] language QWK: 0.668\n[DEV] narrativity QWK: 0.67\n------------------------\n[TEST] AVG QWK: 0.536\n[TEST] score QWK: 0.613\n[TEST] content QWK: 0.507\n[TEST] prompt_adherence QWK: 0.485\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.539\n------------------------\n[BEST TEST] AVG QWK: 0.536, {epoch}: 10\n[BEST TEST] score QWK: 0.613\n[BEST TEST] content QWK: 0.507\n[BEST TEST] prompt_adherence QWK: 0.485\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.539\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012060760520398617 || Val Loss:  0.012134809046983719\nEpoch 11/50\nTraining one epoch in 227.227 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 11\n[DEV] AVG QWK: 0.686\n[DEV] score QWK: 0.757\n[DEV] content QWK: 0.679\n[DEV] organization QWK: 0.709\n[DEV] word_choice QWK: 0.671\n[DEV] sentence_fluency QWK: 0.644\n[DEV] conventions QWK: 0.707\n[DEV] prompt_adherence QWK: 0.669\n[DEV] language QWK: 0.669\n[DEV] narrativity QWK: 0.672\n------------------------\n[TEST] AVG QWK: 0.54\n[TEST] score QWK: 0.615\n[TEST] content QWK: 0.513\n[TEST] prompt_adherence QWK: 0.493\n[TEST] language QWK: 0.538\n[TEST] narrativity QWK: 0.543\n------------------------\n[BEST TEST] AVG QWK: 0.54, {epoch}: 11\n[BEST TEST] score QWK: 0.615\n[BEST TEST] content QWK: 0.513\n[BEST TEST] prompt_adherence QWK: 0.493\n[BEST TEST] language QWK: 0.538\n[BEST TEST] narrativity QWK: 0.543\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012005929835140705 || Val Loss:  0.012080836109817028\nEpoch 12/50\nTraining one epoch in 226.823 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 12\n[DEV] AVG QWK: 0.688\n[DEV] score QWK: 0.758\n[DEV] content QWK: 0.68\n[DEV] organization QWK: 0.71\n[DEV] word_choice QWK: 0.673\n[DEV] sentence_fluency QWK: 0.646\n[DEV] conventions QWK: 0.708\n[DEV] prompt_adherence QWK: 0.671\n[DEV] language QWK: 0.671\n[DEV] narrativity QWK: 0.675\n------------------------\n[TEST] AVG QWK: 0.542\n[TEST] score QWK: 0.617\n[TEST] content QWK: 0.514\n[TEST] prompt_adherence QWK: 0.497\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.547\n------------------------\n[BEST TEST] AVG QWK: 0.542, {epoch}: 12\n[BEST TEST] score QWK: 0.617\n[BEST TEST] content QWK: 0.514\n[BEST TEST] prompt_adherence QWK: 0.497\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.547\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01195837277919054 || Val Loss:  0.012033912353217602\nEpoch 13/50\nTraining one epoch in 228.168 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 13\n[DEV] AVG QWK: 0.69\n[DEV] score QWK: 0.759\n[DEV] content QWK: 0.682\n[DEV] organization QWK: 0.712\n[DEV] word_choice QWK: 0.673\n[DEV] sentence_fluency QWK: 0.648\n[DEV] conventions QWK: 0.711\n[DEV] prompt_adherence QWK: 0.673\n[DEV] language QWK: 0.673\n[DEV] narrativity QWK: 0.676\n------------------------\n[TEST] AVG QWK: 0.546\n[TEST] score QWK: 0.618\n[TEST] content QWK: 0.514\n[TEST] prompt_adherence QWK: 0.506\n[TEST] language QWK: 0.545\n[TEST] narrativity QWK: 0.549\n------------------------\n[BEST TEST] AVG QWK: 0.546, {epoch}: 13\n[BEST TEST] score QWK: 0.618\n[BEST TEST] content QWK: 0.514\n[BEST TEST] prompt_adherence QWK: 0.506\n[BEST TEST] language QWK: 0.545\n[BEST TEST] narrativity QWK: 0.549\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011916727758944035 || Val Loss:  0.011992723681032658\nEpoch 14/50\nTraining one epoch in 226.288 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 14\n[DEV] AVG QWK: 0.691\n[DEV] score QWK: 0.76\n[DEV] content QWK: 0.683\n[DEV] organization QWK: 0.713\n[DEV] word_choice QWK: 0.675\n[DEV] sentence_fluency QWK: 0.649\n[DEV] conventions QWK: 0.712\n[DEV] prompt_adherence QWK: 0.675\n[DEV] language QWK: 0.675\n[DEV] narrativity QWK: 0.677\n------------------------\n[TEST] AVG QWK: 0.55\n[TEST] score QWK: 0.62\n[TEST] content QWK: 0.515\n[TEST] prompt_adherence QWK: 0.509\n[TEST] language QWK: 0.55\n[TEST] narrativity QWK: 0.554\n------------------------\n[BEST TEST] AVG QWK: 0.55, {epoch}: 14\n[BEST TEST] score QWK: 0.62\n[BEST TEST] content QWK: 0.515\n[BEST TEST] prompt_adherence QWK: 0.509\n[BEST TEST] language QWK: 0.55\n[BEST TEST] narrativity QWK: 0.554\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011879914440214634 || Val Loss:  0.011956256814301014\nEpoch 15/50\nTraining one epoch in 226.239 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 15\n[DEV] AVG QWK: 0.692\n[DEV] score QWK: 0.761\n[DEV] content QWK: 0.685\n[DEV] organization QWK: 0.714\n[DEV] word_choice QWK: 0.676\n[DEV] sentence_fluency QWK: 0.65\n[DEV] conventions QWK: 0.715\n[DEV] prompt_adherence QWK: 0.677\n[DEV] language QWK: 0.676\n[DEV] narrativity QWK: 0.678\n------------------------\n[TEST] AVG QWK: 0.552\n[TEST] score QWK: 0.62\n[TEST] content QWK: 0.516\n[TEST] prompt_adherence QWK: 0.51\n[TEST] language QWK: 0.554\n[TEST] narrativity QWK: 0.559\n------------------------\n[BEST TEST] AVG QWK: 0.552, {epoch}: 15\n[BEST TEST] score QWK: 0.62\n[BEST TEST] content QWK: 0.516\n[BEST TEST] prompt_adherence QWK: 0.51\n[BEST TEST] language QWK: 0.554\n[BEST TEST] narrativity QWK: 0.559\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011847171932458878 || Val Loss:  0.011923741549253464\nEpoch 16/50\nTraining one epoch in 227.358 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 16\n[DEV] AVG QWK: 0.694\n[DEV] score QWK: 0.761\n[DEV] content QWK: 0.685\n[DEV] organization QWK: 0.716\n[DEV] word_choice QWK: 0.678\n[DEV] sentence_fluency QWK: 0.651\n[DEV] conventions QWK: 0.716\n[DEV] prompt_adherence QWK: 0.678\n[DEV] language QWK: 0.677\n[DEV] narrativity QWK: 0.68\n------------------------\n[TEST] AVG QWK: 0.553\n[TEST] score QWK: 0.619\n[TEST] content QWK: 0.517\n[TEST] prompt_adherence QWK: 0.513\n[TEST] language QWK: 0.556\n[TEST] narrativity QWK: 0.559\n------------------------\n[BEST TEST] AVG QWK: 0.553, {epoch}: 16\n[BEST TEST] score QWK: 0.619\n[BEST TEST] content QWK: 0.517\n[BEST TEST] prompt_adherence QWK: 0.513\n[BEST TEST] language QWK: 0.556\n[BEST TEST] narrativity QWK: 0.559\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01181783527135849 || Val Loss:  0.011894562281668186\nEpoch 17/50\nTraining one epoch in 227.255 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 17\n[DEV] AVG QWK: 0.694\n[DEV] score QWK: 0.762\n[DEV] content QWK: 0.686\n[DEV] organization QWK: 0.717\n[DEV] word_choice QWK: 0.678\n[DEV] sentence_fluency QWK: 0.652\n[DEV] conventions QWK: 0.716\n[DEV] prompt_adherence QWK: 0.678\n[DEV] language QWK: 0.677\n[DEV] narrativity QWK: 0.681\n------------------------\n[TEST] AVG QWK: 0.557\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.52\n[TEST] prompt_adherence QWK: 0.517\n[TEST] language QWK: 0.562\n[TEST] narrativity QWK: 0.565\n------------------------\n[BEST TEST] AVG QWK: 0.557, {epoch}: 17\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.52\n[BEST TEST] prompt_adherence QWK: 0.517\n[BEST TEST] language QWK: 0.562\n[BEST TEST] narrativity QWK: 0.565\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011791438795626163 || Val Loss:  0.011868244968354702\nEpoch 18/50\nTraining one epoch in 225.984 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step\nCURRENT EPOCH: 18\n[DEV] AVG QWK: 0.695\n[DEV] score QWK: 0.763\n[DEV] content QWK: 0.687\n[DEV] organization QWK: 0.717\n[DEV] word_choice QWK: 0.678\n[DEV] sentence_fluency QWK: 0.654\n[DEV] conventions QWK: 0.716\n[DEV] prompt_adherence QWK: 0.679\n[DEV] language QWK: 0.678\n[DEV] narrativity QWK: 0.681\n------------------------\n[TEST] AVG QWK: 0.556\n[TEST] score QWK: 0.617\n[TEST] content QWK: 0.519\n[TEST] prompt_adherence QWK: 0.516\n[TEST] language QWK: 0.563\n[TEST] narrativity QWK: 0.566\n------------------------\n[BEST TEST] AVG QWK: 0.556, {epoch}: 18\n[BEST TEST] score QWK: 0.617\n[BEST TEST] content QWK: 0.519\n[BEST TEST] prompt_adherence QWK: 0.516\n[BEST TEST] language QWK: 0.563\n[BEST TEST] narrativity QWK: 0.566\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01176756713539362 || Val Loss:  0.011844394728541374\nEpoch 19/50\nTraining one epoch in 224.889 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 19\n[DEV] AVG QWK: 0.696\n[DEV] score QWK: 0.763\n[DEV] content QWK: 0.688\n[DEV] organization QWK: 0.718\n[DEV] word_choice QWK: 0.68\n[DEV] sentence_fluency QWK: 0.656\n[DEV] conventions QWK: 0.719\n[DEV] prompt_adherence QWK: 0.68\n[DEV] language QWK: 0.68\n[DEV] narrativity QWK: 0.681\n------------------------\n[TEST] AVG QWK: 0.558\n[TEST] score QWK: 0.616\n[TEST] content QWK: 0.52\n[TEST] prompt_adherence QWK: 0.52\n[TEST] language QWK: 0.564\n[TEST] narrativity QWK: 0.569\n------------------------\n[BEST TEST] AVG QWK: 0.558, {epoch}: 19\n[BEST TEST] score QWK: 0.616\n[BEST TEST] content QWK: 0.52\n[BEST TEST] prompt_adherence QWK: 0.52\n[BEST TEST] language QWK: 0.564\n[BEST TEST] narrativity QWK: 0.569\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011745859868824482 || Val Loss:  0.011822673492133617\nEpoch 20/50\nTraining one epoch in 226.935 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 20\n[DEV] AVG QWK: 0.697\n[DEV] score QWK: 0.763\n[DEV] content QWK: 0.689\n[DEV] organization QWK: 0.719\n[DEV] word_choice QWK: 0.681\n[DEV] sentence_fluency QWK: 0.656\n[DEV] conventions QWK: 0.72\n[DEV] prompt_adherence QWK: 0.68\n[DEV] language QWK: 0.681\n[DEV] narrativity QWK: 0.683\n------------------------\n[TEST] AVG QWK: 0.559\n[TEST] score QWK: 0.617\n[TEST] content QWK: 0.52\n[TEST] prompt_adherence QWK: 0.521\n[TEST] language QWK: 0.568\n[TEST] narrativity QWK: 0.569\n------------------------\n[BEST TEST] AVG QWK: 0.559, {epoch}: 20\n[BEST TEST] score QWK: 0.617\n[BEST TEST] content QWK: 0.52\n[BEST TEST] prompt_adherence QWK: 0.521\n[BEST TEST] language QWK: 0.568\n[BEST TEST] narrativity QWK: 0.569\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011726082302629948 || Val Loss:  0.011802822351455688\nEpoch 21/50\nTraining one epoch in 225.632 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 21\n[DEV] AVG QWK: 0.697\n[DEV] score QWK: 0.763\n[DEV] content QWK: 0.69\n[DEV] organization QWK: 0.719\n[DEV] word_choice QWK: 0.682\n[DEV] sentence_fluency QWK: 0.656\n[DEV] conventions QWK: 0.721\n[DEV] prompt_adherence QWK: 0.681\n[DEV] language QWK: 0.681\n[DEV] narrativity QWK: 0.683\n------------------------\n[TEST] AVG QWK: 0.56\n[TEST] score QWK: 0.616\n[TEST] content QWK: 0.522\n[TEST] prompt_adherence QWK: 0.522\n[TEST] language QWK: 0.569\n[TEST] narrativity QWK: 0.57\n------------------------\n[BEST TEST] AVG QWK: 0.56, {epoch}: 21\n[BEST TEST] score QWK: 0.616\n[BEST TEST] content QWK: 0.522\n[BEST TEST] prompt_adherence QWK: 0.522\n[BEST TEST] language QWK: 0.569\n[BEST TEST] narrativity QWK: 0.57\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011707963421940804 || Val Loss:  0.011784628964960575\nEpoch 22/50\nTraining one epoch in 225.181 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 22\n[DEV] AVG QWK: 0.698\n[DEV] score QWK: 0.763\n[DEV] content QWK: 0.691\n[DEV] organization QWK: 0.72\n[DEV] word_choice QWK: 0.683\n[DEV] sentence_fluency QWK: 0.657\n[DEV] conventions QWK: 0.721\n[DEV] prompt_adherence QWK: 0.682\n[DEV] language QWK: 0.682\n[DEV] narrativity QWK: 0.684\n------------------------\n[TEST] AVG QWK: 0.561\n[TEST] score QWK: 0.616\n[TEST] content QWK: 0.524\n[TEST] prompt_adherence QWK: 0.523\n[TEST] language QWK: 0.571\n[TEST] narrativity QWK: 0.571\n------------------------\n[BEST TEST] AVG QWK: 0.561, {epoch}: 22\n[BEST TEST] score QWK: 0.616\n[BEST TEST] content QWK: 0.524\n[BEST TEST] prompt_adherence QWK: 0.523\n[BEST TEST] language QWK: 0.571\n[BEST TEST] narrativity QWK: 0.571\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011691313236951828 || Val Loss:  0.011767880991101265\nEpoch 23/50\nTraining one epoch in 226.253 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 23\n[DEV] AVG QWK: 0.699\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.691\n[DEV] organization QWK: 0.721\n[DEV] word_choice QWK: 0.683\n[DEV] sentence_fluency QWK: 0.658\n[DEV] conventions QWK: 0.723\n[DEV] prompt_adherence QWK: 0.683\n[DEV] language QWK: 0.682\n[DEV] narrativity QWK: 0.685\n------------------------\n[TEST] AVG QWK: 0.561\n[TEST] score QWK: 0.617\n[TEST] content QWK: 0.524\n[TEST] prompt_adherence QWK: 0.524\n[TEST] language QWK: 0.568\n[TEST] narrativity QWK: 0.574\n------------------------\n[BEST TEST] AVG QWK: 0.561, {epoch}: 23\n[BEST TEST] score QWK: 0.617\n[BEST TEST] content QWK: 0.524\n[BEST TEST] prompt_adherence QWK: 0.524\n[BEST TEST] language QWK: 0.568\n[BEST TEST] narrativity QWK: 0.574\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011675983667373657 || Val Loss:  0.011752426624298096\nEpoch 24/50\nTraining one epoch in 225.502 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 24\n[DEV] AVG QWK: 0.699\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.692\n[DEV] organization QWK: 0.721\n[DEV] word_choice QWK: 0.684\n[DEV] sentence_fluency QWK: 0.659\n[DEV] conventions QWK: 0.723\n[DEV] prompt_adherence QWK: 0.683\n[DEV] language QWK: 0.683\n[DEV] narrativity QWK: 0.685\n------------------------\n[TEST] AVG QWK: 0.562\n[TEST] score QWK: 0.618\n[TEST] content QWK: 0.525\n[TEST] prompt_adherence QWK: 0.526\n[TEST] language QWK: 0.571\n[TEST] narrativity QWK: 0.571\n------------------------\n[BEST TEST] AVG QWK: 0.562, {epoch}: 24\n[BEST TEST] score QWK: 0.618\n[BEST TEST] content QWK: 0.525\n[BEST TEST] prompt_adherence QWK: 0.526\n[BEST TEST] language QWK: 0.571\n[BEST TEST] narrativity QWK: 0.571\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011661813594400883 || Val Loss:  0.011738128960132599\nEpoch 25/50\nTraining one epoch in 226.837 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 25\n[DEV] AVG QWK: 0.7\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.692\n[DEV] organization QWK: 0.722\n[DEV] word_choice QWK: 0.684\n[DEV] sentence_fluency QWK: 0.661\n[DEV] conventions QWK: 0.723\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.683\n[DEV] narrativity QWK: 0.686\n------------------------\n[TEST] AVG QWK: 0.564\n[TEST] score QWK: 0.619\n[TEST] content QWK: 0.527\n[TEST] prompt_adherence QWK: 0.528\n[TEST] language QWK: 0.573\n[TEST] narrativity QWK: 0.571\n------------------------\n[BEST TEST] AVG QWK: 0.564, {epoch}: 25\n[BEST TEST] score QWK: 0.619\n[BEST TEST] content QWK: 0.527\n[BEST TEST] prompt_adherence QWK: 0.528\n[BEST TEST] language QWK: 0.573\n[BEST TEST] narrativity QWK: 0.571\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.0116486931219697 || Val Loss:  0.011724868789315224\nEpoch 26/50\nTraining one epoch in 224.675 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 26\n[DEV] AVG QWK: 0.7\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.693\n[DEV] organization QWK: 0.723\n[DEV] word_choice QWK: 0.684\n[DEV] sentence_fluency QWK: 0.661\n[DEV] conventions QWK: 0.724\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.684\n[DEV] narrativity QWK: 0.687\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.62\n[TEST] content QWK: 0.527\n[TEST] prompt_adherence QWK: 0.528\n[TEST] language QWK: 0.575\n[TEST] narrativity QWK: 0.575\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 26\n[BEST TEST] score QWK: 0.62\n[BEST TEST] content QWK: 0.527\n[BEST TEST] prompt_adherence QWK: 0.528\n[BEST TEST] language QWK: 0.575\n[BEST TEST] narrativity QWK: 0.575\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011636493727564812 || Val Loss:  0.011712534353137016\nEpoch 27/50\nTraining one epoch in 223.972 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 27\n[DEV] AVG QWK: 0.701\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.693\n[DEV] organization QWK: 0.723\n[DEV] word_choice QWK: 0.685\n[DEV] sentence_fluency QWK: 0.661\n[DEV] conventions QWK: 0.724\n[DEV] prompt_adherence QWK: 0.685\n[DEV] language QWK: 0.684\n[DEV] narrativity QWK: 0.688\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.526\n[TEST] prompt_adherence QWK: 0.529\n[TEST] language QWK: 0.574\n[TEST] narrativity QWK: 0.576\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 27\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.526\n[BEST TEST] prompt_adherence QWK: 0.529\n[BEST TEST] language QWK: 0.574\n[BEST TEST] narrativity QWK: 0.576\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011625133454799652 || Val Loss:  0.011701044626533985\nEpoch 28/50\nTraining one epoch in 226.134 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 28\n[DEV] AVG QWK: 0.701\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.693\n[DEV] organization QWK: 0.723\n[DEV] word_choice QWK: 0.685\n[DEV] sentence_fluency QWK: 0.662\n[DEV] conventions QWK: 0.725\n[DEV] prompt_adherence QWK: 0.685\n[DEV] language QWK: 0.684\n[DEV] narrativity QWK: 0.688\n------------------------\n[TEST] AVG QWK: 0.567\n[TEST] score QWK: 0.62\n[TEST] content QWK: 0.526\n[TEST] prompt_adherence QWK: 0.532\n[TEST] language QWK: 0.574\n[TEST] narrativity QWK: 0.58\n------------------------\n[BEST TEST] AVG QWK: 0.567, {epoch}: 28\n[BEST TEST] score QWK: 0.62\n[BEST TEST] content QWK: 0.526\n[BEST TEST] prompt_adherence QWK: 0.532\n[BEST TEST] language QWK: 0.574\n[BEST TEST] narrativity QWK: 0.58\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011614544317126274 || Val Loss:  0.01169031672179699\nEpoch 29/50\nTraining one epoch in 227.912 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 29\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.693\n[DEV] organization QWK: 0.724\n[DEV] word_choice QWK: 0.686\n[DEV] sentence_fluency QWK: 0.662\n[DEV] conventions QWK: 0.725\n[DEV] prompt_adherence QWK: 0.685\n[DEV] language QWK: 0.685\n[DEV] narrativity QWK: 0.689\n------------------------\n[TEST] AVG QWK: 0.567\n[TEST] score QWK: 0.62\n[TEST] content QWK: 0.525\n[TEST] prompt_adherence QWK: 0.534\n[TEST] language QWK: 0.574\n[TEST] narrativity QWK: 0.581\n------------------------\n[BEST TEST] AVG QWK: 0.567, {epoch}: 29\n[BEST TEST] score QWK: 0.62\n[BEST TEST] content QWK: 0.525\n[BEST TEST] prompt_adherence QWK: 0.534\n[BEST TEST] language QWK: 0.574\n[BEST TEST] narrativity QWK: 0.581\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01160462200641632 || Val Loss:  0.011680285446345806\nEpoch 30/50\nTraining one epoch in 226.885 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 30\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.694\n[DEV] organization QWK: 0.724\n[DEV] word_choice QWK: 0.687\n[DEV] sentence_fluency QWK: 0.662\n[DEV] conventions QWK: 0.726\n[DEV] prompt_adherence QWK: 0.686\n[DEV] language QWK: 0.685\n[DEV] narrativity QWK: 0.689\n------------------------\n[TEST] AVG QWK: 0.567\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.527\n[TEST] prompt_adherence QWK: 0.535\n[TEST] language QWK: 0.574\n[TEST] narrativity QWK: 0.58\n------------------------\n[BEST TEST] AVG QWK: 0.567, {epoch}: 30\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.527\n[BEST TEST] prompt_adherence QWK: 0.535\n[BEST TEST] language QWK: 0.574\n[BEST TEST] narrativity QWK: 0.58\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011595344170928001 || Val Loss:  0.011670880950987339\nEpoch 31/50\nTraining one epoch in 225.100 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 31\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.694\n[DEV] organization QWK: 0.724\n[DEV] word_choice QWK: 0.688\n[DEV] sentence_fluency QWK: 0.663\n[DEV] conventions QWK: 0.726\n[DEV] prompt_adherence QWK: 0.686\n[DEV] language QWK: 0.686\n[DEV] narrativity QWK: 0.689\n------------------------\n[TEST] AVG QWK: 0.568\n[TEST] score QWK: 0.622\n[TEST] content QWK: 0.527\n[TEST] prompt_adherence QWK: 0.537\n[TEST] language QWK: 0.574\n[TEST] narrativity QWK: 0.582\n------------------------\n[BEST TEST] AVG QWK: 0.568, {epoch}: 31\n[BEST TEST] score QWK: 0.622\n[BEST TEST] content QWK: 0.527\n[BEST TEST] prompt_adherence QWK: 0.537\n[BEST TEST] language QWK: 0.574\n[BEST TEST] narrativity QWK: 0.582\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011586626060307026 || Val Loss:  0.011662045493721962\nEpoch 32/50\nTraining one epoch in 223.815 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step\nCURRENT EPOCH: 32\n[DEV] AVG QWK: 0.703\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.695\n[DEV] organization QWK: 0.724\n[DEV] word_choice QWK: 0.688\n[DEV] sentence_fluency QWK: 0.664\n[DEV] conventions QWK: 0.727\n[DEV] prompt_adherence QWK: 0.687\n[DEV] language QWK: 0.686\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.57\n[TEST] score QWK: 0.623\n[TEST] content QWK: 0.528\n[TEST] prompt_adherence QWK: 0.539\n[TEST] language QWK: 0.573\n[TEST] narrativity QWK: 0.585\n------------------------\n[BEST TEST] AVG QWK: 0.57, {epoch}: 32\n[BEST TEST] score QWK: 0.623\n[BEST TEST] content QWK: 0.528\n[BEST TEST] prompt_adherence QWK: 0.539\n[BEST TEST] language QWK: 0.573\n[BEST TEST] narrativity QWK: 0.585\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011578432284295559 || Val Loss:  0.011653744615614414\nEpoch 33/50\nTraining one epoch in 223.632 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 33\n[DEV] AVG QWK: 0.703\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.695\n[DEV] organization QWK: 0.725\n[DEV] word_choice QWK: 0.688\n[DEV] sentence_fluency QWK: 0.664\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.687\n[DEV] language QWK: 0.687\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.571\n[TEST] score QWK: 0.622\n[TEST] content QWK: 0.53\n[TEST] prompt_adherence QWK: 0.54\n[TEST] language QWK: 0.576\n[TEST] narrativity QWK: 0.584\n------------------------\n[BEST TEST] AVG QWK: 0.571, {epoch}: 33\n[BEST TEST] score QWK: 0.622\n[BEST TEST] content QWK: 0.53\n[BEST TEST] prompt_adherence QWK: 0.54\n[BEST TEST] language QWK: 0.576\n[BEST TEST] narrativity QWK: 0.584\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011570707894861698 || Val Loss:  0.011645929887890816\nEpoch 34/50\nTraining one epoch in 224.514 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 34\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.696\n[DEV] organization QWK: 0.725\n[DEV] word_choice QWK: 0.689\n[DEV] sentence_fluency QWK: 0.665\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.687\n[DEV] language QWK: 0.687\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.572\n[TEST] score QWK: 0.624\n[TEST] content QWK: 0.532\n[TEST] prompt_adherence QWK: 0.544\n[TEST] language QWK: 0.574\n[TEST] narrativity QWK: 0.585\n------------------------\n[BEST TEST] AVG QWK: 0.572, {epoch}: 34\n[BEST TEST] score QWK: 0.624\n[BEST TEST] content QWK: 0.532\n[BEST TEST] prompt_adherence QWK: 0.544\n[BEST TEST] language QWK: 0.574\n[BEST TEST] narrativity QWK: 0.585\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011563424952328205 || Val Loss:  0.01163855753839016\nEpoch 35/50\nTraining one epoch in 224.463 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 35\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.696\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.689\n[DEV] sentence_fluency QWK: 0.665\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.688\n[DEV] language QWK: 0.687\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.572\n[TEST] score QWK: 0.624\n[TEST] content QWK: 0.533\n[TEST] prompt_adherence QWK: 0.543\n[TEST] language QWK: 0.576\n[TEST] narrativity QWK: 0.586\n------------------------\n[BEST TEST] AVG QWK: 0.572, {epoch}: 35\n[BEST TEST] score QWK: 0.624\n[BEST TEST] content QWK: 0.533\n[BEST TEST] prompt_adherence QWK: 0.543\n[BEST TEST] language QWK: 0.576\n[BEST TEST] narrativity QWK: 0.586\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011556550860404968 || Val Loss:  0.011631594970822334\nEpoch 36/50\nTraining one epoch in 225.327 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 36\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.696\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.689\n[DEV] sentence_fluency QWK: 0.666\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.688\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.573\n[TEST] score QWK: 0.624\n[TEST] content QWK: 0.532\n[TEST] prompt_adherence QWK: 0.543\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.588\n------------------------\n[BEST TEST] AVG QWK: 0.573, {epoch}: 36\n[BEST TEST] score QWK: 0.624\n[BEST TEST] content QWK: 0.532\n[BEST TEST] prompt_adherence QWK: 0.543\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.588\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01155002973973751 || Val Loss:  0.011625012382864952\nEpoch 37/50\nTraining one epoch in 224.844 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 37\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.697\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.689\n[DEV] sentence_fluency QWK: 0.666\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.688\n[DEV] narrativity QWK: 0.691\n------------------------\n[TEST] AVG QWK: 0.572\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.532\n[TEST] prompt_adherence QWK: 0.541\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.586\n------------------------\n[BEST TEST] AVG QWK: 0.572, {epoch}: 37\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.532\n[BEST TEST] prompt_adherence QWK: 0.541\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.586\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011543860659003258 || Val Loss:  0.011618787422776222\nEpoch 38/50\nTraining one epoch in 228.607 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 38\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.697\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.69\n[DEV] sentence_fluency QWK: 0.668\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.688\n[DEV] narrativity QWK: 0.691\n------------------------\n[TEST] AVG QWK: 0.573\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.532\n[TEST] prompt_adherence QWK: 0.543\n[TEST] language QWK: 0.576\n[TEST] narrativity QWK: 0.587\n------------------------\n[BEST TEST] AVG QWK: 0.573, {epoch}: 38\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.532\n[BEST TEST] prompt_adherence QWK: 0.543\n[BEST TEST] language QWK: 0.576\n[BEST TEST] narrativity QWK: 0.587\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011538000777363777 || Val Loss:  0.011612881906330585\nEpoch 39/50\nTraining one epoch in 224.407 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 39\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.697\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.69\n[DEV] sentence_fluency QWK: 0.669\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.69\n[DEV] language QWK: 0.688\n[DEV] narrativity QWK: 0.691\n------------------------\n[TEST] AVG QWK: 0.573\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.533\n[TEST] prompt_adherence QWK: 0.543\n[TEST] language QWK: 0.576\n[TEST] narrativity QWK: 0.589\n------------------------\n[BEST TEST] AVG QWK: 0.573, {epoch}: 39\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.533\n[BEST TEST] prompt_adherence QWK: 0.543\n[BEST TEST] language QWK: 0.576\n[BEST TEST] narrativity QWK: 0.589\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01153244636952877 || Val Loss:  0.011607282795011997\nEpoch 40/50\nTraining one epoch in 225.559 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 40\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.697\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.69\n[DEV] sentence_fluency QWK: 0.669\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.69\n[DEV] language QWK: 0.688\n[DEV] narrativity QWK: 0.692\n------------------------\n[TEST] AVG QWK: 0.574\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.534\n[TEST] prompt_adherence QWK: 0.543\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.59\n------------------------\n[BEST TEST] AVG QWK: 0.574, {epoch}: 40\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.534\n[BEST TEST] prompt_adherence QWK: 0.543\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.59\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011527162045240402 || Val Loss:  0.011601962149143219\nEpoch 41/50\nTraining one epoch in 223.830 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 41\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.697\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.69\n[DEV] sentence_fluency QWK: 0.669\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.69\n[DEV] language QWK: 0.688\n[DEV] narrativity QWK: 0.692\n------------------------\n[TEST] AVG QWK: 0.574\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.535\n[TEST] prompt_adherence QWK: 0.544\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.59\n------------------------\n[BEST TEST] AVG QWK: 0.574, {epoch}: 41\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.535\n[BEST TEST] prompt_adherence QWK: 0.544\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.59\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011522135697305202 || Val Loss:  0.01159690972417593\nEpoch 42/50\nTraining one epoch in 225.222 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 42\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.697\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.691\n[DEV] sentence_fluency QWK: 0.669\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.69\n[DEV] language QWK: 0.688\n[DEV] narrativity QWK: 0.693\n------------------------\n[TEST] AVG QWK: 0.574\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.535\n[TEST] prompt_adherence QWK: 0.544\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.59\n------------------------\n[BEST TEST] AVG QWK: 0.574, {epoch}: 42\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.535\n[BEST TEST] prompt_adherence QWK: 0.544\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.59\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01151734497398138 || Val Loss:  0.011592098511755466\nEpoch 43/50\nTraining one epoch in 225.606 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 43\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.691\n[DEV] sentence_fluency QWK: 0.67\n[DEV] conventions QWK: 0.731\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.689\n[DEV] narrativity QWK: 0.693\n------------------------\n[TEST] AVG QWK: 0.574\n[TEST] score QWK: 0.624\n[TEST] content QWK: 0.535\n[TEST] prompt_adherence QWK: 0.544\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.589\n------------------------\n[BEST TEST] AVG QWK: 0.574, {epoch}: 43\n[BEST TEST] score QWK: 0.624\n[BEST TEST] content QWK: 0.535\n[BEST TEST] prompt_adherence QWK: 0.544\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.589\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011512767523527145 || Val Loss:  0.01158752478659153\nEpoch 44/50\nTraining one epoch in 224.403 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 44\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.691\n[DEV] sentence_fluency QWK: 0.67\n[DEV] conventions QWK: 0.731\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.689\n[DEV] narrativity QWK: 0.693\n------------------------\n[TEST] AVG QWK: 0.574\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.535\n[TEST] prompt_adherence QWK: 0.545\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.589\n------------------------\n[BEST TEST] AVG QWK: 0.574, {epoch}: 44\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.535\n[BEST TEST] prompt_adherence QWK: 0.545\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.589\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011508411727845669 || Val Loss:  0.011583156883716583\nEpoch 45/50\nTraining one epoch in 227.185 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 45\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.692\n[DEV] sentence_fluency QWK: 0.67\n[DEV] conventions QWK: 0.731\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.689\n[DEV] narrativity QWK: 0.693\n------------------------\n[TEST] AVG QWK: 0.574\n[TEST] score QWK: 0.626\n[TEST] content QWK: 0.535\n[TEST] prompt_adherence QWK: 0.542\n[TEST] language QWK: 0.576\n[TEST] narrativity QWK: 0.589\n------------------------\n[BEST TEST] AVG QWK: 0.574, {epoch}: 45\n[BEST TEST] score QWK: 0.626\n[BEST TEST] content QWK: 0.535\n[BEST TEST] prompt_adherence QWK: 0.542\n[BEST TEST] language QWK: 0.576\n[BEST TEST] narrativity QWK: 0.589\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011504235677421093 || Val Loss:  0.011578994803130627\nEpoch 46/50\nTraining one epoch in 224.732 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 46\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.692\n[DEV] sentence_fluency QWK: 0.67\n[DEV] conventions QWK: 0.731\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.689\n[DEV] narrativity QWK: 0.694\n------------------------\n[TEST] AVG QWK: 0.574\n[TEST] score QWK: 0.626\n[TEST] content QWK: 0.536\n[TEST] prompt_adherence QWK: 0.542\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.588\n------------------------\n[BEST TEST] AVG QWK: 0.574, {epoch}: 46\n[BEST TEST] score QWK: 0.626\n[BEST TEST] content QWK: 0.536\n[BEST TEST] prompt_adherence QWK: 0.542\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.588\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011500260792672634 || Val Loss:  0.011575024574995041\nEpoch 47/50\nTraining one epoch in 225.133 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 47\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.692\n[DEV] sentence_fluency QWK: 0.67\n[DEV] conventions QWK: 0.732\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.69\n[DEV] narrativity QWK: 0.694\n------------------------\n[TEST] AVG QWK: 0.574\n[TEST] score QWK: 0.626\n[TEST] content QWK: 0.536\n[TEST] prompt_adherence QWK: 0.543\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.588\n------------------------\n[BEST TEST] AVG QWK: 0.574, {epoch}: 47\n[BEST TEST] score QWK: 0.626\n[BEST TEST] content QWK: 0.536\n[BEST TEST] prompt_adherence QWK: 0.543\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.588\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011496445164084435 || Val Loss:  0.011571229435503483\nEpoch 48/50\nTraining one epoch in 226.479 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\nCURRENT EPOCH: 48\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.693\n[DEV] sentence_fluency QWK: 0.671\n[DEV] conventions QWK: 0.732\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.69\n[DEV] narrativity QWK: 0.694\n------------------------\n[TEST] AVG QWK: 0.574\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.536\n[TEST] prompt_adherence QWK: 0.544\n[TEST] language QWK: 0.578\n[TEST] narrativity QWK: 0.588\n------------------------\n[BEST TEST] AVG QWK: 0.574, {epoch}: 48\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.536\n[BEST TEST] prompt_adherence QWK: 0.544\n[BEST TEST] language QWK: 0.578\n[BEST TEST] narrativity QWK: 0.588\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011492790654301643 || Val Loss:  0.011567601934075356\nEpoch 49/50\nTraining one epoch in 227.242 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 49\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.693\n[DEV] sentence_fluency QWK: 0.671\n[DEV] conventions QWK: 0.732\n[DEV] prompt_adherence QWK: 0.692\n[DEV] language QWK: 0.69\n[DEV] narrativity QWK: 0.694\n------------------------\n[TEST] AVG QWK: 0.574\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.536\n[TEST] prompt_adherence QWK: 0.543\n[TEST] language QWK: 0.578\n[TEST] narrativity QWK: 0.587\n------------------------\n[BEST TEST] AVG QWK: 0.574, {epoch}: 49\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.536\n[BEST TEST] prompt_adherence QWK: 0.543\n[BEST TEST] language QWK: 0.578\n[BEST TEST] narrativity QWK: 0.587\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01148930098861456 || Val Loss:  0.011564135551452637\nEpoch 50/50\nTraining one epoch in 226.721 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 50\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.671\n[DEV] conventions QWK: 0.732\n[DEV] prompt_adherence QWK: 0.692\n[DEV] language QWK: 0.691\n[DEV] narrativity QWK: 0.695\n------------------------\n[TEST] AVG QWK: 0.574\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.537\n[TEST] prompt_adherence QWK: 0.544\n[TEST] language QWK: 0.579\n[TEST] narrativity QWK: 0.586\n------------------------\n[BEST TEST] AVG QWK: 0.574, {epoch}: 50\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.537\n[BEST TEST] prompt_adherence QWK: 0.544\n[BEST TEST] language QWK: 0.579\n[BEST TEST] narrativity QWK: 0.586\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011485939845442772 || Val Loss:  0.011560818180441856\n[BEST TEST] AVG QWK: 0.574, {epoch}: 50\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.537\n[BEST TEST] prompt_adherence QWK: 0.544\n[BEST TEST] language QWK: 0.579\n[BEST TEST] narrativity QWK: 0.586\n--------------------------------------------------------------------------------------------------------------------------\nModel saved as 'trained_model/protact_model_prompt_6_seed_12.h5'\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}