{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-31T03:07:10.738624Z","iopub.execute_input":"2024-10-31T03:07:10.738977Z","iopub.status.idle":"2024-10-31T03:07:11.731490Z","shell.execute_reply.started":"2024-10-31T03:07:10.738942Z","shell.execute_reply":"2024-10-31T03:07:11.730550Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-10-31T03:07:11.733323Z","iopub.execute_input":"2024-10-31T03:07:11.733756Z","iopub.status.idle":"2024-10-31T03:07:24.883217Z","shell.execute_reply.started":"2024-10-31T03:07:11.733721Z","shell.execute_reply":"2024-10-31T03:07:24.882111Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/ishreya09/ProTACT.git","metadata":{"execution":{"iopub.status.busy":"2024-10-31T03:07:24.884746Z","iopub.execute_input":"2024-10-31T03:07:24.885141Z","iopub.status.idle":"2024-10-31T03:07:36.621968Z","shell.execute_reply.started":"2024-10-31T03:07:24.885092Z","shell.execute_reply":"2024-10-31T03:07:36.620765Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'ProTACT'...\nremote: Enumerating objects: 318, done.\u001b[K\nremote: Counting objects: 100% (7/7), done.\u001b[K\nremote: Compressing objects: 100% (7/7), done.\u001b[K\nremote: Total 318 (delta 0), reused 6 (delta 0), pack-reused 311 (from 1)\u001b[K\nReceiving objects: 100% (318/318), 146.60 MiB | 21.22 MiB/s, done.\nResolving deltas: 100% (173/173), done.\nUpdating files: 100% (136/136), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!cp -r /kaggle/working/ProTACT/* /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-10-31T03:07:36.624472Z","iopub.execute_input":"2024-10-31T03:07:36.624824Z","iopub.status.idle":"2024-10-31T03:07:38.119091Z","shell.execute_reply.started":"2024-10-31T03:07:36.624778Z","shell.execute_reply":"2024-10-31T03:07:38.117745Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!mkdir trained_model","metadata":{"execution":{"iopub.status.busy":"2024-10-31T03:07:38.120549Z","iopub.execute_input":"2024-10-31T03:07:38.120886Z","iopub.status.idle":"2024-10-31T03:07:39.109061Z","shell.execute_reply.started":"2024-10-31T03:07:38.120848Z","shell.execute_reply":"2024-10-31T03:07:39.108029Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'trained_model': File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"import gdown\nimport os\n\n# Create directory if it doesn't exist\nos.makedirs('embeddings', exist_ok=True)\n\n# https://drive.google.com/file/d/1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ/view?usp=sharing\n\n# Google Drive file ID\nfile_id = \"1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ\"\n\n# Download file to the specified directory\ngdown.download(f\"https://drive.google.com/uc?id={file_id}\", 'embeddings/glove.6B.50d.txt', quiet=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T03:07:39.110494Z","iopub.execute_input":"2024-10-31T03:07:39.110816Z","iopub.status.idle":"2024-10-31T03:07:45.663671Z","shell.execute_reply.started":"2024-10-31T03:07:39.110779Z","shell.execute_reply":"2024-10-31T03:07:45.662683Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ\nFrom (redirected): https://drive.google.com/uc?id=1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ&confirm=t&uuid=ab5753af-4787-4fb5-8b38-9500c5e5f92c\nTo: /kaggle/working/embeddings/glove.6B.50d.txt\n100%|██████████| 171M/171M [00:02<00:00, 70.3MB/s] \n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'embeddings/glove.6B.50d.txt'"},"metadata":{}}]},{"cell_type":"code","source":"!bash /kaggle/working/train_prompt6_seed32.sh ","metadata":{"execution":{"iopub.status.busy":"2024-10-31T03:07:45.664943Z","iopub.execute_input":"2024-10-31T03:07:45.665540Z","iopub.status.idle":"2024-10-31T06:43:26.814006Z","shell.execute_reply.started":"2024-10-31T03:07:45.665496Z","shell.execute_reply":"2024-10-31T06:43:26.812862Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Test prompt id is 6 of type <class 'int'>\nSeed: 32\nNumhead :  2  | Features :  data/LDA/hand_crafted_final_6.csv  | Pos_emb :  50\n prompt_pos size: 8\n prompt_words size: 8\n pos_x size: 9498\n readability_x size: 9498\n pos_x size: 1678\n readability_x size: 1678\n pos_x size: 1800\n readability_x size: 1800\nLoading GloVe ...\nOOV number =204, OOV ratio = 0.051013\nmax sent length: 50\nmax sent num: 97\nmax prompt sent length: 18\nmax prompt sent num: 8\n================================\nX_train_pos:  (9498, 4850)\nX_train_prompt_words:  (9498, 4850)\nX_train_prompt_pos:  (9498, 4850)\nX_train_readability:  (9498, 35)\nX_train_ling:  (9498, 52)\nX_train_attribute_rel:  (9498, 9)\nY_train:  (9498, 9)\n================================\nX_dev_pos:  (1678, 4850)\nX_dev_prompt_words:  (1678, 4850)\nX_dev_prompt_pos:  (1678, 4850)\nX_dev_readability:  (1678, 35)\nX_dev_ling:  (1678, 52)\nX_dev_attribute_rel:  (1678, 9)\nY_dev:  (1678, 9)\n================================\nX_test_pos:  (1800, 4850)\nX_test_prompt_words:  (1800, 4850)\nX_test_prompt_pos:  (1800, 4850)\nX_test_readability:  (1800, 35)\nX_test_ling:  (1800, 52)\nX_test_attribute_rel:  (1800, 9)\nY_test:  (1800, 9)\n================================\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n\u001b[1mModel: \"functional_1\"\u001b[0m\n┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ prompt_word_input   │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_input    │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_input           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt (\u001b[94mEmbedding\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │    \u001b[32m200,000\u001b[0m │ prompt_word_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_1         │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ prompt_word_inpu… │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_prompt          │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │      \u001b[32m1,950\u001b[0m │ prompt_pos_input… │\n│ (\u001b[94mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_2         │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ prompt_pos_input… │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x (\u001b[94mEmbedding\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │      \u001b[32m1,950\u001b[0m │ pos_input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ pos_input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_maskedout    │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ prompt[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_maskedo… │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_prompt[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x_maskedout     │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_x[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (\u001b[94mAdd\u001b[0m)           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ prompt_maskedout… │\n│                     │                   │            │ prompt_pos_maske… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_drop_x          │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_x_maskedout[\u001b[32m…\u001b[0m │\n│ (\u001b[94mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_drop_x       │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ add[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]         │\n│ (\u001b[94mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_resh_W          │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m50\u001b[0m,    │          \u001b[32m0\u001b[0m │ pos_drop_x[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]  │\n│ (\u001b[94mReshape\u001b[0m)           │ \u001b[32m50\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_resh_W       │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m50\u001b[0m,    │          \u001b[32m0\u001b[0m │ prompt_drop_x[\u001b[32m0\u001b[0m]… │\n│ (\u001b[94mReshape\u001b[0m)           │ \u001b[32m50\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_zcnn            │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m46\u001b[0m,    │     \u001b[32m25,100\u001b[0m │ pos_resh_W[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]  │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │ \u001b[32m100\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_zcnn         │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m46\u001b[0m,    │     \u001b[32m25,100\u001b[0m │ prompt_resh_W[\u001b[32m0\u001b[0m]… │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │ \u001b[32m100\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_avg_zcnn        │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m100\u001b[0m)   │          \u001b[32m0\u001b[0m │ pos_zcnn[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_avg_zcnn     │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m100\u001b[0m)   │          \u001b[32m0\u001b[0m │ prompt_zcnn[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ prompt_avg_zcnn[\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (\u001b[94mLSTM\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_9 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_4 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_5 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_6 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_7 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_8 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_1         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]        │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_11        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_2         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_3         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_4         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_5         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_6         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_7         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_8         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_9         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_10 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_11 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_12 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_13 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_14 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_15 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_16 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_17 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_18 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_12        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_10[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ linguistic_input    │ (\u001b[96mNone\u001b[0m, \u001b[32m52\u001b[0m)        │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ readability_input   │ (\u001b[96mNone\u001b[0m, \u001b[32m35\u001b[0m)        │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_13        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_11[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_14        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_12[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_15        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_13[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_16        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_14[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_17        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_15[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_18        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_16[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_19        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_17[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_20        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_18[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_12[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_13[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_14[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_15[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_4       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_16[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_5       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_17[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_6       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_18[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_7       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_19[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_8       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_20[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (\u001b[94mLambda\u001b[0m)     │ (\u001b[96mNone\u001b[0m, \u001b[32m9\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ concatenate[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│                     │                   │            │ concatenate_1[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_2[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_3[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_4[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_5[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_6[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_7[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_8[\u001b[32m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (\u001b[94mGetItem\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_1 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_1          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_2 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_2          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_3 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_3          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_4 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_4          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_5 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_5          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_6 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_6          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_7 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_7          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_8 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_8          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_9 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_21        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_22        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_23        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_24        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_25        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_26        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_27        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_28        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_29        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_9       │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_21[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_10      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_22[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_11      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_23[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_12      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_24[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_13      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_25[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_14      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_26[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_15      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_27[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_16      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_28[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_17      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_29[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (\u001b[94mFlatten\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_9[\u001b[32m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_10[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_2 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_11[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_3 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_12[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_4 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_13[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_5 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_14[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_6 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_15[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_7 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_16[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_8 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_17[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_76 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_77 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_78 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_79 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_80 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_81 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_82 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_83 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_84 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_18      │ (\u001b[96mNone\u001b[0m, \u001b[32m9\u001b[0m)         │          \u001b[32m0\u001b[0m │ dense_76[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ dense_77[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_78[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_79[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_80[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_81[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_82[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_83[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_84[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n\u001b[1m Total params: \u001b[0m\u001b[32m2,552,675\u001b[0m (9.74 MB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,552,675\u001b[0m (9.74 MB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 415ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\nCURRENT EPOCH: -1\n[DEV] AVG QWK: 0.002\n[DEV] score QWK: -0.007\n[DEV] content QWK: 0.005\n[DEV] organization QWK: 0.067\n[DEV] word_choice QWK: -0.052\n[DEV] sentence_fluency QWK: 0.004\n[DEV] conventions QWK: 0.034\n[DEV] prompt_adherence QWK: -0.053\n[DEV] language QWK: -0.052\n[DEV] narrativity QWK: 0.069\n------------------------\n[TEST] AVG QWK: 0.009\n[TEST] score QWK: 0.024\n[TEST] content QWK: 0.016\n[TEST] prompt_adherence QWK: -0.001\n[TEST] language QWK: -0.031\n[TEST] narrativity QWK: 0.034\n------------------------\n[BEST TEST] AVG QWK: 0.009, {epoch}: -1\n[BEST TEST] score QWK: 0.024\n[BEST TEST] content QWK: 0.016\n[BEST TEST] prompt_adherence QWK: -0.001\n[BEST TEST] language QWK: -0.031\n[BEST TEST] narrativity QWK: 0.034\n--------------------------------------------------------------------------------------------------------------------------\nEpoch 1/50\ntrait num:  9\ntrait num:  9\ntrait num:  9\nTraining one epoch in 380.213 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 1\n[DEV] AVG QWK: 0.6\n[DEV] score QWK: 0.711\n[DEV] content QWK: 0.597\n[DEV] organization QWK: 0.618\n[DEV] word_choice QWK: 0.606\n[DEV] sentence_fluency QWK: 0.568\n[DEV] conventions QWK: 0.569\n[DEV] prompt_adherence QWK: 0.58\n[DEV] language QWK: 0.57\n[DEV] narrativity QWK: 0.581\n------------------------\n[TEST] AVG QWK: 0.494\n[TEST] score QWK: 0.559\n[TEST] content QWK: 0.434\n[TEST] prompt_adherence QWK: 0.47\n[TEST] language QWK: 0.489\n[TEST] narrativity QWK: 0.519\n------------------------\n[BEST TEST] AVG QWK: 0.494, {epoch}: 1\n[BEST TEST] score QWK: 0.559\n[BEST TEST] content QWK: 0.434\n[BEST TEST] prompt_adherence QWK: 0.47\n[BEST TEST] language QWK: 0.489\n[BEST TEST] narrativity QWK: 0.519\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01660902611911297 || Val Loss:  0.014123598113656044\nEpoch 2/50\nTraining one epoch in 239.010 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 2\n[DEV] AVG QWK: 0.636\n[DEV] score QWK: 0.728\n[DEV] content QWK: 0.632\n[DEV] organization QWK: 0.659\n[DEV] word_choice QWK: 0.637\n[DEV] sentence_fluency QWK: 0.602\n[DEV] conventions QWK: 0.628\n[DEV] prompt_adherence QWK: 0.615\n[DEV] language QWK: 0.61\n[DEV] narrativity QWK: 0.613\n------------------------\n[TEST] AVG QWK: 0.519\n[TEST] score QWK: 0.578\n[TEST] content QWK: 0.473\n[TEST] prompt_adherence QWK: 0.497\n[TEST] language QWK: 0.506\n[TEST] narrativity QWK: 0.543\n------------------------\n[BEST TEST] AVG QWK: 0.519, {epoch}: 2\n[BEST TEST] score QWK: 0.578\n[BEST TEST] content QWK: 0.473\n[BEST TEST] prompt_adherence QWK: 0.497\n[BEST TEST] language QWK: 0.506\n[BEST TEST] narrativity QWK: 0.543\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.013624188490211964 || Val Loss:  0.01334457565099001\nEpoch 3/50\nTraining one epoch in 239.135 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\nCURRENT EPOCH: 3\n[DEV] AVG QWK: 0.651\n[DEV] score QWK: 0.735\n[DEV] content QWK: 0.647\n[DEV] organization QWK: 0.678\n[DEV] word_choice QWK: 0.649\n[DEV] sentence_fluency QWK: 0.618\n[DEV] conventions QWK: 0.653\n[DEV] prompt_adherence QWK: 0.628\n[DEV] language QWK: 0.625\n[DEV] narrativity QWK: 0.624\n------------------------\n[TEST] AVG QWK: 0.53\n[TEST] score QWK: 0.578\n[TEST] content QWK: 0.487\n[TEST] prompt_adherence QWK: 0.515\n[TEST] language QWK: 0.518\n[TEST] narrativity QWK: 0.551\n------------------------\n[BEST TEST] AVG QWK: 0.53, {epoch}: 3\n[BEST TEST] score QWK: 0.578\n[BEST TEST] content QWK: 0.487\n[BEST TEST] prompt_adherence QWK: 0.515\n[BEST TEST] language QWK: 0.518\n[BEST TEST] narrativity QWK: 0.551\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.013079550117254257 || Val Loss:  0.012950656935572624\nEpoch 4/50\nTraining one epoch in 238.878 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 4\n[DEV] AVG QWK: 0.66\n[DEV] score QWK: 0.741\n[DEV] content QWK: 0.656\n[DEV] organization QWK: 0.688\n[DEV] word_choice QWK: 0.657\n[DEV] sentence_fluency QWK: 0.628\n[DEV] conventions QWK: 0.669\n[DEV] prompt_adherence QWK: 0.638\n[DEV] language QWK: 0.635\n[DEV] narrativity QWK: 0.632\n------------------------\n[TEST] AVG QWK: 0.536\n[TEST] score QWK: 0.587\n[TEST] content QWK: 0.49\n[TEST] prompt_adherence QWK: 0.522\n[TEST] language QWK: 0.532\n[TEST] narrativity QWK: 0.551\n------------------------\n[BEST TEST] AVG QWK: 0.536, {epoch}: 4\n[BEST TEST] score QWK: 0.587\n[BEST TEST] content QWK: 0.49\n[BEST TEST] prompt_adherence QWK: 0.522\n[BEST TEST] language QWK: 0.532\n[BEST TEST] narrativity QWK: 0.551\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012772363610565662 || Val Loss:  0.012698556296527386\nEpoch 5/50\nTraining one epoch in 238.715 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 5\n[DEV] AVG QWK: 0.667\n[DEV] score QWK: 0.744\n[DEV] content QWK: 0.663\n[DEV] organization QWK: 0.693\n[DEV] word_choice QWK: 0.662\n[DEV] sentence_fluency QWK: 0.634\n[DEV] conventions QWK: 0.68\n[DEV] prompt_adherence QWK: 0.645\n[DEV] language QWK: 0.642\n[DEV] narrativity QWK: 0.638\n------------------------\n[TEST] AVG QWK: 0.537\n[TEST] score QWK: 0.59\n[TEST] content QWK: 0.491\n[TEST] prompt_adherence QWK: 0.525\n[TEST] language QWK: 0.531\n[TEST] narrativity QWK: 0.55\n------------------------\n[BEST TEST] AVG QWK: 0.537, {epoch}: 5\n[BEST TEST] score QWK: 0.59\n[BEST TEST] content QWK: 0.491\n[BEST TEST] prompt_adherence QWK: 0.525\n[BEST TEST] language QWK: 0.531\n[BEST TEST] narrativity QWK: 0.55\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012567445635795593 || Val Loss:  0.012519899755716324\nEpoch 6/50\nTraining one epoch in 238.614 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\nCURRENT EPOCH: 6\n[DEV] AVG QWK: 0.672\n[DEV] score QWK: 0.747\n[DEV] content QWK: 0.668\n[DEV] organization QWK: 0.699\n[DEV] word_choice QWK: 0.666\n[DEV] sentence_fluency QWK: 0.639\n[DEV] conventions QWK: 0.686\n[DEV] prompt_adherence QWK: 0.65\n[DEV] language QWK: 0.647\n[DEV] narrativity QWK: 0.642\n------------------------\n[TEST] AVG QWK: 0.54\n[TEST] score QWK: 0.595\n[TEST] content QWK: 0.497\n[TEST] prompt_adherence QWK: 0.532\n[TEST] language QWK: 0.532\n[TEST] narrativity QWK: 0.548\n------------------------\n[BEST TEST] AVG QWK: 0.54, {epoch}: 6\n[BEST TEST] score QWK: 0.595\n[BEST TEST] content QWK: 0.497\n[BEST TEST] prompt_adherence QWK: 0.532\n[BEST TEST] language QWK: 0.532\n[BEST TEST] narrativity QWK: 0.548\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01241824496537447 || Val Loss:  0.01238517090678215\nEpoch 7/50\nTraining one epoch in 238.318 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 7\n[DEV] AVG QWK: 0.675\n[DEV] score QWK: 0.75\n[DEV] content QWK: 0.672\n[DEV] organization QWK: 0.702\n[DEV] word_choice QWK: 0.669\n[DEV] sentence_fluency QWK: 0.643\n[DEV] conventions QWK: 0.691\n[DEV] prompt_adherence QWK: 0.654\n[DEV] language QWK: 0.651\n[DEV] narrativity QWK: 0.646\n------------------------\n[TEST] AVG QWK: 0.542\n[TEST] score QWK: 0.597\n[TEST] content QWK: 0.504\n[TEST] prompt_adherence QWK: 0.534\n[TEST] language QWK: 0.53\n[TEST] narrativity QWK: 0.546\n------------------------\n[BEST TEST] AVG QWK: 0.542, {epoch}: 7\n[BEST TEST] score QWK: 0.597\n[BEST TEST] content QWK: 0.504\n[BEST TEST] prompt_adherence QWK: 0.534\n[BEST TEST] language QWK: 0.53\n[BEST TEST] narrativity QWK: 0.546\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012303359806537628 || Val Loss:  0.012279098853468895\nEpoch 8/50\nTraining one epoch in 262.613 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 8\n[DEV] AVG QWK: 0.679\n[DEV] score QWK: 0.752\n[DEV] content QWK: 0.676\n[DEV] organization QWK: 0.704\n[DEV] word_choice QWK: 0.672\n[DEV] sentence_fluency QWK: 0.646\n[DEV] conventions QWK: 0.697\n[DEV] prompt_adherence QWK: 0.657\n[DEV] language QWK: 0.655\n[DEV] narrativity QWK: 0.649\n------------------------\n[TEST] AVG QWK: 0.545\n[TEST] score QWK: 0.598\n[TEST] content QWK: 0.512\n[TEST] prompt_adherence QWK: 0.537\n[TEST] language QWK: 0.531\n[TEST] narrativity QWK: 0.546\n------------------------\n[BEST TEST] AVG QWK: 0.545, {epoch}: 8\n[BEST TEST] score QWK: 0.598\n[BEST TEST] content QWK: 0.512\n[BEST TEST] prompt_adherence QWK: 0.537\n[BEST TEST] language QWK: 0.531\n[BEST TEST] narrativity QWK: 0.546\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012211387977004051 || Val Loss:  0.012192879803478718\nEpoch 9/50\nTraining one epoch in 238.506 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 9\n[DEV] AVG QWK: 0.681\n[DEV] score QWK: 0.754\n[DEV] content QWK: 0.679\n[DEV] organization QWK: 0.706\n[DEV] word_choice QWK: 0.673\n[DEV] sentence_fluency QWK: 0.648\n[DEV] conventions QWK: 0.7\n[DEV] prompt_adherence QWK: 0.66\n[DEV] language QWK: 0.658\n[DEV] narrativity QWK: 0.651\n------------------------\n[TEST] AVG QWK: 0.547\n[TEST] score QWK: 0.598\n[TEST] content QWK: 0.514\n[TEST] prompt_adherence QWK: 0.543\n[TEST] language QWK: 0.533\n[TEST] narrativity QWK: 0.549\n------------------------\n[BEST TEST] AVG QWK: 0.547, {epoch}: 9\n[BEST TEST] score QWK: 0.598\n[BEST TEST] content QWK: 0.514\n[BEST TEST] prompt_adherence QWK: 0.543\n[BEST TEST] language QWK: 0.533\n[BEST TEST] narrativity QWK: 0.549\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01213567703962326 || Val Loss:  0.012121101841330528\nEpoch 10/50\nTraining one epoch in 238.838 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 10\n[DEV] AVG QWK: 0.683\n[DEV] score QWK: 0.756\n[DEV] content QWK: 0.681\n[DEV] organization QWK: 0.709\n[DEV] word_choice QWK: 0.675\n[DEV] sentence_fluency QWK: 0.65\n[DEV] conventions QWK: 0.703\n[DEV] prompt_adherence QWK: 0.662\n[DEV] language QWK: 0.661\n[DEV] narrativity QWK: 0.655\n------------------------\n[TEST] AVG QWK: 0.55\n[TEST] score QWK: 0.6\n[TEST] content QWK: 0.518\n[TEST] prompt_adherence QWK: 0.544\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.551\n------------------------\n[BEST TEST] AVG QWK: 0.55, {epoch}: 10\n[BEST TEST] score QWK: 0.6\n[BEST TEST] content QWK: 0.518\n[BEST TEST] prompt_adherence QWK: 0.544\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.551\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01207196805626154 || Val Loss:  0.012060185894370079\nEpoch 11/50\nTraining one epoch in 238.977 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 11\n[DEV] AVG QWK: 0.685\n[DEV] score QWK: 0.757\n[DEV] content QWK: 0.684\n[DEV] organization QWK: 0.71\n[DEV] word_choice QWK: 0.677\n[DEV] sentence_fluency QWK: 0.653\n[DEV] conventions QWK: 0.706\n[DEV] prompt_adherence QWK: 0.665\n[DEV] language QWK: 0.662\n[DEV] narrativity QWK: 0.656\n------------------------\n[TEST] AVG QWK: 0.552\n[TEST] score QWK: 0.601\n[TEST] content QWK: 0.519\n[TEST] prompt_adherence QWK: 0.546\n[TEST] language QWK: 0.541\n[TEST] narrativity QWK: 0.553\n------------------------\n[BEST TEST] AVG QWK: 0.552, {epoch}: 11\n[BEST TEST] score QWK: 0.601\n[BEST TEST] content QWK: 0.519\n[BEST TEST] prompt_adherence QWK: 0.546\n[BEST TEST] language QWK: 0.541\n[BEST TEST] narrativity QWK: 0.553\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012017481960356236 || Val Loss:  0.012007723562419415\nEpoch 12/50\nTraining one epoch in 239.002 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 12\n[DEV] AVG QWK: 0.687\n[DEV] score QWK: 0.758\n[DEV] content QWK: 0.685\n[DEV] organization QWK: 0.712\n[DEV] word_choice QWK: 0.679\n[DEV] sentence_fluency QWK: 0.654\n[DEV] conventions QWK: 0.707\n[DEV] prompt_adherence QWK: 0.667\n[DEV] language QWK: 0.664\n[DEV] narrativity QWK: 0.658\n------------------------\n[TEST] AVG QWK: 0.555\n[TEST] score QWK: 0.601\n[TEST] content QWK: 0.525\n[TEST] prompt_adherence QWK: 0.546\n[TEST] language QWK: 0.542\n[TEST] narrativity QWK: 0.559\n------------------------\n[BEST TEST] AVG QWK: 0.555, {epoch}: 12\n[BEST TEST] score QWK: 0.601\n[BEST TEST] content QWK: 0.525\n[BEST TEST] prompt_adherence QWK: 0.546\n[BEST TEST] language QWK: 0.542\n[BEST TEST] narrativity QWK: 0.559\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011970270425081253 || Val Loss:  0.011961987242102623\nEpoch 13/50\nTraining one epoch in 238.650 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\nCURRENT EPOCH: 13\n[DEV] AVG QWK: 0.688\n[DEV] score QWK: 0.759\n[DEV] content QWK: 0.687\n[DEV] organization QWK: 0.714\n[DEV] word_choice QWK: 0.679\n[DEV] sentence_fluency QWK: 0.655\n[DEV] conventions QWK: 0.709\n[DEV] prompt_adherence QWK: 0.667\n[DEV] language QWK: 0.665\n[DEV] narrativity QWK: 0.66\n------------------------\n[TEST] AVG QWK: 0.556\n[TEST] score QWK: 0.604\n[TEST] content QWK: 0.525\n[TEST] prompt_adherence QWK: 0.55\n[TEST] language QWK: 0.542\n[TEST] narrativity QWK: 0.558\n------------------------\n[BEST TEST] AVG QWK: 0.556, {epoch}: 13\n[BEST TEST] score QWK: 0.604\n[BEST TEST] content QWK: 0.525\n[BEST TEST] prompt_adherence QWK: 0.55\n[BEST TEST] language QWK: 0.542\n[BEST TEST] narrativity QWK: 0.558\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011928905732929707 || Val Loss:  0.011921707540750504\nEpoch 14/50\nTraining one epoch in 237.542 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 14\n[DEV] AVG QWK: 0.69\n[DEV] score QWK: 0.759\n[DEV] content QWK: 0.688\n[DEV] organization QWK: 0.715\n[DEV] word_choice QWK: 0.681\n[DEV] sentence_fluency QWK: 0.656\n[DEV] conventions QWK: 0.71\n[DEV] prompt_adherence QWK: 0.669\n[DEV] language QWK: 0.667\n[DEV] narrativity QWK: 0.661\n------------------------\n[TEST] AVG QWK: 0.555\n[TEST] score QWK: 0.602\n[TEST] content QWK: 0.523\n[TEST] prompt_adherence QWK: 0.552\n[TEST] language QWK: 0.54\n[TEST] narrativity QWK: 0.558\n------------------------\n[BEST TEST] AVG QWK: 0.555, {epoch}: 14\n[BEST TEST] score QWK: 0.602\n[BEST TEST] content QWK: 0.523\n[BEST TEST] prompt_adherence QWK: 0.552\n[BEST TEST] language QWK: 0.54\n[BEST TEST] narrativity QWK: 0.558\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011892354115843773 || Val Loss:  0.0118859326466918\nEpoch 15/50\nTraining one epoch in 237.289 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\nCURRENT EPOCH: 15\n[DEV] AVG QWK: 0.691\n[DEV] score QWK: 0.76\n[DEV] content QWK: 0.689\n[DEV] organization QWK: 0.716\n[DEV] word_choice QWK: 0.681\n[DEV] sentence_fluency QWK: 0.658\n[DEV] conventions QWK: 0.712\n[DEV] prompt_adherence QWK: 0.671\n[DEV] language QWK: 0.668\n[DEV] narrativity QWK: 0.662\n------------------------\n[TEST] AVG QWK: 0.556\n[TEST] score QWK: 0.604\n[TEST] content QWK: 0.526\n[TEST] prompt_adherence QWK: 0.554\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.558\n------------------------\n[BEST TEST] AVG QWK: 0.556, {epoch}: 15\n[BEST TEST] score QWK: 0.604\n[BEST TEST] content QWK: 0.526\n[BEST TEST] prompt_adherence QWK: 0.554\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.558\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011859799735248089 || Val Loss:  0.011853929609060287\nEpoch 16/50\nTraining one epoch in 237.286 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 16\n[DEV] AVG QWK: 0.692\n[DEV] score QWK: 0.761\n[DEV] content QWK: 0.69\n[DEV] organization QWK: 0.716\n[DEV] word_choice QWK: 0.682\n[DEV] sentence_fluency QWK: 0.659\n[DEV] conventions QWK: 0.713\n[DEV] prompt_adherence QWK: 0.672\n[DEV] language QWK: 0.669\n[DEV] narrativity QWK: 0.663\n------------------------\n[TEST] AVG QWK: 0.556\n[TEST] score QWK: 0.606\n[TEST] content QWK: 0.527\n[TEST] prompt_adherence QWK: 0.554\n[TEST] language QWK: 0.534\n[TEST] narrativity QWK: 0.56\n------------------------\n[BEST TEST] AVG QWK: 0.556, {epoch}: 16\n[BEST TEST] score QWK: 0.606\n[BEST TEST] content QWK: 0.527\n[BEST TEST] prompt_adherence QWK: 0.554\n[BEST TEST] language QWK: 0.534\n[BEST TEST] narrativity QWK: 0.56\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011830602772533894 || Val Loss:  0.011825129389762878\nEpoch 17/50\nTraining one epoch in 236.139 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 17\n[DEV] AVG QWK: 0.693\n[DEV] score QWK: 0.762\n[DEV] content QWK: 0.691\n[DEV] organization QWK: 0.717\n[DEV] word_choice QWK: 0.683\n[DEV] sentence_fluency QWK: 0.66\n[DEV] conventions QWK: 0.714\n[DEV] prompt_adherence QWK: 0.673\n[DEV] language QWK: 0.67\n[DEV] narrativity QWK: 0.664\n------------------------\n[TEST] AVG QWK: 0.556\n[TEST] score QWK: 0.606\n[TEST] content QWK: 0.527\n[TEST] prompt_adherence QWK: 0.556\n[TEST] language QWK: 0.53\n[TEST] narrativity QWK: 0.56\n------------------------\n[BEST TEST] AVG QWK: 0.556, {epoch}: 17\n[BEST TEST] score QWK: 0.606\n[BEST TEST] content QWK: 0.527\n[BEST TEST] prompt_adherence QWK: 0.556\n[BEST TEST] language QWK: 0.53\n[BEST TEST] narrativity QWK: 0.56\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011804301291704178 || Val Loss:  0.011799050495028496\nEpoch 18/50\nTraining one epoch in 236.160 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\nCURRENT EPOCH: 18\n[DEV] AVG QWK: 0.694\n[DEV] score QWK: 0.762\n[DEV] content QWK: 0.692\n[DEV] organization QWK: 0.718\n[DEV] word_choice QWK: 0.684\n[DEV] sentence_fluency QWK: 0.662\n[DEV] conventions QWK: 0.715\n[DEV] prompt_adherence QWK: 0.674\n[DEV] language QWK: 0.671\n[DEV] narrativity QWK: 0.665\n------------------------\n[TEST] AVG QWK: 0.557\n[TEST] score QWK: 0.609\n[TEST] content QWK: 0.528\n[TEST] prompt_adherence QWK: 0.561\n[TEST] language QWK: 0.528\n[TEST] narrativity QWK: 0.561\n------------------------\n[BEST TEST] AVG QWK: 0.557, {epoch}: 18\n[BEST TEST] score QWK: 0.609\n[BEST TEST] content QWK: 0.528\n[BEST TEST] prompt_adherence QWK: 0.561\n[BEST TEST] language QWK: 0.528\n[BEST TEST] narrativity QWK: 0.561\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011780474334955215 || Val Loss:  0.011775331571698189\nEpoch 19/50\nTraining one epoch in 235.064 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 19\n[DEV] AVG QWK: 0.694\n[DEV] score QWK: 0.763\n[DEV] content QWK: 0.692\n[DEV] organization QWK: 0.719\n[DEV] word_choice QWK: 0.685\n[DEV] sentence_fluency QWK: 0.663\n[DEV] conventions QWK: 0.717\n[DEV] prompt_adherence QWK: 0.674\n[DEV] language QWK: 0.672\n[DEV] narrativity QWK: 0.666\n------------------------\n[TEST] AVG QWK: 0.56\n[TEST] score QWK: 0.61\n[TEST] content QWK: 0.53\n[TEST] prompt_adherence QWK: 0.565\n[TEST] language QWK: 0.529\n[TEST] narrativity QWK: 0.565\n------------------------\n[BEST TEST] AVG QWK: 0.56, {epoch}: 19\n[BEST TEST] score QWK: 0.61\n[BEST TEST] content QWK: 0.53\n[BEST TEST] prompt_adherence QWK: 0.565\n[BEST TEST] language QWK: 0.529\n[BEST TEST] narrativity QWK: 0.565\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.0117587735876441 || Val Loss:  0.011753671802580357\nEpoch 20/50\nTraining one epoch in 234.799 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 20\n[DEV] AVG QWK: 0.695\n[DEV] score QWK: 0.763\n[DEV] content QWK: 0.693\n[DEV] organization QWK: 0.72\n[DEV] word_choice QWK: 0.686\n[DEV] sentence_fluency QWK: 0.664\n[DEV] conventions QWK: 0.718\n[DEV] prompt_adherence QWK: 0.675\n[DEV] language QWK: 0.672\n[DEV] narrativity QWK: 0.667\n------------------------\n[TEST] AVG QWK: 0.559\n[TEST] score QWK: 0.613\n[TEST] content QWK: 0.532\n[TEST] prompt_adherence QWK: 0.561\n[TEST] language QWK: 0.53\n[TEST] narrativity QWK: 0.562\n------------------------\n[BEST TEST] AVG QWK: 0.559, {epoch}: 20\n[BEST TEST] score QWK: 0.613\n[BEST TEST] content QWK: 0.532\n[BEST TEST] prompt_adherence QWK: 0.561\n[BEST TEST] language QWK: 0.53\n[BEST TEST] narrativity QWK: 0.562\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011738955043256283 || Val Loss:  0.011733807623386383\nEpoch 21/50\nTraining one epoch in 234.465 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\nCURRENT EPOCH: 21\n[DEV] AVG QWK: 0.696\n[DEV] score QWK: 0.763\n[DEV] content QWK: 0.694\n[DEV] organization QWK: 0.72\n[DEV] word_choice QWK: 0.687\n[DEV] sentence_fluency QWK: 0.665\n[DEV] conventions QWK: 0.719\n[DEV] prompt_adherence QWK: 0.676\n[DEV] language QWK: 0.674\n[DEV] narrativity QWK: 0.667\n------------------------\n[TEST] AVG QWK: 0.561\n[TEST] score QWK: 0.613\n[TEST] content QWK: 0.535\n[TEST] prompt_adherence QWK: 0.564\n[TEST] language QWK: 0.53\n[TEST] narrativity QWK: 0.563\n------------------------\n[BEST TEST] AVG QWK: 0.561, {epoch}: 21\n[BEST TEST] score QWK: 0.613\n[BEST TEST] content QWK: 0.535\n[BEST TEST] prompt_adherence QWK: 0.564\n[BEST TEST] language QWK: 0.53\n[BEST TEST] narrativity QWK: 0.563\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011720781214535236 || Val Loss:  0.01171552762389183\nEpoch 22/50\nTraining one epoch in 262.605 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 22\n[DEV] AVG QWK: 0.697\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.695\n[DEV] organization QWK: 0.721\n[DEV] word_choice QWK: 0.687\n[DEV] sentence_fluency QWK: 0.666\n[DEV] conventions QWK: 0.72\n[DEV] prompt_adherence QWK: 0.676\n[DEV] language QWK: 0.674\n[DEV] narrativity QWK: 0.667\n------------------------\n[TEST] AVG QWK: 0.562\n[TEST] score QWK: 0.613\n[TEST] content QWK: 0.534\n[TEST] prompt_adherence QWK: 0.567\n[TEST] language QWK: 0.531\n[TEST] narrativity QWK: 0.564\n------------------------\n[BEST TEST] AVG QWK: 0.562, {epoch}: 22\n[BEST TEST] score QWK: 0.613\n[BEST TEST] content QWK: 0.534\n[BEST TEST] prompt_adherence QWK: 0.567\n[BEST TEST] language QWK: 0.531\n[BEST TEST] narrativity QWK: 0.564\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01170404627919197 || Val Loss:  0.011698644608259201\nEpoch 23/50\nTraining one epoch in 236.047 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 23\n[DEV] AVG QWK: 0.697\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.696\n[DEV] organization QWK: 0.722\n[DEV] word_choice QWK: 0.688\n[DEV] sentence_fluency QWK: 0.668\n[DEV] conventions QWK: 0.72\n[DEV] prompt_adherence QWK: 0.677\n[DEV] language QWK: 0.674\n[DEV] narrativity QWK: 0.668\n------------------------\n[TEST] AVG QWK: 0.563\n[TEST] score QWK: 0.614\n[TEST] content QWK: 0.534\n[TEST] prompt_adherence QWK: 0.569\n[TEST] language QWK: 0.533\n[TEST] narrativity QWK: 0.566\n------------------------\n[BEST TEST] AVG QWK: 0.563, {epoch}: 23\n[BEST TEST] score QWK: 0.614\n[BEST TEST] content QWK: 0.534\n[BEST TEST] prompt_adherence QWK: 0.569\n[BEST TEST] language QWK: 0.533\n[BEST TEST] narrativity QWK: 0.566\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01168860960751772 || Val Loss:  0.011683019809424877\nEpoch 24/50\nTraining one epoch in 235.602 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 24\n[DEV] AVG QWK: 0.698\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.696\n[DEV] organization QWK: 0.722\n[DEV] word_choice QWK: 0.688\n[DEV] sentence_fluency QWK: 0.669\n[DEV] conventions QWK: 0.721\n[DEV] prompt_adherence QWK: 0.678\n[DEV] language QWK: 0.675\n[DEV] narrativity QWK: 0.669\n------------------------\n[TEST] AVG QWK: 0.563\n[TEST] score QWK: 0.614\n[TEST] content QWK: 0.537\n[TEST] prompt_adherence QWK: 0.566\n[TEST] language QWK: 0.534\n[TEST] narrativity QWK: 0.566\n------------------------\n[BEST TEST] AVG QWK: 0.563, {epoch}: 24\n[BEST TEST] score QWK: 0.614\n[BEST TEST] content QWK: 0.537\n[BEST TEST] prompt_adherence QWK: 0.566\n[BEST TEST] language QWK: 0.534\n[BEST TEST] narrativity QWK: 0.566\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011674334295094013 || Val Loss:  0.011668499559164047\nEpoch 25/50\nTraining one epoch in 236.257 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 25\n[DEV] AVG QWK: 0.699\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.697\n[DEV] organization QWK: 0.723\n[DEV] word_choice QWK: 0.69\n[DEV] sentence_fluency QWK: 0.669\n[DEV] conventions QWK: 0.721\n[DEV] prompt_adherence QWK: 0.678\n[DEV] language QWK: 0.675\n[DEV] narrativity QWK: 0.669\n------------------------\n[TEST] AVG QWK: 0.564\n[TEST] score QWK: 0.617\n[TEST] content QWK: 0.537\n[TEST] prompt_adherence QWK: 0.57\n[TEST] language QWK: 0.533\n[TEST] narrativity QWK: 0.565\n------------------------\n[BEST TEST] AVG QWK: 0.564, {epoch}: 25\n[BEST TEST] score QWK: 0.617\n[BEST TEST] content QWK: 0.537\n[BEST TEST] prompt_adherence QWK: 0.57\n[BEST TEST] language QWK: 0.533\n[BEST TEST] narrativity QWK: 0.565\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01166106853634119 || Val Loss:  0.0116549888625741\nEpoch 26/50\nTraining one epoch in 235.562 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 26\n[DEV] AVG QWK: 0.699\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.697\n[DEV] organization QWK: 0.723\n[DEV] word_choice QWK: 0.69\n[DEV] sentence_fluency QWK: 0.669\n[DEV] conventions QWK: 0.722\n[DEV] prompt_adherence QWK: 0.679\n[DEV] language QWK: 0.676\n[DEV] narrativity QWK: 0.67\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.617\n[TEST] content QWK: 0.536\n[TEST] prompt_adherence QWK: 0.572\n[TEST] language QWK: 0.533\n[TEST] narrativity QWK: 0.566\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 26\n[BEST TEST] score QWK: 0.617\n[BEST TEST] content QWK: 0.536\n[BEST TEST] prompt_adherence QWK: 0.572\n[BEST TEST] language QWK: 0.533\n[BEST TEST] narrativity QWK: 0.566\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01164873968809843 || Val Loss:  0.011642378754913807\nEpoch 27/50\nTraining one epoch in 235.286 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 27\n[DEV] AVG QWK: 0.7\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.723\n[DEV] word_choice QWK: 0.691\n[DEV] sentence_fluency QWK: 0.669\n[DEV] conventions QWK: 0.723\n[DEV] prompt_adherence QWK: 0.679\n[DEV] language QWK: 0.676\n[DEV] narrativity QWK: 0.671\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.619\n[TEST] content QWK: 0.536\n[TEST] prompt_adherence QWK: 0.574\n[TEST] language QWK: 0.534\n[TEST] narrativity QWK: 0.563\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 27\n[BEST TEST] score QWK: 0.619\n[BEST TEST] content QWK: 0.536\n[BEST TEST] prompt_adherence QWK: 0.574\n[BEST TEST] language QWK: 0.534\n[BEST TEST] narrativity QWK: 0.563\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011637230403721333 || Val Loss:  0.011630584485828876\nEpoch 28/50\nTraining one epoch in 235.434 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 28\n[DEV] AVG QWK: 0.7\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.724\n[DEV] word_choice QWK: 0.692\n[DEV] sentence_fluency QWK: 0.67\n[DEV] conventions QWK: 0.723\n[DEV] prompt_adherence QWK: 0.68\n[DEV] language QWK: 0.677\n[DEV] narrativity QWK: 0.671\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.618\n[TEST] content QWK: 0.539\n[TEST] prompt_adherence QWK: 0.575\n[TEST] language QWK: 0.532\n[TEST] narrativity QWK: 0.561\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 28\n[BEST TEST] score QWK: 0.618\n[BEST TEST] content QWK: 0.539\n[BEST TEST] prompt_adherence QWK: 0.575\n[BEST TEST] language QWK: 0.532\n[BEST TEST] narrativity QWK: 0.561\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01162649504840374 || Val Loss:  0.011619530618190765\nEpoch 29/50\nTraining one epoch in 235.455 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 29\n[DEV] AVG QWK: 0.7\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.725\n[DEV] word_choice QWK: 0.693\n[DEV] sentence_fluency QWK: 0.67\n[DEV] conventions QWK: 0.723\n[DEV] prompt_adherence QWK: 0.681\n[DEV] language QWK: 0.677\n[DEV] narrativity QWK: 0.672\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.62\n[TEST] content QWK: 0.537\n[TEST] prompt_adherence QWK: 0.574\n[TEST] language QWK: 0.535\n[TEST] narrativity QWK: 0.56\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 29\n[BEST TEST] score QWK: 0.62\n[BEST TEST] content QWK: 0.537\n[BEST TEST] prompt_adherence QWK: 0.574\n[BEST TEST] language QWK: 0.535\n[BEST TEST] narrativity QWK: 0.56\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011616443283855915 || Val Loss:  0.011609150096774101\nEpoch 30/50\nTraining one epoch in 235.556 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 30\n[DEV] AVG QWK: 0.701\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.693\n[DEV] sentence_fluency QWK: 0.671\n[DEV] conventions QWK: 0.724\n[DEV] prompt_adherence QWK: 0.681\n[DEV] language QWK: 0.678\n[DEV] narrativity QWK: 0.672\n------------------------\n[TEST] AVG QWK: 0.566\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.537\n[TEST] prompt_adherence QWK: 0.574\n[TEST] language QWK: 0.535\n[TEST] narrativity QWK: 0.561\n------------------------\n[BEST TEST] AVG QWK: 0.566, {epoch}: 30\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.537\n[BEST TEST] prompt_adherence QWK: 0.574\n[BEST TEST] language QWK: 0.535\n[BEST TEST] narrativity QWK: 0.561\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011607004329562187 || Val Loss:  0.011599382385611534\nEpoch 31/50\nTraining one epoch in 235.702 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\nCURRENT EPOCH: 31\n[DEV] AVG QWK: 0.701\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.725\n[DEV] prompt_adherence QWK: 0.681\n[DEV] language QWK: 0.678\n[DEV] narrativity QWK: 0.673\n------------------------\n[TEST] AVG QWK: 0.566\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.538\n[TEST] prompt_adherence QWK: 0.573\n[TEST] language QWK: 0.536\n[TEST] narrativity QWK: 0.563\n------------------------\n[BEST TEST] AVG QWK: 0.566, {epoch}: 31\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.538\n[BEST TEST] prompt_adherence QWK: 0.573\n[BEST TEST] language QWK: 0.536\n[BEST TEST] narrativity QWK: 0.563\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011598152108490467 || Val Loss:  0.011590184643864632\nEpoch 32/50\nTraining one epoch in 235.725 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\nCURRENT EPOCH: 32\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.725\n[DEV] prompt_adherence QWK: 0.681\n[DEV] language QWK: 0.678\n[DEV] narrativity QWK: 0.673\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.536\n[TEST] prompt_adherence QWK: 0.57\n[TEST] language QWK: 0.534\n[TEST] narrativity QWK: 0.564\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 32\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.536\n[BEST TEST] prompt_adherence QWK: 0.57\n[BEST TEST] language QWK: 0.534\n[BEST TEST] narrativity QWK: 0.564\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011589817702770233 || Val Loss:  0.01158150378614664\nEpoch 33/50\nTraining one epoch in 236.433 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 33\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.673\n[DEV] conventions QWK: 0.726\n[DEV] prompt_adherence QWK: 0.681\n[DEV] language QWK: 0.678\n[DEV] narrativity QWK: 0.674\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.538\n[TEST] prompt_adherence QWK: 0.571\n[TEST] language QWK: 0.534\n[TEST] narrativity QWK: 0.562\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 33\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.538\n[BEST TEST] prompt_adherence QWK: 0.571\n[BEST TEST] language QWK: 0.534\n[BEST TEST] narrativity QWK: 0.562\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011581961996853352 || Val Loss:  0.01157329324632883\nEpoch 34/50\nTraining one epoch in 235.856 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 34\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.674\n[DEV] conventions QWK: 0.726\n[DEV] prompt_adherence QWK: 0.682\n[DEV] language QWK: 0.679\n[DEV] narrativity QWK: 0.674\n------------------------\n[TEST] AVG QWK: 0.566\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.539\n[TEST] prompt_adherence QWK: 0.572\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.562\n------------------------\n[BEST TEST] AVG QWK: 0.566, {epoch}: 34\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.539\n[BEST TEST] prompt_adherence QWK: 0.572\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.562\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011574536561965942 || Val Loss:  0.011565521359443665\nEpoch 35/50\nTraining one epoch in 235.438 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\nCURRENT EPOCH: 35\n[DEV] AVG QWK: 0.703\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.674\n[DEV] conventions QWK: 0.727\n[DEV] prompt_adherence QWK: 0.682\n[DEV] language QWK: 0.68\n[DEV] narrativity QWK: 0.674\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.538\n[TEST] prompt_adherence QWK: 0.573\n[TEST] language QWK: 0.536\n[TEST] narrativity QWK: 0.56\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 35\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.538\n[BEST TEST] prompt_adherence QWK: 0.573\n[BEST TEST] language QWK: 0.536\n[BEST TEST] narrativity QWK: 0.56\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011567539535462856 || Val Loss:  0.011558162979781628\nEpoch 36/50\nTraining one epoch in 235.688 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 36\n[DEV] AVG QWK: 0.703\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.7\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.695\n[DEV] sentence_fluency QWK: 0.675\n[DEV] conventions QWK: 0.727\n[DEV] prompt_adherence QWK: 0.682\n[DEV] language QWK: 0.68\n[DEV] narrativity QWK: 0.674\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.539\n[TEST] prompt_adherence QWK: 0.571\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.56\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 36\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.539\n[BEST TEST] prompt_adherence QWK: 0.571\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.56\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011560914106667042 || Val Loss:  0.01155116967856884\nEpoch 37/50\nTraining one epoch in 262.606 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 37\n[DEV] AVG QWK: 0.703\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.7\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.695\n[DEV] sentence_fluency QWK: 0.675\n[DEV] conventions QWK: 0.727\n[DEV] prompt_adherence QWK: 0.682\n[DEV] language QWK: 0.68\n[DEV] narrativity QWK: 0.674\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.621\n[TEST] content QWK: 0.539\n[TEST] prompt_adherence QWK: 0.571\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.556\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 37\n[BEST TEST] score QWK: 0.621\n[BEST TEST] content QWK: 0.539\n[BEST TEST] prompt_adherence QWK: 0.571\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.556\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01155463419854641 || Val Loss:  0.01154453493654728\nEpoch 38/50\nTraining one epoch in 236.827 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 38\n[DEV] AVG QWK: 0.703\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.695\n[DEV] sentence_fluency QWK: 0.676\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.683\n[DEV] language QWK: 0.681\n[DEV] narrativity QWK: 0.674\n------------------------\n[TEST] AVG QWK: 0.564\n[TEST] score QWK: 0.62\n[TEST] content QWK: 0.54\n[TEST] prompt_adherence QWK: 0.569\n[TEST] language QWK: 0.538\n[TEST] narrativity QWK: 0.555\n------------------------\n[BEST TEST] AVG QWK: 0.564, {epoch}: 38\n[BEST TEST] score QWK: 0.62\n[BEST TEST] content QWK: 0.54\n[BEST TEST] prompt_adherence QWK: 0.569\n[BEST TEST] language QWK: 0.538\n[BEST TEST] narrativity QWK: 0.555\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011548684909939766 || Val Loss:  0.011538208462297916\nEpoch 39/50\nTraining one epoch in 237.767 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 39\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.696\n[DEV] sentence_fluency QWK: 0.677\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.683\n[DEV] language QWK: 0.681\n[DEV] narrativity QWK: 0.675\n------------------------\n[TEST] AVG QWK: 0.564\n[TEST] score QWK: 0.619\n[TEST] content QWK: 0.539\n[TEST] prompt_adherence QWK: 0.569\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.555\n------------------------\n[BEST TEST] AVG QWK: 0.564, {epoch}: 39\n[BEST TEST] score QWK: 0.619\n[BEST TEST] content QWK: 0.539\n[BEST TEST] prompt_adherence QWK: 0.569\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.555\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011543022468686104 || Val Loss:  0.011532205156981945\nEpoch 40/50\nTraining one epoch in 236.709 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step\nCURRENT EPOCH: 40\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.696\n[DEV] sentence_fluency QWK: 0.678\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.683\n[DEV] language QWK: 0.681\n[DEV] narrativity QWK: 0.675\n------------------------\n[TEST] AVG QWK: 0.563\n[TEST] score QWK: 0.619\n[TEST] content QWK: 0.538\n[TEST] prompt_adherence QWK: 0.568\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.554\n------------------------\n[BEST TEST] AVG QWK: 0.563, {epoch}: 40\n[BEST TEST] score QWK: 0.619\n[BEST TEST] content QWK: 0.538\n[BEST TEST] prompt_adherence QWK: 0.568\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.554\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011537646874785423 || Val Loss:  0.011526471935212612\nEpoch 41/50\nTraining one epoch in 238.296 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step\nCURRENT EPOCH: 41\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.696\n[DEV] sentence_fluency QWK: 0.678\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.683\n[DEV] language QWK: 0.681\n[DEV] narrativity QWK: 0.676\n------------------------\n[TEST] AVG QWK: 0.563\n[TEST] score QWK: 0.62\n[TEST] content QWK: 0.539\n[TEST] prompt_adherence QWK: 0.568\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.553\n------------------------\n[BEST TEST] AVG QWK: 0.563, {epoch}: 41\n[BEST TEST] score QWK: 0.62\n[BEST TEST] content QWK: 0.539\n[BEST TEST] prompt_adherence QWK: 0.568\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.553\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01153254508972168 || Val Loss:  0.011521002277731895\nEpoch 42/50\nTraining one epoch in 238.017 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 42\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.678\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.681\n[DEV] narrativity QWK: 0.676\n------------------------\n[TEST] AVG QWK: 0.563\n[TEST] score QWK: 0.62\n[TEST] content QWK: 0.539\n[TEST] prompt_adherence QWK: 0.569\n[TEST] language QWK: 0.538\n[TEST] narrativity QWK: 0.552\n------------------------\n[BEST TEST] AVG QWK: 0.563, {epoch}: 42\n[BEST TEST] score QWK: 0.62\n[BEST TEST] content QWK: 0.539\n[BEST TEST] prompt_adherence QWK: 0.569\n[BEST TEST] language QWK: 0.538\n[BEST TEST] narrativity QWK: 0.552\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011527667753398418 || Val Loss:  0.011515780352056026\nEpoch 43/50\nTraining one epoch in 237.896 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step\nCURRENT EPOCH: 43\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.678\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.682\n[DEV] narrativity QWK: 0.676\n------------------------\n[TEST] AVG QWK: 0.564\n[TEST] score QWK: 0.622\n[TEST] content QWK: 0.54\n[TEST] prompt_adherence QWK: 0.569\n[TEST] language QWK: 0.538\n[TEST] narrativity QWK: 0.552\n------------------------\n[BEST TEST] AVG QWK: 0.564, {epoch}: 43\n[BEST TEST] score QWK: 0.622\n[BEST TEST] content QWK: 0.54\n[BEST TEST] prompt_adherence QWK: 0.569\n[BEST TEST] language QWK: 0.538\n[BEST TEST] narrativity QWK: 0.552\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011523031629621983 || Val Loss:  0.011510787531733513\nEpoch 44/50\nTraining one epoch in 237.602 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step\nCURRENT EPOCH: 44\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.679\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.681\n[DEV] narrativity QWK: 0.676\n------------------------\n[TEST] AVG QWK: 0.563\n[TEST] score QWK: 0.622\n[TEST] content QWK: 0.54\n[TEST] prompt_adherence QWK: 0.567\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.551\n------------------------\n[BEST TEST] AVG QWK: 0.563, {epoch}: 44\n[BEST TEST] score QWK: 0.622\n[BEST TEST] content QWK: 0.54\n[BEST TEST] prompt_adherence QWK: 0.567\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.551\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011518600396811962 || Val Loss:  0.011506014503538609\nEpoch 45/50\nTraining one epoch in 236.346 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 45\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.679\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.682\n[DEV] narrativity QWK: 0.677\n------------------------\n[TEST] AVG QWK: 0.563\n[TEST] score QWK: 0.622\n[TEST] content QWK: 0.54\n[TEST] prompt_adherence QWK: 0.568\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.549\n------------------------\n[BEST TEST] AVG QWK: 0.563, {epoch}: 45\n[BEST TEST] score QWK: 0.622\n[BEST TEST] content QWK: 0.54\n[BEST TEST] prompt_adherence QWK: 0.568\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.549\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011514377780258656 || Val Loss:  0.011501440778374672\nEpoch 46/50\nTraining one epoch in 234.014 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 46\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.679\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.682\n[DEV] narrativity QWK: 0.677\n------------------------\n[TEST] AVG QWK: 0.563\n[TEST] score QWK: 0.623\n[TEST] content QWK: 0.538\n[TEST] prompt_adherence QWK: 0.568\n[TEST] language QWK: 0.536\n[TEST] narrativity QWK: 0.55\n------------------------\n[BEST TEST] AVG QWK: 0.563, {epoch}: 46\n[BEST TEST] score QWK: 0.623\n[BEST TEST] content QWK: 0.538\n[BEST TEST] prompt_adherence QWK: 0.568\n[BEST TEST] language QWK: 0.536\n[BEST TEST] narrativity QWK: 0.55\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011510343290865421 || Val Loss:  0.011497065424919128\nEpoch 47/50\nTraining one epoch in 234.247 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 47\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.68\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.682\n[DEV] narrativity QWK: 0.677\n------------------------\n[TEST] AVG QWK: 0.563\n[TEST] score QWK: 0.623\n[TEST] content QWK: 0.539\n[TEST] prompt_adherence QWK: 0.569\n[TEST] language QWK: 0.535\n[TEST] narrativity QWK: 0.55\n------------------------\n[BEST TEST] AVG QWK: 0.563, {epoch}: 47\n[BEST TEST] score QWK: 0.623\n[BEST TEST] content QWK: 0.539\n[BEST TEST] prompt_adherence QWK: 0.569\n[BEST TEST] language QWK: 0.535\n[BEST TEST] narrativity QWK: 0.55\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01150648482143879 || Val Loss:  0.011492864228785038\nEpoch 48/50\nTraining one epoch in 235.714 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\nCURRENT EPOCH: 48\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.68\n[DEV] conventions QWK: 0.731\n[DEV] prompt_adherence QWK: 0.685\n[DEV] language QWK: 0.683\n[DEV] narrativity QWK: 0.677\n------------------------\n[TEST] AVG QWK: 0.563\n[TEST] score QWK: 0.624\n[TEST] content QWK: 0.539\n[TEST] prompt_adherence QWK: 0.568\n[TEST] language QWK: 0.535\n[TEST] narrativity QWK: 0.549\n------------------------\n[BEST TEST] AVG QWK: 0.563, {epoch}: 48\n[BEST TEST] score QWK: 0.624\n[BEST TEST] content QWK: 0.539\n[BEST TEST] prompt_adherence QWK: 0.568\n[BEST TEST] language QWK: 0.535\n[BEST TEST] narrativity QWK: 0.549\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011502791196107864 || Val Loss:  0.011488840915262699\nEpoch 49/50\nTraining one epoch in 235.947 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 49\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.681\n[DEV] conventions QWK: 0.731\n[DEV] prompt_adherence QWK: 0.685\n[DEV] language QWK: 0.683\n[DEV] narrativity QWK: 0.677\n------------------------\n[TEST] AVG QWK: 0.563\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.538\n[TEST] prompt_adherence QWK: 0.57\n[TEST] language QWK: 0.535\n[TEST] narrativity QWK: 0.55\n------------------------\n[BEST TEST] AVG QWK: 0.563, {epoch}: 49\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.538\n[BEST TEST] prompt_adherence QWK: 0.57\n[BEST TEST] language QWK: 0.535\n[BEST TEST] narrativity QWK: 0.55\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.0114992531016469 || Val Loss:  0.011484970338642597\nEpoch 50/50\nTraining one epoch in 234.896 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step\nCURRENT EPOCH: 50\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.68\n[DEV] conventions QWK: 0.731\n[DEV] prompt_adherence QWK: 0.685\n[DEV] language QWK: 0.683\n[DEV] narrativity QWK: 0.678\n------------------------\n[TEST] AVG QWK: 0.564\n[TEST] score QWK: 0.625\n[TEST] content QWK: 0.538\n[TEST] prompt_adherence QWK: 0.571\n[TEST] language QWK: 0.535\n[TEST] narrativity QWK: 0.551\n------------------------\n[BEST TEST] AVG QWK: 0.564, {epoch}: 50\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.538\n[BEST TEST] prompt_adherence QWK: 0.571\n[BEST TEST] language QWK: 0.535\n[BEST TEST] narrativity QWK: 0.551\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011495864950120449 || Val Loss:  0.011481264606118202\n[BEST TEST] AVG QWK: 0.564, {epoch}: 50\n[BEST TEST] score QWK: 0.625\n[BEST TEST] content QWK: 0.538\n[BEST TEST] prompt_adherence QWK: 0.571\n[BEST TEST] language QWK: 0.535\n[BEST TEST] narrativity QWK: 0.551\n--------------------------------------------------------------------------------------------------------------------------\nModel saved as 'trained_model/protact_model_prompt_6_seed_32.h5'\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}