{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-29T14:49:07.475750Z","iopub.execute_input":"2024-10-29T14:49:07.476494Z","iopub.status.idle":"2024-10-29T14:49:08.394729Z","shell.execute_reply.started":"2024-10-29T14:49:07.476450Z","shell.execute_reply":"2024-10-29T14:49:08.393759Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:49:08.396485Z","iopub.execute_input":"2024-10-29T14:49:08.396943Z","iopub.status.idle":"2024-10-29T14:49:21.664540Z","shell.execute_reply.started":"2024-10-29T14:49:08.396908Z","shell.execute_reply":"2024-10-29T14:49:21.663585Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/ishreya09/ProTACT.git","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:49:21.665920Z","iopub.execute_input":"2024-10-29T14:49:21.666222Z","iopub.status.idle":"2024-10-29T14:49:30.330534Z","shell.execute_reply.started":"2024-10-29T14:49:21.666189Z","shell.execute_reply":"2024-10-29T14:49:30.329419Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'ProTACT'...\nremote: Enumerating objects: 318, done.\u001b[K\nremote: Counting objects: 100% (7/7), done.\u001b[K\nremote: Compressing objects: 100% (7/7), done.\u001b[K\nremote: Total 318 (delta 0), reused 6 (delta 0), pack-reused 311 (from 1)\u001b[K\nReceiving objects: 100% (318/318), 146.60 MiB | 39.47 MiB/s, done.\nResolving deltas: 100% (173/173), done.\nUpdating files: 100% (136/136), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!cp -r /kaggle/working/ProTACT/* /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:49:30.333444Z","iopub.execute_input":"2024-10-29T14:49:30.334376Z","iopub.status.idle":"2024-10-29T14:49:31.828141Z","shell.execute_reply.started":"2024-10-29T14:49:30.334323Z","shell.execute_reply":"2024-10-29T14:49:31.826946Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!mkdir trained_model","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:49:31.829580Z","iopub.execute_input":"2024-10-29T14:49:31.829932Z","iopub.status.idle":"2024-10-29T14:49:32.819220Z","shell.execute_reply.started":"2024-10-29T14:49:31.829897Z","shell.execute_reply":"2024-10-29T14:49:32.818253Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'trained_model': File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"import gdown\nimport os\n\n# Create directory if it doesn't exist\nos.makedirs('embeddings', exist_ok=True)\n\n# https://drive.google.com/file/d/1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ/view?usp=sharing\n\n# Google Drive file ID\nfile_id = \"1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ\"\n\n# Download file to the specified directory\ngdown.download(f\"https://drive.google.com/uc?id={file_id}\", 'embeddings/glove.6B.50d.txt', quiet=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:49:32.820661Z","iopub.execute_input":"2024-10-29T14:49:32.820978Z","iopub.status.idle":"2024-10-29T14:49:39.477722Z","shell.execute_reply.started":"2024-10-29T14:49:32.820945Z","shell.execute_reply":"2024-10-29T14:49:39.476839Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ\nFrom (redirected): https://drive.google.com/uc?id=1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ&confirm=t&uuid=44452d97-0972-4259-8ecd-d9eaa35f24b0\nTo: /kaggle/working/embeddings/glove.6B.50d.txt\n100%|██████████| 171M/171M [00:02<00:00, 73.1MB/s] \n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'embeddings/glove.6B.50d.txt'"},"metadata":{}}]},{"cell_type":"code","source":"!bash /kaggle/working/train_prompt5_seed22.sh ","metadata":{"execution":{"iopub.status.busy":"2024-10-29T14:49:39.478988Z","iopub.execute_input":"2024-10-29T14:49:39.479431Z","iopub.status.idle":"2024-10-29T18:13:08.148338Z","shell.execute_reply.started":"2024-10-29T14:49:39.479398Z","shell.execute_reply":"2024-10-29T18:13:08.147053Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Test prompt id is 5 of type <class 'int'>\nSeed: 22\nNumhead :  2  | Features :  data/LDA/hand_crafted_final_5.csv  | Pos_emb :  50\n prompt_pos size: 8\n prompt_words size: 8\n pos_x size: 9494\n readability_x size: 9494\n pos_x size: 1677\n readability_x size: 1677\n pos_x size: 1805\n readability_x size: 1805\nLoading GloVe ...\nOOV number =188, OOV ratio = 0.047012\nmax sent length: 50\nmax sent num: 97\nmax prompt sent length: 18\nmax prompt sent num: 8\n================================\nX_train_pos:  (9494, 4850)\nX_train_prompt_words:  (9494, 4850)\nX_train_prompt_pos:  (9494, 4850)\nX_train_readability:  (9494, 35)\nX_train_ling:  (9494, 52)\nX_train_attribute_rel:  (9494, 9)\nY_train:  (9494, 9)\n================================\nX_dev_pos:  (1677, 4850)\nX_dev_prompt_words:  (1677, 4850)\nX_dev_prompt_pos:  (1677, 4850)\nX_dev_readability:  (1677, 35)\nX_dev_ling:  (1677, 52)\nX_dev_attribute_rel:  (1677, 9)\nY_dev:  (1677, 9)\n================================\nX_test_pos:  (1805, 4850)\nX_test_prompt_words:  (1805, 4850)\nX_test_prompt_pos:  (1805, 4850)\nX_test_readability:  (1805, 35)\nX_test_ling:  (1805, 52)\nX_test_attribute_rel:  (1805, 9)\nY_test:  (1805, 9)\n================================\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n\u001b[1mModel: \"functional_1\"\u001b[0m\n┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ prompt_word_input   │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_input    │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_input           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt (\u001b[94mEmbedding\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │    \u001b[32m200,000\u001b[0m │ prompt_word_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_1         │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ prompt_word_inpu… │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_prompt          │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │      \u001b[32m1,850\u001b[0m │ prompt_pos_input… │\n│ (\u001b[94mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_2         │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ prompt_pos_input… │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x (\u001b[94mEmbedding\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │      \u001b[32m1,850\u001b[0m │ pos_input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ pos_input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_maskedout    │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ prompt[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_maskedo… │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_prompt[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x_maskedout     │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_x[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (\u001b[94mAdd\u001b[0m)           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ prompt_maskedout… │\n│                     │                   │            │ prompt_pos_maske… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_drop_x          │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_x_maskedout[\u001b[32m…\u001b[0m │\n│ (\u001b[94mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_drop_x       │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ add[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]         │\n│ (\u001b[94mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_resh_W          │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m50\u001b[0m,    │          \u001b[32m0\u001b[0m │ pos_drop_x[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]  │\n│ (\u001b[94mReshape\u001b[0m)           │ \u001b[32m50\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_resh_W       │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m50\u001b[0m,    │          \u001b[32m0\u001b[0m │ prompt_drop_x[\u001b[32m0\u001b[0m]… │\n│ (\u001b[94mReshape\u001b[0m)           │ \u001b[32m50\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_zcnn            │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m46\u001b[0m,    │     \u001b[32m25,100\u001b[0m │ pos_resh_W[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]  │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │ \u001b[32m100\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_zcnn         │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m46\u001b[0m,    │     \u001b[32m25,100\u001b[0m │ prompt_resh_W[\u001b[32m0\u001b[0m]… │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │ \u001b[32m100\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_avg_zcnn        │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m100\u001b[0m)   │          \u001b[32m0\u001b[0m │ pos_zcnn[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_avg_zcnn     │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m100\u001b[0m)   │          \u001b[32m0\u001b[0m │ prompt_zcnn[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ prompt_avg_zcnn[\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (\u001b[94mLSTM\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_9 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_4 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_5 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_6 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_7 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_8 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_1         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]        │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_11        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_2         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_3         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_4         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_5         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_6         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_7         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_8         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_9         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_10 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_11 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_12 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_13 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_14 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_15 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_16 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_17 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_18 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_12        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_10[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ linguistic_input    │ (\u001b[96mNone\u001b[0m, \u001b[32m52\u001b[0m)        │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ readability_input   │ (\u001b[96mNone\u001b[0m, \u001b[32m35\u001b[0m)        │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_13        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_11[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_14        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_12[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_15        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_13[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_16        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_14[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_17        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_15[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_18        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_16[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_19        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_17[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_20        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_18[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_12[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_13[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_14[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_15[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_4       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_16[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_5       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_17[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_6       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_18[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_7       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_19[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_8       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_20[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (\u001b[94mLambda\u001b[0m)     │ (\u001b[96mNone\u001b[0m, \u001b[32m9\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ concatenate[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│                     │                   │            │ concatenate_1[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_2[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_3[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_4[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_5[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_6[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_7[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_8[\u001b[32m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (\u001b[94mGetItem\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_1 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_1          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_2 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_2          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_3 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_3          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_4 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_4          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_5 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_5          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_6 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_6          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_7 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_7          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_8 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_8          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_9 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_21        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_22        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_23        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_24        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_25        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_26        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_27        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_28        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_29        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_9       │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_21[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_10      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_22[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_11      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_23[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_12      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_24[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_13      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_25[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_14      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_26[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_15      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_27[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_16      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_28[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_17      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_29[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (\u001b[94mFlatten\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_9[\u001b[32m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_10[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_2 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_11[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_3 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_12[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_4 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_13[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_5 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_14[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_6 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_15[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_7 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_16[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_8 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_17[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_76 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_77 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_78 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_79 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_80 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_81 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_82 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_83 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_84 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_18      │ (\u001b[96mNone\u001b[0m, \u001b[32m9\u001b[0m)         │          \u001b[32m0\u001b[0m │ dense_76[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ dense_77[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_78[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_79[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_80[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_81[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_82[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_83[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_84[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n\u001b[1m Total params: \u001b[0m\u001b[32m2,552,475\u001b[0m (9.74 MB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,552,475\u001b[0m (9.74 MB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 418ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\n/kaggle/working/metrics/metrics.py:190: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  ret_score = pearsonr(y_true, y_pred)[0]\n/kaggle/working/metrics/metrics.py:172: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n  ret_score = spearmanr(y_true, y_pred)[0]\nCURRENT EPOCH: -1\n[DEV] AVG QWK: 0.025\n[DEV] score QWK: -0.059\n[DEV] content QWK: -0.03\n[DEV] organization QWK: 0.099\n[DEV] word_choice QWK: 0.086\n[DEV] sentence_fluency QWK: 0.069\n[DEV] conventions QWK: 0.04\n[DEV] prompt_adherence QWK: 0.063\n[DEV] language QWK: -0.025\n[DEV] narrativity QWK: -0.018\n------------------------\n[TEST] AVG QWK: -0.029\n[TEST] score QWK: 0.0\n[TEST] content QWK: -0.003\n[TEST] prompt_adherence QWK: 0.003\n[TEST] language QWK: -0.143\n[TEST] narrativity QWK: 0.0\n------------------------\n[BEST TEST] AVG QWK: -0.029, {epoch}: -1\n[BEST TEST] score QWK: 0.0\n[BEST TEST] content QWK: -0.003\n[BEST TEST] prompt_adherence QWK: 0.003\n[BEST TEST] language QWK: -0.143\n[BEST TEST] narrativity QWK: 0.0\n--------------------------------------------------------------------------------------------------------------------------\nEpoch 1/50\ntrait num:  9\ntrait num:  9\ntrait num:  9\nTraining one epoch in 373.238 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 1\n[DEV] AVG QWK: 0.591\n[DEV] score QWK: 0.709\n[DEV] content QWK: 0.578\n[DEV] organization QWK: 0.606\n[DEV] word_choice QWK: 0.597\n[DEV] sentence_fluency QWK: 0.557\n[DEV] conventions QWK: 0.563\n[DEV] prompt_adherence QWK: 0.564\n[DEV] language QWK: 0.561\n[DEV] narrativity QWK: 0.583\n------------------------\n[TEST] AVG QWK: 0.551\n[TEST] score QWK: 0.686\n[TEST] content QWK: 0.541\n[TEST] prompt_adherence QWK: 0.49\n[TEST] language QWK: 0.471\n[TEST] narrativity QWK: 0.566\n------------------------\n[BEST TEST] AVG QWK: 0.551, {epoch}: 1\n[BEST TEST] score QWK: 0.686\n[BEST TEST] content QWK: 0.541\n[BEST TEST] prompt_adherence QWK: 0.49\n[BEST TEST] language QWK: 0.471\n[BEST TEST] narrativity QWK: 0.566\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.017198113724589348 || Val Loss:  0.014170967042446136\nEpoch 2/50\nTraining one epoch in 229.446 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 2\n[DEV] AVG QWK: 0.632\n[DEV] score QWK: 0.727\n[DEV] content QWK: 0.622\n[DEV] organization QWK: 0.654\n[DEV] word_choice QWK: 0.633\n[DEV] sentence_fluency QWK: 0.597\n[DEV] conventions QWK: 0.629\n[DEV] prompt_adherence QWK: 0.608\n[DEV] language QWK: 0.599\n[DEV] narrativity QWK: 0.622\n------------------------\n[TEST] AVG QWK: 0.565\n[TEST] score QWK: 0.701\n[TEST] content QWK: 0.588\n[TEST] prompt_adherence QWK: 0.503\n[TEST] language QWK: 0.466\n[TEST] narrativity QWK: 0.565\n------------------------\n[BEST TEST] AVG QWK: 0.565, {epoch}: 2\n[BEST TEST] score QWK: 0.701\n[BEST TEST] content QWK: 0.588\n[BEST TEST] prompt_adherence QWK: 0.503\n[BEST TEST] language QWK: 0.466\n[BEST TEST] narrativity QWK: 0.565\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.0141352703794837 || Val Loss:  0.013294876553118229\nEpoch 3/50\nTraining one epoch in 229.123 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 3\n[DEV] AVG QWK: 0.65\n[DEV] score QWK: 0.737\n[DEV] content QWK: 0.642\n[DEV] organization QWK: 0.674\n[DEV] word_choice QWK: 0.648\n[DEV] sentence_fluency QWK: 0.613\n[DEV] conventions QWK: 0.658\n[DEV] prompt_adherence QWK: 0.626\n[DEV] language QWK: 0.616\n[DEV] narrativity QWK: 0.638\n------------------------\n[TEST] AVG QWK: 0.569\n[TEST] score QWK: 0.714\n[TEST] content QWK: 0.603\n[TEST] prompt_adherence QWK: 0.509\n[TEST] language QWK: 0.464\n[TEST] narrativity QWK: 0.558\n------------------------\n[BEST TEST] AVG QWK: 0.569, {epoch}: 3\n[BEST TEST] score QWK: 0.714\n[BEST TEST] content QWK: 0.603\n[BEST TEST] prompt_adherence QWK: 0.509\n[BEST TEST] language QWK: 0.464\n[BEST TEST] narrativity QWK: 0.558\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.013496631756424904 || Val Loss:  0.012864206917583942\nEpoch 4/50\nTraining one epoch in 229.041 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 4\n[DEV] AVG QWK: 0.661\n[DEV] score QWK: 0.743\n[DEV] content QWK: 0.653\n[DEV] organization QWK: 0.686\n[DEV] word_choice QWK: 0.656\n[DEV] sentence_fluency QWK: 0.622\n[DEV] conventions QWK: 0.674\n[DEV] prompt_adherence QWK: 0.637\n[DEV] language QWK: 0.626\n[DEV] narrativity QWK: 0.647\n------------------------\n[TEST] AVG QWK: 0.58\n[TEST] score QWK: 0.717\n[TEST] content QWK: 0.613\n[TEST] prompt_adherence QWK: 0.527\n[TEST] language QWK: 0.471\n[TEST] narrativity QWK: 0.575\n------------------------\n[BEST TEST] AVG QWK: 0.58, {epoch}: 4\n[BEST TEST] score QWK: 0.717\n[BEST TEST] content QWK: 0.613\n[BEST TEST] prompt_adherence QWK: 0.527\n[BEST TEST] language QWK: 0.471\n[BEST TEST] narrativity QWK: 0.575\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.013139891438186169 || Val Loss:  0.012589340098202229\nEpoch 5/50\nTraining one epoch in 229.346 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 5\n[DEV] AVG QWK: 0.668\n[DEV] score QWK: 0.747\n[DEV] content QWK: 0.662\n[DEV] organization QWK: 0.692\n[DEV] word_choice QWK: 0.663\n[DEV] sentence_fluency QWK: 0.631\n[DEV] conventions QWK: 0.685\n[DEV] prompt_adherence QWK: 0.646\n[DEV] language QWK: 0.633\n[DEV] narrativity QWK: 0.654\n------------------------\n[TEST] AVG QWK: 0.586\n[TEST] score QWK: 0.72\n[TEST] content QWK: 0.617\n[TEST] prompt_adherence QWK: 0.532\n[TEST] language QWK: 0.476\n[TEST] narrativity QWK: 0.585\n------------------------\n[BEST TEST] AVG QWK: 0.586, {epoch}: 5\n[BEST TEST] score QWK: 0.72\n[BEST TEST] content QWK: 0.617\n[BEST TEST] prompt_adherence QWK: 0.532\n[BEST TEST] language QWK: 0.476\n[BEST TEST] narrativity QWK: 0.585\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012900150381028652 || Val Loss:  0.012394620105624199\nEpoch 6/50\nTraining one epoch in 228.531 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 6\n[DEV] AVG QWK: 0.674\n[DEV] score QWK: 0.75\n[DEV] content QWK: 0.668\n[DEV] organization QWK: 0.699\n[DEV] word_choice QWK: 0.668\n[DEV] sentence_fluency QWK: 0.635\n[DEV] conventions QWK: 0.692\n[DEV] prompt_adherence QWK: 0.651\n[DEV] language QWK: 0.639\n[DEV] narrativity QWK: 0.659\n------------------------\n[TEST] AVG QWK: 0.593\n[TEST] score QWK: 0.724\n[TEST] content QWK: 0.626\n[TEST] prompt_adherence QWK: 0.536\n[TEST] language QWK: 0.489\n[TEST] narrativity QWK: 0.591\n------------------------\n[BEST TEST] AVG QWK: 0.593, {epoch}: 6\n[BEST TEST] score QWK: 0.724\n[BEST TEST] content QWK: 0.626\n[BEST TEST] prompt_adherence QWK: 0.536\n[BEST TEST] language QWK: 0.489\n[BEST TEST] narrativity QWK: 0.591\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012724519707262516 || Val Loss:  0.012248200364410877\nEpoch 7/50\nTraining one epoch in 227.534 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 7\n[DEV] AVG QWK: 0.678\n[DEV] score QWK: 0.754\n[DEV] content QWK: 0.673\n[DEV] organization QWK: 0.703\n[DEV] word_choice QWK: 0.671\n[DEV] sentence_fluency QWK: 0.639\n[DEV] conventions QWK: 0.698\n[DEV] prompt_adherence QWK: 0.656\n[DEV] language QWK: 0.643\n[DEV] narrativity QWK: 0.663\n------------------------\n[TEST] AVG QWK: 0.598\n[TEST] score QWK: 0.726\n[TEST] content QWK: 0.629\n[TEST] prompt_adherence QWK: 0.545\n[TEST] language QWK: 0.494\n[TEST] narrativity QWK: 0.597\n------------------------\n[BEST TEST] AVG QWK: 0.598, {epoch}: 7\n[BEST TEST] score QWK: 0.726\n[BEST TEST] content QWK: 0.629\n[BEST TEST] prompt_adherence QWK: 0.545\n[BEST TEST] language QWK: 0.494\n[BEST TEST] narrativity QWK: 0.597\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012588895857334137 || Val Loss:  0.01213352382183075\nEpoch 8/50\nTraining one epoch in 228.089 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 8\n[DEV] AVG QWK: 0.681\n[DEV] score QWK: 0.756\n[DEV] content QWK: 0.677\n[DEV] organization QWK: 0.706\n[DEV] word_choice QWK: 0.674\n[DEV] sentence_fluency QWK: 0.642\n[DEV] conventions QWK: 0.703\n[DEV] prompt_adherence QWK: 0.66\n[DEV] language QWK: 0.647\n[DEV] narrativity QWK: 0.666\n------------------------\n[TEST] AVG QWK: 0.604\n[TEST] score QWK: 0.728\n[TEST] content QWK: 0.637\n[TEST] prompt_adherence QWK: 0.553\n[TEST] language QWK: 0.497\n[TEST] narrativity QWK: 0.604\n------------------------\n[BEST TEST] AVG QWK: 0.604, {epoch}: 8\n[BEST TEST] score QWK: 0.728\n[BEST TEST] content QWK: 0.637\n[BEST TEST] prompt_adherence QWK: 0.553\n[BEST TEST] language QWK: 0.497\n[BEST TEST] narrativity QWK: 0.604\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012480310164391994 || Val Loss:  0.012040946632623672\nEpoch 9/50\nTraining one epoch in 227.757 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 9\n[DEV] AVG QWK: 0.684\n[DEV] score QWK: 0.758\n[DEV] content QWK: 0.68\n[DEV] organization QWK: 0.709\n[DEV] word_choice QWK: 0.676\n[DEV] sentence_fluency QWK: 0.645\n[DEV] conventions QWK: 0.707\n[DEV] prompt_adherence QWK: 0.663\n[DEV] language QWK: 0.65\n[DEV] narrativity QWK: 0.669\n------------------------\n[TEST] AVG QWK: 0.608\n[TEST] score QWK: 0.734\n[TEST] content QWK: 0.638\n[TEST] prompt_adherence QWK: 0.561\n[TEST] language QWK: 0.5\n[TEST] narrativity QWK: 0.609\n------------------------\n[BEST TEST] AVG QWK: 0.608, {epoch}: 9\n[BEST TEST] score QWK: 0.734\n[BEST TEST] content QWK: 0.638\n[BEST TEST] prompt_adherence QWK: 0.561\n[BEST TEST] language QWK: 0.5\n[BEST TEST] narrativity QWK: 0.609\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01239105500280857 || Val Loss:  0.011964447796344757\nEpoch 10/50\nTraining one epoch in 228.639 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 10\n[DEV] AVG QWK: 0.686\n[DEV] score QWK: 0.76\n[DEV] content QWK: 0.683\n[DEV] organization QWK: 0.71\n[DEV] word_choice QWK: 0.678\n[DEV] sentence_fluency QWK: 0.647\n[DEV] conventions QWK: 0.709\n[DEV] prompt_adherence QWK: 0.666\n[DEV] language QWK: 0.652\n[DEV] narrativity QWK: 0.671\n------------------------\n[TEST] AVG QWK: 0.612\n[TEST] score QWK: 0.735\n[TEST] content QWK: 0.642\n[TEST] prompt_adherence QWK: 0.569\n[TEST] language QWK: 0.506\n[TEST] narrativity QWK: 0.609\n------------------------\n[BEST TEST] AVG QWK: 0.612, {epoch}: 10\n[BEST TEST] score QWK: 0.735\n[BEST TEST] content QWK: 0.642\n[BEST TEST] prompt_adherence QWK: 0.569\n[BEST TEST] language QWK: 0.506\n[BEST TEST] narrativity QWK: 0.609\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012316208332777023 || Val Loss:  0.011900072917342186\nEpoch 11/50\nTraining one epoch in 227.904 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 11\n[DEV] AVG QWK: 0.688\n[DEV] score QWK: 0.761\n[DEV] content QWK: 0.685\n[DEV] organization QWK: 0.713\n[DEV] word_choice QWK: 0.679\n[DEV] sentence_fluency QWK: 0.649\n[DEV] conventions QWK: 0.711\n[DEV] prompt_adherence QWK: 0.668\n[DEV] language QWK: 0.655\n[DEV] narrativity QWK: 0.672\n------------------------\n[TEST] AVG QWK: 0.614\n[TEST] score QWK: 0.736\n[TEST] content QWK: 0.642\n[TEST] prompt_adherence QWK: 0.573\n[TEST] language QWK: 0.512\n[TEST] narrativity QWK: 0.608\n------------------------\n[BEST TEST] AVG QWK: 0.614, {epoch}: 11\n[BEST TEST] score QWK: 0.736\n[BEST TEST] content QWK: 0.642\n[BEST TEST] prompt_adherence QWK: 0.573\n[BEST TEST] language QWK: 0.512\n[BEST TEST] narrativity QWK: 0.608\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012252435088157654 || Val Loss:  0.011845051310956478\nEpoch 12/50\nTraining one epoch in 227.308 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 12\n[DEV] AVG QWK: 0.69\n[DEV] score QWK: 0.761\n[DEV] content QWK: 0.687\n[DEV] organization QWK: 0.715\n[DEV] word_choice QWK: 0.681\n[DEV] sentence_fluency QWK: 0.651\n[DEV] conventions QWK: 0.713\n[DEV] prompt_adherence QWK: 0.67\n[DEV] language QWK: 0.656\n[DEV] narrativity QWK: 0.675\n------------------------\n[TEST] AVG QWK: 0.617\n[TEST] score QWK: 0.738\n[TEST] content QWK: 0.641\n[TEST] prompt_adherence QWK: 0.577\n[TEST] language QWK: 0.518\n[TEST] narrativity QWK: 0.611\n------------------------\n[BEST TEST] AVG QWK: 0.617, {epoch}: 12\n[BEST TEST] score QWK: 0.738\n[BEST TEST] content QWK: 0.641\n[BEST TEST] prompt_adherence QWK: 0.577\n[BEST TEST] language QWK: 0.518\n[BEST TEST] narrativity QWK: 0.611\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012197405099868774 || Val Loss:  0.011797464452683926\nEpoch 13/50\nTraining one epoch in 227.400 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 13\n[DEV] AVG QWK: 0.692\n[DEV] score QWK: 0.763\n[DEV] content QWK: 0.689\n[DEV] organization QWK: 0.717\n[DEV] word_choice QWK: 0.683\n[DEV] sentence_fluency QWK: 0.654\n[DEV] conventions QWK: 0.715\n[DEV] prompt_adherence QWK: 0.673\n[DEV] language QWK: 0.659\n[DEV] narrativity QWK: 0.676\n------------------------\n[TEST] AVG QWK: 0.62\n[TEST] score QWK: 0.737\n[TEST] content QWK: 0.646\n[TEST] prompt_adherence QWK: 0.581\n[TEST] language QWK: 0.521\n[TEST] narrativity QWK: 0.614\n------------------------\n[BEST TEST] AVG QWK: 0.62, {epoch}: 13\n[BEST TEST] score QWK: 0.737\n[BEST TEST] content QWK: 0.646\n[BEST TEST] prompt_adherence QWK: 0.581\n[BEST TEST] language QWK: 0.521\n[BEST TEST] narrativity QWK: 0.614\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012149432674050331 || Val Loss:  0.011755864135921001\nEpoch 14/50\nTraining one epoch in 227.727 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 14\n[DEV] AVG QWK: 0.693\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.69\n[DEV] organization QWK: 0.718\n[DEV] word_choice QWK: 0.684\n[DEV] sentence_fluency QWK: 0.655\n[DEV] conventions QWK: 0.717\n[DEV] prompt_adherence QWK: 0.674\n[DEV] language QWK: 0.66\n[DEV] narrativity QWK: 0.677\n------------------------\n[TEST] AVG QWK: 0.621\n[TEST] score QWK: 0.736\n[TEST] content QWK: 0.645\n[TEST] prompt_adherence QWK: 0.583\n[TEST] language QWK: 0.522\n[TEST] narrativity QWK: 0.618\n------------------------\n[BEST TEST] AVG QWK: 0.621, {epoch}: 14\n[BEST TEST] score QWK: 0.736\n[BEST TEST] content QWK: 0.645\n[BEST TEST] prompt_adherence QWK: 0.583\n[BEST TEST] language QWK: 0.522\n[BEST TEST] narrativity QWK: 0.618\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.0121072456240654 || Val Loss:  0.0117191718891263\nEpoch 15/50\nTraining one epoch in 262.602 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 15\n[DEV] AVG QWK: 0.694\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.692\n[DEV] organization QWK: 0.719\n[DEV] word_choice QWK: 0.685\n[DEV] sentence_fluency QWK: 0.655\n[DEV] conventions QWK: 0.719\n[DEV] prompt_adherence QWK: 0.676\n[DEV] language QWK: 0.661\n[DEV] narrativity QWK: 0.678\n------------------------\n[TEST] AVG QWK: 0.623\n[TEST] score QWK: 0.735\n[TEST] content QWK: 0.647\n[TEST] prompt_adherence QWK: 0.589\n[TEST] language QWK: 0.523\n[TEST] narrativity QWK: 0.62\n------------------------\n[BEST TEST] AVG QWK: 0.623, {epoch}: 15\n[BEST TEST] score QWK: 0.735\n[BEST TEST] content QWK: 0.647\n[BEST TEST] prompt_adherence QWK: 0.589\n[BEST TEST] language QWK: 0.523\n[BEST TEST] narrativity QWK: 0.62\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01206982135772705 || Val Loss:  0.011686568148434162\nEpoch 16/50\nTraining one epoch in 226.764 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 16\n[DEV] AVG QWK: 0.696\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.693\n[DEV] organization QWK: 0.72\n[DEV] word_choice QWK: 0.686\n[DEV] sentence_fluency QWK: 0.656\n[DEV] conventions QWK: 0.72\n[DEV] prompt_adherence QWK: 0.677\n[DEV] language QWK: 0.663\n[DEV] narrativity QWK: 0.68\n------------------------\n[TEST] AVG QWK: 0.625\n[TEST] score QWK: 0.736\n[TEST] content QWK: 0.649\n[TEST] prompt_adherence QWK: 0.588\n[TEST] language QWK: 0.529\n[TEST] narrativity QWK: 0.622\n------------------------\n[BEST TEST] AVG QWK: 0.625, {epoch}: 16\n[BEST TEST] score QWK: 0.736\n[BEST TEST] content QWK: 0.649\n[BEST TEST] prompt_adherence QWK: 0.588\n[BEST TEST] language QWK: 0.529\n[BEST TEST] narrativity QWK: 0.622\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012036456726491451 || Val Loss:  0.011657395400106907\nEpoch 17/50\nTraining one epoch in 226.914 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step\nCURRENT EPOCH: 17\n[DEV] AVG QWK: 0.696\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.694\n[DEV] organization QWK: 0.721\n[DEV] word_choice QWK: 0.688\n[DEV] sentence_fluency QWK: 0.657\n[DEV] conventions QWK: 0.72\n[DEV] prompt_adherence QWK: 0.678\n[DEV] language QWK: 0.664\n[DEV] narrativity QWK: 0.68\n------------------------\n[TEST] AVG QWK: 0.627\n[TEST] score QWK: 0.738\n[TEST] content QWK: 0.65\n[TEST] prompt_adherence QWK: 0.591\n[TEST] language QWK: 0.531\n[TEST] narrativity QWK: 0.622\n------------------------\n[BEST TEST] AVG QWK: 0.627, {epoch}: 17\n[BEST TEST] score QWK: 0.738\n[BEST TEST] content QWK: 0.65\n[BEST TEST] prompt_adherence QWK: 0.591\n[BEST TEST] language QWK: 0.531\n[BEST TEST] narrativity QWK: 0.622\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012006520293653011 || Val Loss:  0.011631138622760773\nEpoch 18/50\nTraining one epoch in 226.158 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 18\n[DEV] AVG QWK: 0.697\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.695\n[DEV] organization QWK: 0.722\n[DEV] word_choice QWK: 0.689\n[DEV] sentence_fluency QWK: 0.658\n[DEV] conventions QWK: 0.722\n[DEV] prompt_adherence QWK: 0.679\n[DEV] language QWK: 0.664\n[DEV] narrativity QWK: 0.682\n------------------------\n[TEST] AVG QWK: 0.63\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.654\n[TEST] prompt_adherence QWK: 0.594\n[TEST] language QWK: 0.535\n[TEST] narrativity QWK: 0.626\n------------------------\n[BEST TEST] AVG QWK: 0.63, {epoch}: 18\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.654\n[BEST TEST] prompt_adherence QWK: 0.594\n[BEST TEST] language QWK: 0.535\n[BEST TEST] narrativity QWK: 0.626\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01197949331253767 || Val Loss:  0.011607376858592033\nEpoch 19/50\nTraining one epoch in 221.387 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 19\n[DEV] AVG QWK: 0.698\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.696\n[DEV] organization QWK: 0.722\n[DEV] word_choice QWK: 0.689\n[DEV] sentence_fluency QWK: 0.659\n[DEV] conventions QWK: 0.722\n[DEV] prompt_adherence QWK: 0.68\n[DEV] language QWK: 0.665\n[DEV] narrativity QWK: 0.682\n------------------------\n[TEST] AVG QWK: 0.631\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.655\n[TEST] prompt_adherence QWK: 0.597\n[TEST] language QWK: 0.536\n[TEST] narrativity QWK: 0.627\n------------------------\n[BEST TEST] AVG QWK: 0.631, {epoch}: 19\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.655\n[BEST TEST] prompt_adherence QWK: 0.597\n[BEST TEST] language QWK: 0.536\n[BEST TEST] narrativity QWK: 0.627\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011955000460147858 || Val Loss:  0.011585774831473827\nEpoch 20/50\nTraining one epoch in 221.664 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 20\n[DEV] AVG QWK: 0.699\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.697\n[DEV] organization QWK: 0.723\n[DEV] word_choice QWK: 0.689\n[DEV] sentence_fluency QWK: 0.66\n[DEV] conventions QWK: 0.723\n[DEV] prompt_adherence QWK: 0.681\n[DEV] language QWK: 0.666\n[DEV] narrativity QWK: 0.683\n------------------------\n[TEST] AVG QWK: 0.631\n[TEST] score QWK: 0.739\n[TEST] content QWK: 0.657\n[TEST] prompt_adherence QWK: 0.597\n[TEST] language QWK: 0.536\n[TEST] narrativity QWK: 0.628\n------------------------\n[BEST TEST] AVG QWK: 0.631, {epoch}: 20\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.657\n[BEST TEST] prompt_adherence QWK: 0.597\n[BEST TEST] language QWK: 0.536\n[BEST TEST] narrativity QWK: 0.628\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011932688765227795 || Val Loss:  0.011566054075956345\nEpoch 21/50\nTraining one epoch in 220.547 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 21\n[DEV] AVG QWK: 0.7\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.724\n[DEV] word_choice QWK: 0.69\n[DEV] sentence_fluency QWK: 0.661\n[DEV] conventions QWK: 0.724\n[DEV] prompt_adherence QWK: 0.682\n[DEV] language QWK: 0.667\n[DEV] narrativity QWK: 0.684\n------------------------\n[TEST] AVG QWK: 0.632\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.657\n[TEST] prompt_adherence QWK: 0.598\n[TEST] language QWK: 0.537\n[TEST] narrativity QWK: 0.628\n------------------------\n[BEST TEST] AVG QWK: 0.632, {epoch}: 21\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.657\n[BEST TEST] prompt_adherence QWK: 0.598\n[BEST TEST] language QWK: 0.537\n[BEST TEST] narrativity QWK: 0.628\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011912300251424313 || Val Loss:  0.011547979898750782\nEpoch 22/50\nTraining one epoch in 221.497 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 22\n[DEV] AVG QWK: 0.7\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.725\n[DEV] word_choice QWK: 0.691\n[DEV] sentence_fluency QWK: 0.661\n[DEV] conventions QWK: 0.724\n[DEV] prompt_adherence QWK: 0.683\n[DEV] language QWK: 0.668\n[DEV] narrativity QWK: 0.684\n------------------------\n[TEST] AVG QWK: 0.634\n[TEST] score QWK: 0.738\n[TEST] content QWK: 0.658\n[TEST] prompt_adherence QWK: 0.601\n[TEST] language QWK: 0.539\n[TEST] narrativity QWK: 0.633\n------------------------\n[BEST TEST] AVG QWK: 0.634, {epoch}: 22\n[BEST TEST] score QWK: 0.738\n[BEST TEST] content QWK: 0.658\n[BEST TEST] prompt_adherence QWK: 0.601\n[BEST TEST] language QWK: 0.539\n[BEST TEST] narrativity QWK: 0.633\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011893593706190586 || Val Loss:  0.011531350202858448\nEpoch 23/50\nTraining one epoch in 221.578 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 23\n[DEV] AVG QWK: 0.701\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.7\n[DEV] organization QWK: 0.725\n[DEV] word_choice QWK: 0.692\n[DEV] sentence_fluency QWK: 0.661\n[DEV] conventions QWK: 0.725\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.669\n[DEV] narrativity QWK: 0.686\n------------------------\n[TEST] AVG QWK: 0.634\n[TEST] score QWK: 0.737\n[TEST] content QWK: 0.658\n[TEST] prompt_adherence QWK: 0.601\n[TEST] language QWK: 0.54\n[TEST] narrativity QWK: 0.635\n------------------------\n[BEST TEST] AVG QWK: 0.634, {epoch}: 23\n[BEST TEST] score QWK: 0.737\n[BEST TEST] content QWK: 0.658\n[BEST TEST] prompt_adherence QWK: 0.601\n[BEST TEST] language QWK: 0.54\n[BEST TEST] narrativity QWK: 0.635\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011876357719302177 || Val Loss:  0.011516003869473934\nEpoch 24/50\nTraining one epoch in 223.833 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 24\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.7\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.662\n[DEV] conventions QWK: 0.726\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.669\n[DEV] narrativity QWK: 0.687\n------------------------\n[TEST] AVG QWK: 0.635\n[TEST] score QWK: 0.738\n[TEST] content QWK: 0.659\n[TEST] prompt_adherence QWK: 0.602\n[TEST] language QWK: 0.541\n[TEST] narrativity QWK: 0.636\n------------------------\n[BEST TEST] AVG QWK: 0.635, {epoch}: 24\n[BEST TEST] score QWK: 0.738\n[BEST TEST] content QWK: 0.659\n[BEST TEST] prompt_adherence QWK: 0.602\n[BEST TEST] language QWK: 0.541\n[BEST TEST] narrativity QWK: 0.636\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011860457248985767 || Val Loss:  0.01150179747492075\nEpoch 25/50\nTraining one epoch in 222.123 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 25\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.7\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.663\n[DEV] conventions QWK: 0.727\n[DEV] prompt_adherence QWK: 0.685\n[DEV] language QWK: 0.67\n[DEV] narrativity QWK: 0.687\n------------------------\n[TEST] AVG QWK: 0.636\n[TEST] score QWK: 0.738\n[TEST] content QWK: 0.659\n[TEST] prompt_adherence QWK: 0.603\n[TEST] language QWK: 0.544\n[TEST] narrativity QWK: 0.637\n------------------------\n[BEST TEST] AVG QWK: 0.636, {epoch}: 25\n[BEST TEST] score QWK: 0.738\n[BEST TEST] content QWK: 0.659\n[BEST TEST] prompt_adherence QWK: 0.603\n[BEST TEST] language QWK: 0.544\n[BEST TEST] narrativity QWK: 0.637\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01184573583304882 || Val Loss:  0.011488609947264194\nEpoch 26/50\nTraining one epoch in 221.254 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 26\n[DEV] AVG QWK: 0.703\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.664\n[DEV] conventions QWK: 0.727\n[DEV] prompt_adherence QWK: 0.685\n[DEV] language QWK: 0.67\n[DEV] narrativity QWK: 0.688\n------------------------\n[TEST] AVG QWK: 0.638\n[TEST] score QWK: 0.737\n[TEST] content QWK: 0.66\n[TEST] prompt_adherence QWK: 0.607\n[TEST] language QWK: 0.55\n[TEST] narrativity QWK: 0.639\n------------------------\n[BEST TEST] AVG QWK: 0.638, {epoch}: 26\n[BEST TEST] score QWK: 0.737\n[BEST TEST] content QWK: 0.66\n[BEST TEST] prompt_adherence QWK: 0.607\n[BEST TEST] language QWK: 0.55\n[BEST TEST] narrativity QWK: 0.639\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011832034215331078 || Val Loss:  0.011476345360279083\nEpoch 27/50\nTraining one epoch in 220.380 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 27\n[DEV] AVG QWK: 0.703\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.664\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.686\n[DEV] language QWK: 0.67\n[DEV] narrativity QWK: 0.689\n------------------------\n[TEST] AVG QWK: 0.639\n[TEST] score QWK: 0.738\n[TEST] content QWK: 0.661\n[TEST] prompt_adherence QWK: 0.608\n[TEST] language QWK: 0.55\n[TEST] narrativity QWK: 0.64\n------------------------\n[BEST TEST] AVG QWK: 0.639, {epoch}: 27\n[BEST TEST] score QWK: 0.738\n[BEST TEST] content QWK: 0.661\n[BEST TEST] prompt_adherence QWK: 0.608\n[BEST TEST] language QWK: 0.55\n[BEST TEST] narrativity QWK: 0.64\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011819282546639442 || Val Loss:  0.011464894749224186\nEpoch 28/50\nTraining one epoch in 220.511 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 28\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.695\n[DEV] sentence_fluency QWK: 0.665\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.686\n[DEV] language QWK: 0.67\n[DEV] narrativity QWK: 0.689\n------------------------\n[TEST] AVG QWK: 0.641\n[TEST] score QWK: 0.739\n[TEST] content QWK: 0.662\n[TEST] prompt_adherence QWK: 0.609\n[TEST] language QWK: 0.553\n[TEST] narrativity QWK: 0.641\n------------------------\n[BEST TEST] AVG QWK: 0.641, {epoch}: 28\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.662\n[BEST TEST] prompt_adherence QWK: 0.609\n[BEST TEST] language QWK: 0.553\n[BEST TEST] narrativity QWK: 0.641\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011807391420006752 || Val Loss:  0.011454199440777302\nEpoch 29/50\nTraining one epoch in 220.856 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 29\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.695\n[DEV] sentence_fluency QWK: 0.666\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.687\n[DEV] language QWK: 0.671\n[DEV] narrativity QWK: 0.689\n------------------------\n[TEST] AVG QWK: 0.641\n[TEST] score QWK: 0.738\n[TEST] content QWK: 0.66\n[TEST] prompt_adherence QWK: 0.61\n[TEST] language QWK: 0.553\n[TEST] narrativity QWK: 0.643\n------------------------\n[BEST TEST] AVG QWK: 0.641, {epoch}: 29\n[BEST TEST] score QWK: 0.738\n[BEST TEST] content QWK: 0.66\n[BEST TEST] prompt_adherence QWK: 0.61\n[BEST TEST] language QWK: 0.553\n[BEST TEST] narrativity QWK: 0.643\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01179625652730465 || Val Loss:  0.01144417840987444\nEpoch 30/50\nTraining one epoch in 221.596 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 30\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.703\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.696\n[DEV] sentence_fluency QWK: 0.666\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.688\n[DEV] language QWK: 0.672\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.643\n[TEST] score QWK: 0.739\n[TEST] content QWK: 0.66\n[TEST] prompt_adherence QWK: 0.614\n[TEST] language QWK: 0.559\n[TEST] narrativity QWK: 0.645\n------------------------\n[BEST TEST] AVG QWK: 0.643, {epoch}: 30\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.66\n[BEST TEST] prompt_adherence QWK: 0.614\n[BEST TEST] language QWK: 0.559\n[BEST TEST] narrativity QWK: 0.645\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011785822920501232 || Val Loss:  0.011434781365096569\nEpoch 31/50\nTraining one epoch in 220.000 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 31\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.703\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.696\n[DEV] sentence_fluency QWK: 0.667\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.688\n[DEV] language QWK: 0.673\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.645\n[TEST] score QWK: 0.739\n[TEST] content QWK: 0.661\n[TEST] prompt_adherence QWK: 0.615\n[TEST] language QWK: 0.561\n[TEST] narrativity QWK: 0.646\n------------------------\n[BEST TEST] AVG QWK: 0.645, {epoch}: 31\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.661\n[BEST TEST] prompt_adherence QWK: 0.615\n[BEST TEST] language QWK: 0.561\n[BEST TEST] narrativity QWK: 0.646\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011776014231145382 || Val Loss:  0.011425948701798916\nEpoch 32/50\nTraining one epoch in 220.819 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 32\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.703\n[DEV] organization QWK: 0.73\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.667\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.673\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.645\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.661\n[TEST] prompt_adherence QWK: 0.615\n[TEST] language QWK: 0.561\n[TEST] narrativity QWK: 0.647\n------------------------\n[BEST TEST] AVG QWK: 0.645, {epoch}: 32\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.661\n[BEST TEST] prompt_adherence QWK: 0.615\n[BEST TEST] language QWK: 0.561\n[BEST TEST] narrativity QWK: 0.647\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011766796000301838 || Val Loss:  0.011417629197239876\nEpoch 33/50\nTraining one epoch in 262.597 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 33\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.771\n[DEV] content QWK: 0.704\n[DEV] organization QWK: 0.73\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.668\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.674\n[DEV] narrativity QWK: 0.691\n------------------------\n[TEST] AVG QWK: 0.645\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.66\n[TEST] prompt_adherence QWK: 0.614\n[TEST] language QWK: 0.562\n[TEST] narrativity QWK: 0.647\n------------------------\n[BEST TEST] AVG QWK: 0.645, {epoch}: 33\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.66\n[BEST TEST] prompt_adherence QWK: 0.614\n[BEST TEST] language QWK: 0.562\n[BEST TEST] narrativity QWK: 0.647\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011758089065551758 || Val Loss:  0.011409789323806763\nEpoch 34/50\nTraining one epoch in 222.087 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 34\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.771\n[DEV] content QWK: 0.704\n[DEV] organization QWK: 0.73\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.669\n[DEV] conventions QWK: 0.731\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.674\n[DEV] narrativity QWK: 0.691\n------------------------\n[TEST] AVG QWK: 0.646\n[TEST] score QWK: 0.741\n[TEST] content QWK: 0.661\n[TEST] prompt_adherence QWK: 0.615\n[TEST] language QWK: 0.564\n[TEST] narrativity QWK: 0.648\n------------------------\n[BEST TEST] AVG QWK: 0.646, {epoch}: 34\n[BEST TEST] score QWK: 0.741\n[BEST TEST] content QWK: 0.661\n[BEST TEST] prompt_adherence QWK: 0.615\n[BEST TEST] language QWK: 0.564\n[BEST TEST] narrativity QWK: 0.648\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01174988504499197 || Val Loss:  0.011402381584048271\nEpoch 35/50\nTraining one epoch in 220.127 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 35\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.771\n[DEV] content QWK: 0.704\n[DEV] organization QWK: 0.73\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.669\n[DEV] conventions QWK: 0.731\n[DEV] prompt_adherence QWK: 0.69\n[DEV] language QWK: 0.674\n[DEV] narrativity QWK: 0.692\n------------------------\n[TEST] AVG QWK: 0.646\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.659\n[TEST] prompt_adherence QWK: 0.615\n[TEST] language QWK: 0.564\n[TEST] narrativity QWK: 0.648\n------------------------\n[BEST TEST] AVG QWK: 0.646, {epoch}: 35\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.659\n[BEST TEST] prompt_adherence QWK: 0.615\n[BEST TEST] language QWK: 0.564\n[BEST TEST] narrativity QWK: 0.648\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011742117814719677 || Val Loss:  0.01139538362622261\nEpoch 36/50\nTraining one epoch in 218.959 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 36\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.771\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.731\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.67\n[DEV] conventions QWK: 0.732\n[DEV] prompt_adherence QWK: 0.69\n[DEV] language QWK: 0.675\n[DEV] narrativity QWK: 0.692\n------------------------\n[TEST] AVG QWK: 0.647\n[TEST] score QWK: 0.741\n[TEST] content QWK: 0.661\n[TEST] prompt_adherence QWK: 0.616\n[TEST] language QWK: 0.567\n[TEST] narrativity QWK: 0.648\n------------------------\n[BEST TEST] AVG QWK: 0.647, {epoch}: 36\n[BEST TEST] score QWK: 0.741\n[BEST TEST] content QWK: 0.661\n[BEST TEST] prompt_adherence QWK: 0.616\n[BEST TEST] language QWK: 0.567\n[BEST TEST] narrativity QWK: 0.648\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011734751053154469 || Val Loss:  0.011388757266104221\nEpoch 37/50\nTraining one epoch in 221.113 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 37\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.731\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.67\n[DEV] conventions QWK: 0.732\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.675\n[DEV] narrativity QWK: 0.692\n------------------------\n[TEST] AVG QWK: 0.647\n[TEST] score QWK: 0.741\n[TEST] content QWK: 0.662\n[TEST] prompt_adherence QWK: 0.617\n[TEST] language QWK: 0.567\n[TEST] narrativity QWK: 0.65\n------------------------\n[BEST TEST] AVG QWK: 0.647, {epoch}: 37\n[BEST TEST] score QWK: 0.741\n[BEST TEST] content QWK: 0.662\n[BEST TEST] prompt_adherence QWK: 0.617\n[BEST TEST] language QWK: 0.567\n[BEST TEST] narrativity QWK: 0.65\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01172777358442545 || Val Loss:  0.011382480151951313\nEpoch 38/50\nTraining one epoch in 220.529 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 38\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.731\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.671\n[DEV] conventions QWK: 0.732\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.675\n[DEV] narrativity QWK: 0.692\n------------------------\n[TEST] AVG QWK: 0.648\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.663\n[TEST] prompt_adherence QWK: 0.618\n[TEST] language QWK: 0.569\n[TEST] narrativity QWK: 0.651\n------------------------\n[BEST TEST] AVG QWK: 0.648, {epoch}: 38\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.663\n[BEST TEST] prompt_adherence QWK: 0.618\n[BEST TEST] language QWK: 0.569\n[BEST TEST] narrativity QWK: 0.651\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011721142567694187 || Val Loss:  0.011376524344086647\nEpoch 39/50\nTraining one epoch in 219.493 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 39\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.671\n[DEV] conventions QWK: 0.733\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.675\n[DEV] narrativity QWK: 0.693\n------------------------\n[TEST] AVG QWK: 0.648\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.663\n[TEST] prompt_adherence QWK: 0.619\n[TEST] language QWK: 0.569\n[TEST] narrativity QWK: 0.651\n------------------------\n[BEST TEST] AVG QWK: 0.648, {epoch}: 39\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.663\n[BEST TEST] prompt_adherence QWK: 0.619\n[BEST TEST] language QWK: 0.569\n[BEST TEST] narrativity QWK: 0.651\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011714858934283257 || Val Loss:  0.011370868422091007\nEpoch 40/50\nTraining one epoch in 218.792 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 40\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.671\n[DEV] conventions QWK: 0.733\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.675\n[DEV] narrativity QWK: 0.693\n------------------------\n[TEST] AVG QWK: 0.648\n[TEST] score QWK: 0.739\n[TEST] content QWK: 0.662\n[TEST] prompt_adherence QWK: 0.618\n[TEST] language QWK: 0.568\n[TEST] narrativity QWK: 0.652\n------------------------\n[BEST TEST] AVG QWK: 0.648, {epoch}: 40\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.662\n[BEST TEST] prompt_adherence QWK: 0.618\n[BEST TEST] language QWK: 0.568\n[BEST TEST] narrativity QWK: 0.652\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011708867736160755 || Val Loss:  0.011365492828190327\nEpoch 41/50\nTraining one epoch in 219.360 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 41\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.733\n[DEV] prompt_adherence QWK: 0.692\n[DEV] language QWK: 0.676\n[DEV] narrativity QWK: 0.693\n------------------------\n[TEST] AVG QWK: 0.649\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.663\n[TEST] prompt_adherence QWK: 0.619\n[TEST] language QWK: 0.571\n[TEST] narrativity QWK: 0.651\n------------------------\n[BEST TEST] AVG QWK: 0.649, {epoch}: 41\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.663\n[BEST TEST] prompt_adherence QWK: 0.619\n[BEST TEST] language QWK: 0.571\n[BEST TEST] narrativity QWK: 0.651\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01170316245406866 || Val Loss:  0.01136038452386856\nEpoch 42/50\nTraining one epoch in 218.973 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 42\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.671\n[DEV] conventions QWK: 0.733\n[DEV] prompt_adherence QWK: 0.692\n[DEV] language QWK: 0.676\n[DEV] narrativity QWK: 0.694\n------------------------\n[TEST] AVG QWK: 0.649\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.664\n[TEST] prompt_adherence QWK: 0.62\n[TEST] language QWK: 0.572\n[TEST] narrativity QWK: 0.651\n------------------------\n[BEST TEST] AVG QWK: 0.649, {epoch}: 42\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.664\n[BEST TEST] prompt_adherence QWK: 0.62\n[BEST TEST] language QWK: 0.572\n[BEST TEST] narrativity QWK: 0.651\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011697703041136265 || Val Loss:  0.011355514638125896\nEpoch 43/50\nTraining one epoch in 219.206 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 43\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.706\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.699\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.733\n[DEV] prompt_adherence QWK: 0.693\n[DEV] language QWK: 0.677\n[DEV] narrativity QWK: 0.694\n------------------------\n[TEST] AVG QWK: 0.65\n[TEST] score QWK: 0.741\n[TEST] content QWK: 0.664\n[TEST] prompt_adherence QWK: 0.621\n[TEST] language QWK: 0.573\n[TEST] narrativity QWK: 0.652\n------------------------\n[BEST TEST] AVG QWK: 0.65, {epoch}: 43\n[BEST TEST] score QWK: 0.741\n[BEST TEST] content QWK: 0.664\n[BEST TEST] prompt_adherence QWK: 0.621\n[BEST TEST] language QWK: 0.573\n[BEST TEST] narrativity QWK: 0.652\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011692498810589314 || Val Loss:  0.011350885033607483\nEpoch 44/50\nTraining one epoch in 218.814 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 44\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.706\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.699\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.733\n[DEV] prompt_adherence QWK: 0.693\n[DEV] language QWK: 0.676\n[DEV] narrativity QWK: 0.694\n------------------------\n[TEST] AVG QWK: 0.65\n[TEST] score QWK: 0.739\n[TEST] content QWK: 0.663\n[TEST] prompt_adherence QWK: 0.621\n[TEST] language QWK: 0.574\n[TEST] narrativity QWK: 0.653\n------------------------\n[BEST TEST] AVG QWK: 0.65, {epoch}: 44\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.663\n[BEST TEST] prompt_adherence QWK: 0.621\n[BEST TEST] language QWK: 0.574\n[BEST TEST] narrativity QWK: 0.653\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01168754231184721 || Val Loss:  0.011346466839313507\nEpoch 45/50\nTraining one epoch in 219.463 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 45\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.706\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.699\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.733\n[DEV] prompt_adherence QWK: 0.693\n[DEV] language QWK: 0.676\n[DEV] narrativity QWK: 0.694\n------------------------\n[TEST] AVG QWK: 0.651\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.664\n[TEST] prompt_adherence QWK: 0.621\n[TEST] language QWK: 0.575\n[TEST] narrativity QWK: 0.653\n------------------------\n[BEST TEST] AVG QWK: 0.651, {epoch}: 45\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.664\n[BEST TEST] prompt_adherence QWK: 0.621\n[BEST TEST] language QWK: 0.575\n[BEST TEST] narrativity QWK: 0.653\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011682785116136074 || Val Loss:  0.011342247016727924\nEpoch 46/50\nTraining one epoch in 218.540 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 46\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.706\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.699\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.734\n[DEV] prompt_adherence QWK: 0.693\n[DEV] language QWK: 0.677\n[DEV] narrativity QWK: 0.695\n------------------------\n[TEST] AVG QWK: 0.651\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.664\n[TEST] prompt_adherence QWK: 0.623\n[TEST] language QWK: 0.575\n[TEST] narrativity QWK: 0.653\n------------------------\n[BEST TEST] AVG QWK: 0.651, {epoch}: 46\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.664\n[BEST TEST] prompt_adherence QWK: 0.623\n[BEST TEST] language QWK: 0.575\n[BEST TEST] narrativity QWK: 0.653\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011678236536681652 || Val Loss:  0.01133822463452816\nEpoch 47/50\nTraining one epoch in 219.165 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 47\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.706\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.7\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.734\n[DEV] prompt_adherence QWK: 0.694\n[DEV] language QWK: 0.677\n[DEV] narrativity QWK: 0.695\n------------------------\n[TEST] AVG QWK: 0.651\n[TEST] score QWK: 0.739\n[TEST] content QWK: 0.664\n[TEST] prompt_adherence QWK: 0.624\n[TEST] language QWK: 0.576\n[TEST] narrativity QWK: 0.653\n------------------------\n[BEST TEST] AVG QWK: 0.651, {epoch}: 47\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.664\n[BEST TEST] prompt_adherence QWK: 0.624\n[BEST TEST] language QWK: 0.576\n[BEST TEST] narrativity QWK: 0.653\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011673878878355026 || Val Loss:  0.011334379203617573\nEpoch 48/50\nTraining one epoch in 219.195 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 48\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.707\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.7\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.734\n[DEV] prompt_adherence QWK: 0.694\n[DEV] language QWK: 0.677\n[DEV] narrativity QWK: 0.696\n------------------------\n[TEST] AVG QWK: 0.652\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.664\n[TEST] prompt_adherence QWK: 0.624\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.654\n------------------------\n[BEST TEST] AVG QWK: 0.652, {epoch}: 48\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.664\n[BEST TEST] prompt_adherence QWK: 0.624\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.654\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.0116697046905756 || Val Loss:  0.011330700479447842\nEpoch 49/50\nTraining one epoch in 219.146 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 49\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.707\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.7\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.734\n[DEV] prompt_adherence QWK: 0.694\n[DEV] language QWK: 0.678\n[DEV] narrativity QWK: 0.696\n------------------------\n[TEST] AVG QWK: 0.652\n[TEST] score QWK: 0.739\n[TEST] content QWK: 0.664\n[TEST] prompt_adherence QWK: 0.625\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.656\n------------------------\n[BEST TEST] AVG QWK: 0.652, {epoch}: 49\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.664\n[BEST TEST] prompt_adherence QWK: 0.625\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.656\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011665704660117626 || Val Loss:  0.011327190324664116\nEpoch 50/50\nTraining one epoch in 219.087 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step\nCURRENT EPOCH: 50\n[DEV] AVG QWK: 0.71\n[DEV] score QWK: 0.772\n[DEV] content QWK: 0.707\n[DEV] organization QWK: 0.733\n[DEV] word_choice QWK: 0.7\n[DEV] sentence_fluency QWK: 0.673\n[DEV] conventions QWK: 0.734\n[DEV] prompt_adherence QWK: 0.694\n[DEV] language QWK: 0.678\n[DEV] narrativity QWK: 0.696\n------------------------\n[TEST] AVG QWK: 0.652\n[TEST] score QWK: 0.739\n[TEST] content QWK: 0.664\n[TEST] prompt_adherence QWK: 0.626\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.656\n------------------------\n[BEST TEST] AVG QWK: 0.652, {epoch}: 50\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.664\n[BEST TEST] prompt_adherence QWK: 0.626\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.656\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011661861091852188 || Val Loss:  0.011323830112814903\n[BEST TEST] AVG QWK: 0.652, {epoch}: 50\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.664\n[BEST TEST] prompt_adherence QWK: 0.626\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.656\n--------------------------------------------------------------------------------------------------------------------------\nModel saved as 'trained_model/protact_model_prompt_5_seed_22.h5'\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}