{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-30T07:33:01.259890Z","iopub.execute_input":"2024-10-30T07:33:01.260641Z","iopub.status.idle":"2024-10-30T07:33:02.323286Z","shell.execute_reply.started":"2024-10-30T07:33:01.260598Z","shell.execute_reply":"2024-10-30T07:33:02.322391Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install gdown","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:33:02.325272Z","iopub.execute_input":"2024-10-30T07:33:02.325769Z","iopub.status.idle":"2024-10-30T07:33:15.642868Z","shell.execute_reply.started":"2024-10-30T07:33:02.325724Z","shell.execute_reply":"2024-10-30T07:33:15.641910Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting gdown\n  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from gdown) (3.15.1)\nRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.10/site-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from gdown) (4.66.4)\nRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->gdown) (2.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]->gdown) (1.7.1)\nDownloading gdown-5.2.0-py3-none-any.whl (18 kB)\nInstalling collected packages: gdown\nSuccessfully installed gdown-5.2.0\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/ishreya09/ProTACT.git","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:33:15.644381Z","iopub.execute_input":"2024-10-30T07:33:15.644782Z","iopub.status.idle":"2024-10-30T07:33:24.544387Z","shell.execute_reply.started":"2024-10-30T07:33:15.644734Z","shell.execute_reply":"2024-10-30T07:33:24.543378Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Cloning into 'ProTACT'...\nremote: Enumerating objects: 318, done.\u001b[K\nremote: Counting objects: 100% (7/7), done.\u001b[K\nremote: Compressing objects: 100% (7/7), done.\u001b[K\nremote: Total 318 (delta 0), reused 6 (delta 0), pack-reused 311 (from 1)\u001b[K\nReceiving objects: 100% (318/318), 146.60 MiB | 37.29 MiB/s, done.\nResolving deltas: 100% (173/173), done.\nUpdating files: 100% (136/136), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"!cp -r /kaggle/working/ProTACT/* /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:33:24.546911Z","iopub.execute_input":"2024-10-30T07:33:24.547278Z","iopub.status.idle":"2024-10-30T07:33:26.064208Z","shell.execute_reply.started":"2024-10-30T07:33:24.547239Z","shell.execute_reply":"2024-10-30T07:33:26.063141Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!mkdir trained_model","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:33:26.065588Z","iopub.execute_input":"2024-10-30T07:33:26.065912Z","iopub.status.idle":"2024-10-30T07:33:27.072178Z","shell.execute_reply.started":"2024-10-30T07:33:26.065878Z","shell.execute_reply":"2024-10-30T07:33:27.071223Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory 'trained_model': File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"import gdown\nimport os\n\n# Create directory if it doesn't exist\nos.makedirs('embeddings', exist_ok=True)\n\n# https://drive.google.com/file/d/1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ/view?usp=sharing\n\n# Google Drive file ID\nfile_id = \"1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ\"\n\n# Download file to the specified directory\ngdown.download(f\"https://drive.google.com/uc?id={file_id}\", 'embeddings/glove.6B.50d.txt', quiet=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:33:27.073550Z","iopub.execute_input":"2024-10-30T07:33:27.073855Z","iopub.status.idle":"2024-10-30T07:33:32.133309Z","shell.execute_reply.started":"2024-10-30T07:33:27.073821Z","shell.execute_reply":"2024-10-30T07:33:32.132308Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Downloading...\nFrom (original): https://drive.google.com/uc?id=1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ\nFrom (redirected): https://drive.google.com/uc?id=1qUImUtKmpspJCxAQY2OYD5DFlvvZA4IZ&confirm=t&uuid=b4f9a92c-e30c-497b-9afd-70af5a5b81d3\nTo: /kaggle/working/embeddings/glove.6B.50d.txt\n100%|██████████| 171M/171M [00:01<00:00, 150MB/s]  \n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"'embeddings/glove.6B.50d.txt'"},"metadata":{}}]},{"cell_type":"code","source":"!bash /kaggle/working/train_prompt5_seed32.sh ","metadata":{"execution":{"iopub.status.busy":"2024-10-30T07:33:32.134621Z","iopub.execute_input":"2024-10-30T07:33:32.135082Z","iopub.status.idle":"2024-10-30T11:06:53.826913Z","shell.execute_reply.started":"2024-10-30T07:33:32.135046Z","shell.execute_reply":"2024-10-30T11:06:53.825956Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Test prompt id is 5 of type <class 'int'>\nSeed: 32\nNumhead :  2  | Features :  data/LDA/hand_crafted_final_5.csv  | Pos_emb :  50\n prompt_pos size: 8\n prompt_words size: 8\n pos_x size: 9494\n readability_x size: 9494\n pos_x size: 1677\n readability_x size: 1677\n pos_x size: 1805\n readability_x size: 1805\nLoading GloVe ...\nOOV number =188, OOV ratio = 0.047012\nmax sent length: 50\nmax sent num: 97\nmax prompt sent length: 18\nmax prompt sent num: 8\n================================\nX_train_pos:  (9494, 4850)\nX_train_prompt_words:  (9494, 4850)\nX_train_prompt_pos:  (9494, 4850)\nX_train_readability:  (9494, 35)\nX_train_ling:  (9494, 52)\nX_train_attribute_rel:  (9494, 9)\nY_train:  (9494, 9)\n================================\nX_dev_pos:  (1677, 4850)\nX_dev_prompt_words:  (1677, 4850)\nX_dev_prompt_pos:  (1677, 4850)\nX_dev_readability:  (1677, 35)\nX_dev_ling:  (1677, 52)\nX_dev_attribute_rel:  (1677, 9)\nY_dev:  (1677, 9)\n================================\nX_test_pos:  (1805, 4850)\nX_test_prompt_words:  (1805, 4850)\nX_test_prompt_pos:  (1805, 4850)\nX_test_readability:  (1805, 35)\nX_test_ling:  (1805, 52)\nX_test_attribute_rel:  (1805, 9)\nY_test:  (1805, 9)\n================================\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n\u001b[1mModel: \"functional_1\"\u001b[0m\n┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n│ prompt_word_input   │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_input    │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_input           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt (\u001b[94mEmbedding\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │    \u001b[32m200,000\u001b[0m │ prompt_word_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_1         │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ prompt_word_inpu… │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_prompt          │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │      \u001b[32m1,850\u001b[0m │ prompt_pos_input… │\n│ (\u001b[94mEmbedding\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal_2         │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ prompt_pos_input… │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x (\u001b[94mEmbedding\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │      \u001b[32m1,850\u001b[0m │ pos_input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ not_equal           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m)      │          \u001b[32m0\u001b[0m │ pos_input[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n│ (\u001b[94mNotEqual\u001b[0m)          │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_maskedout    │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ prompt[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],     │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_pos_maskedo… │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_prompt[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_x_maskedout     │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_x[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],      │\n│ (\u001b[94mZeroMaskedEntries\u001b[0m) │                   │            │ not_equal[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ add (\u001b[94mAdd\u001b[0m)           │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ prompt_maskedout… │\n│                     │                   │            │ prompt_pos_maske… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_drop_x          │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ pos_x_maskedout[\u001b[32m…\u001b[0m │\n│ (\u001b[94mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_drop_x       │ (\u001b[96mNone\u001b[0m, \u001b[32m4850\u001b[0m, \u001b[32m50\u001b[0m)  │          \u001b[32m0\u001b[0m │ add[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]         │\n│ (\u001b[94mDropout\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_resh_W          │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m50\u001b[0m,    │          \u001b[32m0\u001b[0m │ pos_drop_x[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]  │\n│ (\u001b[94mReshape\u001b[0m)           │ \u001b[32m50\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_resh_W       │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m50\u001b[0m,    │          \u001b[32m0\u001b[0m │ prompt_drop_x[\u001b[32m0\u001b[0m]… │\n│ (\u001b[94mReshape\u001b[0m)           │ \u001b[32m50\u001b[0m)               │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_zcnn            │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m46\u001b[0m,    │     \u001b[32m25,100\u001b[0m │ pos_resh_W[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]  │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │ \u001b[32m100\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_zcnn         │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m46\u001b[0m,    │     \u001b[32m25,100\u001b[0m │ prompt_resh_W[\u001b[32m0\u001b[0m]… │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │ \u001b[32m100\u001b[0m)              │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ pos_avg_zcnn        │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m100\u001b[0m)   │          \u001b[32m0\u001b[0m │ pos_zcnn[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ prompt_avg_zcnn     │ (\u001b[96mNone\u001b[0m, \u001b[32m97\u001b[0m, \u001b[32m100\u001b[0m)   │          \u001b[32m0\u001b[0m │ prompt_zcnn[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m] │\n│ (\u001b[94mTimeDistributed\u001b[0m)   │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ prompt_avg_zcnn[\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ pos_avg_zcnn[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm (\u001b[94mLSTM\u001b[0m)         │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_9 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_1 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_2 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_3 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_4 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_5 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_6 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_7 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_8 (\u001b[94mLSTM\u001b[0m)       │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_1         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]        │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_11        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_2         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_3         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_4         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_5         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_6         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_7         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_8         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_9         │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ multi_head_attenti… │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m40,400\u001b[0m │ attention_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│ (\u001b[94mMultiHeadAttentio…\u001b[0m │                   │            │ attention_11[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_10 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_11 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_12 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_13 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_14 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_15 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_16 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_17 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lstm_18 (\u001b[94mLSTM\u001b[0m)      │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m) │     \u001b[32m80,400\u001b[0m │ multi_head_atten… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_12        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_10[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ linguistic_input    │ (\u001b[96mNone\u001b[0m, \u001b[32m52\u001b[0m)        │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ readability_input   │ (\u001b[96mNone\u001b[0m, \u001b[32m35\u001b[0m)        │          \u001b[32m0\u001b[0m │ -                 │\n│ (\u001b[94mInputLayer\u001b[0m)        │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_13        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_11[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_14        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_12[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_15        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_13[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_16        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_14[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_17        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_15[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_18        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_16[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_19        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_17[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_20        │ (\u001b[96mNone\u001b[0m, \u001b[32m100\u001b[0m)       │          \u001b[32m0\u001b[0m │ lstm_18[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate         │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_12[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_1       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_13[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_2       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_14[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_3       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_15[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_4       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_16[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_5       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_17[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_6       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_18[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_7       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_19[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_8       │ (\u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m)       │          \u001b[32m0\u001b[0m │ attention_20[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ linguistic_input… │\n│                     │                   │            │ readability_inpu… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda (\u001b[94mLambda\u001b[0m)     │ (\u001b[96mNone\u001b[0m, \u001b[32m9\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ concatenate[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m… │\n│                     │                   │            │ concatenate_1[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_2[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_3[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_4[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_5[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_6[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_7[\u001b[32m0\u001b[0m]… │\n│                     │                   │            │ concatenate_8[\u001b[32m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item (\u001b[94mGetItem\u001b[0m)  │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_1 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_1          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_2 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_2          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_3 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_3          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_4 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_4          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_5 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_5          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_6 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_6          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_7 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_7          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_8 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ get_item_8          │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n│ (\u001b[94mGetItem\u001b[0m)           │                   │            │                   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ lambda_9 (\u001b[94mLambda\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[96mNone\u001b[0m, \u001b[32m187\u001b[0m) │          \u001b[32m0\u001b[0m │ lambda[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]      │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_21        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_22        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_23        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_24        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_25        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_26        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_27        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_28        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ attention_29        │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m187\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mAttention\u001b[0m)         │                   │            │ lambda_9[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_9       │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_21[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_10      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_22[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_11      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_23[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_12      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_24[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_13      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_25[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_14      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_26[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_15      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_27[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_16      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_28[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_17      │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m, \u001b[32m374\u001b[0m)    │          \u001b[32m0\u001b[0m │ get_item_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m], │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ attention_29[\u001b[32m0\u001b[0m][\u001b[32m…\u001b[0m │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten (\u001b[94mFlatten\u001b[0m)   │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_9[\u001b[32m0\u001b[0m]… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_1 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_10[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_2 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_11[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_3 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_12[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_4 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_13[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_5 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_14[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_6 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_15[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_7 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_16[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ flatten_8 (\u001b[94mFlatten\u001b[0m) │ (\u001b[96mNone\u001b[0m, \u001b[32m374\u001b[0m)       │          \u001b[32m0\u001b[0m │ concatenate_17[\u001b[32m0\u001b[0m… │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_76 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]     │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_77 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_1[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_78 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_2[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_79 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_3[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_80 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_4[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_81 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_5[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_82 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_6[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_83 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_7[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ dense_84 (\u001b[94mDense\u001b[0m)    │ (\u001b[96mNone\u001b[0m, \u001b[32m1\u001b[0m)         │        \u001b[32m375\u001b[0m │ flatten_8[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]   │\n├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n│ concatenate_18      │ (\u001b[96mNone\u001b[0m, \u001b[32m9\u001b[0m)         │          \u001b[32m0\u001b[0m │ dense_76[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│ (\u001b[94mConcatenate\u001b[0m)       │                   │            │ dense_77[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_78[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_79[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_80[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_81[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_82[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_83[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m],   │\n│                     │                   │            │ dense_84[\u001b[32m0\u001b[0m][\u001b[32m0\u001b[0m]    │\n└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n\u001b[1m Total params: \u001b[0m\u001b[32m2,552,475\u001b[0m (9.74 MB)\n\u001b[1m Trainable params: \u001b[0m\u001b[32m2,552,475\u001b[0m (9.74 MB)\n\u001b[1m Non-trainable params: \u001b[0m\u001b[32m0\u001b[0m (0.00 B)\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 418ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step\nCURRENT EPOCH: -1\n[DEV] AVG QWK: 0.007\n[DEV] score QWK: -0.005\n[DEV] content QWK: 0.006\n[DEV] organization QWK: 0.077\n[DEV] word_choice QWK: -0.052\n[DEV] sentence_fluency QWK: 0.005\n[DEV] conventions QWK: 0.031\n[DEV] prompt_adherence QWK: -0.044\n[DEV] language QWK: -0.028\n[DEV] narrativity QWK: 0.075\n------------------------\n[TEST] AVG QWK: 0.053\n[TEST] score QWK: 0.058\n[TEST] content QWK: 0.033\n[TEST] prompt_adherence QWK: -0.015\n[TEST] language QWK: -0.023\n[TEST] narrativity QWK: 0.21\n------------------------\n[BEST TEST] AVG QWK: 0.053, {epoch}: -1\n[BEST TEST] score QWK: 0.058\n[BEST TEST] content QWK: 0.033\n[BEST TEST] prompt_adherence QWK: -0.015\n[BEST TEST] language QWK: -0.023\n[BEST TEST] narrativity QWK: 0.21\n--------------------------------------------------------------------------------------------------------------------------\nEpoch 1/50\ntrait num:  9\ntrait num:  9\ntrait num:  9\nTraining one epoch in 381.867 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 1\n[DEV] AVG QWK: 0.592\n[DEV] score QWK: 0.712\n[DEV] content QWK: 0.575\n[DEV] organization QWK: 0.616\n[DEV] word_choice QWK: 0.6\n[DEV] sentence_fluency QWK: 0.565\n[DEV] conventions QWK: 0.573\n[DEV] prompt_adherence QWK: 0.559\n[DEV] language QWK: 0.555\n[DEV] narrativity QWK: 0.576\n------------------------\n[TEST] AVG QWK: 0.568\n[TEST] score QWK: 0.693\n[TEST] content QWK: 0.567\n[TEST] prompt_adherence QWK: 0.503\n[TEST] language QWK: 0.487\n[TEST] narrativity QWK: 0.59\n------------------------\n[BEST TEST] AVG QWK: 0.568, {epoch}: 1\n[BEST TEST] score QWK: 0.693\n[BEST TEST] content QWK: 0.567\n[BEST TEST] prompt_adherence QWK: 0.503\n[BEST TEST] language QWK: 0.487\n[BEST TEST] narrativity QWK: 0.59\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.017278572544455528 || Val Loss:  0.014108888804912567\nEpoch 2/50\nTraining one epoch in 237.563 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 2\n[DEV] AVG QWK: 0.633\n[DEV] score QWK: 0.728\n[DEV] content QWK: 0.617\n[DEV] organization QWK: 0.661\n[DEV] word_choice QWK: 0.635\n[DEV] sentence_fluency QWK: 0.605\n[DEV] conventions QWK: 0.632\n[DEV] prompt_adherence QWK: 0.605\n[DEV] language QWK: 0.594\n[DEV] narrativity QWK: 0.617\n------------------------\n[TEST] AVG QWK: 0.584\n[TEST] score QWK: 0.712\n[TEST] content QWK: 0.596\n[TEST] prompt_adherence QWK: 0.511\n[TEST] language QWK: 0.502\n[TEST] narrativity QWK: 0.599\n------------------------\n[BEST TEST] AVG QWK: 0.584, {epoch}: 2\n[BEST TEST] score QWK: 0.712\n[BEST TEST] content QWK: 0.596\n[BEST TEST] prompt_adherence QWK: 0.511\n[BEST TEST] language QWK: 0.502\n[BEST TEST] narrativity QWK: 0.599\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.014068552292883396 || Val Loss:  0.013265137560665607\nEpoch 3/50\nTraining one epoch in 237.398 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 3\n[DEV] AVG QWK: 0.65\n[DEV] score QWK: 0.737\n[DEV] content QWK: 0.637\n[DEV] organization QWK: 0.679\n[DEV] word_choice QWK: 0.649\n[DEV] sentence_fluency QWK: 0.622\n[DEV] conventions QWK: 0.66\n[DEV] prompt_adherence QWK: 0.623\n[DEV] language QWK: 0.612\n[DEV] narrativity QWK: 0.633\n------------------------\n[TEST] AVG QWK: 0.592\n[TEST] score QWK: 0.721\n[TEST] content QWK: 0.612\n[TEST] prompt_adherence QWK: 0.527\n[TEST] language QWK: 0.501\n[TEST] narrativity QWK: 0.603\n------------------------\n[BEST TEST] AVG QWK: 0.592, {epoch}: 3\n[BEST TEST] score QWK: 0.721\n[BEST TEST] content QWK: 0.612\n[BEST TEST] prompt_adherence QWK: 0.527\n[BEST TEST] language QWK: 0.501\n[BEST TEST] narrativity QWK: 0.603\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.013438365422189236 || Val Loss:  0.0128352465108037\nEpoch 4/50\nTraining one epoch in 237.097 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 4\n[DEV] AVG QWK: 0.661\n[DEV] score QWK: 0.743\n[DEV] content QWK: 0.649\n[DEV] organization QWK: 0.689\n[DEV] word_choice QWK: 0.658\n[DEV] sentence_fluency QWK: 0.632\n[DEV] conventions QWK: 0.675\n[DEV] prompt_adherence QWK: 0.634\n[DEV] language QWK: 0.622\n[DEV] narrativity QWK: 0.643\n------------------------\n[TEST] AVG QWK: 0.598\n[TEST] score QWK: 0.727\n[TEST] content QWK: 0.617\n[TEST] prompt_adherence QWK: 0.535\n[TEST] language QWK: 0.507\n[TEST] narrativity QWK: 0.606\n------------------------\n[BEST TEST] AVG QWK: 0.598, {epoch}: 4\n[BEST TEST] score QWK: 0.727\n[BEST TEST] content QWK: 0.617\n[BEST TEST] prompt_adherence QWK: 0.535\n[BEST TEST] language QWK: 0.507\n[BEST TEST] narrativity QWK: 0.606\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.013085822574794292 || Val Loss:  0.012559323571622372\nEpoch 5/50\nTraining one epoch in 237.399 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 5\n[DEV] AVG QWK: 0.668\n[DEV] score QWK: 0.747\n[DEV] content QWK: 0.659\n[DEV] organization QWK: 0.696\n[DEV] word_choice QWK: 0.663\n[DEV] sentence_fluency QWK: 0.639\n[DEV] conventions QWK: 0.685\n[DEV] prompt_adherence QWK: 0.643\n[DEV] language QWK: 0.63\n[DEV] narrativity QWK: 0.65\n------------------------\n[TEST] AVG QWK: 0.604\n[TEST] score QWK: 0.733\n[TEST] content QWK: 0.626\n[TEST] prompt_adherence QWK: 0.547\n[TEST] language QWK: 0.51\n[TEST] narrativity QWK: 0.605\n------------------------\n[BEST TEST] AVG QWK: 0.604, {epoch}: 5\n[BEST TEST] score QWK: 0.733\n[BEST TEST] content QWK: 0.626\n[BEST TEST] prompt_adherence QWK: 0.547\n[BEST TEST] language QWK: 0.51\n[BEST TEST] narrativity QWK: 0.605\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012850252911448479 || Val Loss:  0.012364575639367104\nEpoch 6/50\nTraining one epoch in 237.591 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 6\n[DEV] AVG QWK: 0.673\n[DEV] score QWK: 0.751\n[DEV] content QWK: 0.665\n[DEV] organization QWK: 0.701\n[DEV] word_choice QWK: 0.668\n[DEV] sentence_fluency QWK: 0.645\n[DEV] conventions QWK: 0.692\n[DEV] prompt_adherence QWK: 0.649\n[DEV] language QWK: 0.636\n[DEV] narrativity QWK: 0.655\n------------------------\n[TEST] AVG QWK: 0.612\n[TEST] score QWK: 0.736\n[TEST] content QWK: 0.632\n[TEST] prompt_adherence QWK: 0.558\n[TEST] language QWK: 0.523\n[TEST] narrativity QWK: 0.609\n------------------------\n[BEST TEST] AVG QWK: 0.612, {epoch}: 6\n[BEST TEST] score QWK: 0.736\n[BEST TEST] content QWK: 0.632\n[BEST TEST] prompt_adherence QWK: 0.558\n[BEST TEST] language QWK: 0.523\n[BEST TEST] narrativity QWK: 0.609\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01267875824123621 || Val Loss:  0.012219050899147987\nEpoch 7/50\nTraining one epoch in 237.240 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 7\n[DEV] AVG QWK: 0.677\n[DEV] score QWK: 0.753\n[DEV] content QWK: 0.67\n[DEV] organization QWK: 0.704\n[DEV] word_choice QWK: 0.67\n[DEV] sentence_fluency QWK: 0.65\n[DEV] conventions QWK: 0.697\n[DEV] prompt_adherence QWK: 0.653\n[DEV] language QWK: 0.641\n[DEV] narrativity QWK: 0.659\n------------------------\n[TEST] AVG QWK: 0.615\n[TEST] score QWK: 0.735\n[TEST] content QWK: 0.635\n[TEST] prompt_adherence QWK: 0.563\n[TEST] language QWK: 0.529\n[TEST] narrativity QWK: 0.612\n------------------------\n[BEST TEST] AVG QWK: 0.615, {epoch}: 7\n[BEST TEST] score QWK: 0.735\n[BEST TEST] content QWK: 0.635\n[BEST TEST] prompt_adherence QWK: 0.563\n[BEST TEST] language QWK: 0.529\n[BEST TEST] narrativity QWK: 0.612\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01254711952060461 || Val Loss:  0.012105878442525864\nEpoch 8/50\nTraining one epoch in 236.645 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 8\n[DEV] AVG QWK: 0.681\n[DEV] score QWK: 0.756\n[DEV] content QWK: 0.674\n[DEV] organization QWK: 0.707\n[DEV] word_choice QWK: 0.674\n[DEV] sentence_fluency QWK: 0.652\n[DEV] conventions QWK: 0.701\n[DEV] prompt_adherence QWK: 0.657\n[DEV] language QWK: 0.644\n[DEV] narrativity QWK: 0.663\n------------------------\n[TEST] AVG QWK: 0.619\n[TEST] score QWK: 0.735\n[TEST] content QWK: 0.634\n[TEST] prompt_adherence QWK: 0.572\n[TEST] language QWK: 0.532\n[TEST] narrativity QWK: 0.62\n------------------------\n[BEST TEST] AVG QWK: 0.619, {epoch}: 8\n[BEST TEST] score QWK: 0.735\n[BEST TEST] content QWK: 0.634\n[BEST TEST] prompt_adherence QWK: 0.572\n[BEST TEST] language QWK: 0.532\n[BEST TEST] narrativity QWK: 0.62\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01244228146970272 || Val Loss:  0.01201516855508089\nEpoch 9/50\nTraining one epoch in 236.852 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 9\n[DEV] AVG QWK: 0.684\n[DEV] score QWK: 0.757\n[DEV] content QWK: 0.678\n[DEV] organization QWK: 0.711\n[DEV] word_choice QWK: 0.675\n[DEV] sentence_fluency QWK: 0.656\n[DEV] conventions QWK: 0.704\n[DEV] prompt_adherence QWK: 0.66\n[DEV] language QWK: 0.648\n[DEV] narrativity QWK: 0.666\n------------------------\n[TEST] AVG QWK: 0.623\n[TEST] score QWK: 0.732\n[TEST] content QWK: 0.638\n[TEST] prompt_adherence QWK: 0.58\n[TEST] language QWK: 0.539\n[TEST] narrativity QWK: 0.625\n------------------------\n[BEST TEST] AVG QWK: 0.623, {epoch}: 9\n[BEST TEST] score QWK: 0.732\n[BEST TEST] content QWK: 0.638\n[BEST TEST] prompt_adherence QWK: 0.58\n[BEST TEST] language QWK: 0.539\n[BEST TEST] narrativity QWK: 0.625\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012356564402580261 || Val Loss:  0.011940747499465942\nEpoch 10/50\nTraining one epoch in 236.182 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 10\n[DEV] AVG QWK: 0.686\n[DEV] score QWK: 0.758\n[DEV] content QWK: 0.68\n[DEV] organization QWK: 0.712\n[DEV] word_choice QWK: 0.678\n[DEV] sentence_fluency QWK: 0.659\n[DEV] conventions QWK: 0.706\n[DEV] prompt_adherence QWK: 0.664\n[DEV] language QWK: 0.65\n[DEV] narrativity QWK: 0.668\n------------------------\n[TEST] AVG QWK: 0.625\n[TEST] score QWK: 0.732\n[TEST] content QWK: 0.64\n[TEST] prompt_adherence QWK: 0.585\n[TEST] language QWK: 0.542\n[TEST] narrativity QWK: 0.628\n------------------------\n[BEST TEST] AVG QWK: 0.625, {epoch}: 10\n[BEST TEST] score QWK: 0.732\n[BEST TEST] content QWK: 0.64\n[BEST TEST] prompt_adherence QWK: 0.585\n[BEST TEST] language QWK: 0.542\n[BEST TEST] narrativity QWK: 0.628\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012285001575946808 || Val Loss:  0.011878502555191517\nEpoch 11/50\nTraining one epoch in 236.312 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 11\n[DEV] AVG QWK: 0.688\n[DEV] score QWK: 0.76\n[DEV] content QWK: 0.683\n[DEV] organization QWK: 0.715\n[DEV] word_choice QWK: 0.679\n[DEV] sentence_fluency QWK: 0.66\n[DEV] conventions QWK: 0.709\n[DEV] prompt_adherence QWK: 0.666\n[DEV] language QWK: 0.652\n[DEV] narrativity QWK: 0.669\n------------------------\n[TEST] AVG QWK: 0.628\n[TEST] score QWK: 0.732\n[TEST] content QWK: 0.642\n[TEST] prompt_adherence QWK: 0.59\n[TEST] language QWK: 0.544\n[TEST] narrativity QWK: 0.632\n------------------------\n[BEST TEST] AVG QWK: 0.628, {epoch}: 11\n[BEST TEST] score QWK: 0.732\n[BEST TEST] content QWK: 0.642\n[BEST TEST] prompt_adherence QWK: 0.59\n[BEST TEST] language QWK: 0.544\n[BEST TEST] narrativity QWK: 0.632\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012224321253597736 || Val Loss:  0.011825628578662872\nEpoch 12/50\nTraining one epoch in 236.516 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 12\n[DEV] AVG QWK: 0.69\n[DEV] score QWK: 0.761\n[DEV] content QWK: 0.685\n[DEV] organization QWK: 0.716\n[DEV] word_choice QWK: 0.681\n[DEV] sentence_fluency QWK: 0.662\n[DEV] conventions QWK: 0.711\n[DEV] prompt_adherence QWK: 0.669\n[DEV] language QWK: 0.654\n[DEV] narrativity QWK: 0.671\n------------------------\n[TEST] AVG QWK: 0.63\n[TEST] score QWK: 0.735\n[TEST] content QWK: 0.642\n[TEST] prompt_adherence QWK: 0.595\n[TEST] language QWK: 0.548\n[TEST] narrativity QWK: 0.633\n------------------------\n[BEST TEST] AVG QWK: 0.63, {epoch}: 12\n[BEST TEST] score QWK: 0.735\n[BEST TEST] content QWK: 0.642\n[BEST TEST] prompt_adherence QWK: 0.595\n[BEST TEST] language QWK: 0.548\n[BEST TEST] narrativity QWK: 0.633\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012172194197773933 || Val Loss:  0.011780119501054287\nEpoch 13/50\nTraining one epoch in 236.242 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 13\n[DEV] AVG QWK: 0.692\n[DEV] score QWK: 0.762\n[DEV] content QWK: 0.687\n[DEV] organization QWK: 0.717\n[DEV] word_choice QWK: 0.684\n[DEV] sentence_fluency QWK: 0.664\n[DEV] conventions QWK: 0.713\n[DEV] prompt_adherence QWK: 0.67\n[DEV] language QWK: 0.655\n[DEV] narrativity QWK: 0.673\n------------------------\n[TEST] AVG QWK: 0.632\n[TEST] score QWK: 0.735\n[TEST] content QWK: 0.641\n[TEST] prompt_adherence QWK: 0.599\n[TEST] language QWK: 0.55\n[TEST] narrativity QWK: 0.634\n------------------------\n[BEST TEST] AVG QWK: 0.632, {epoch}: 13\n[BEST TEST] score QWK: 0.735\n[BEST TEST] content QWK: 0.641\n[BEST TEST] prompt_adherence QWK: 0.599\n[BEST TEST] language QWK: 0.55\n[BEST TEST] narrativity QWK: 0.634\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012126925401389599 || Val Loss:  0.011740505695343018\nEpoch 14/50\nTraining one epoch in 236.413 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 14\n[DEV] AVG QWK: 0.693\n[DEV] score QWK: 0.763\n[DEV] content QWK: 0.688\n[DEV] organization QWK: 0.719\n[DEV] word_choice QWK: 0.684\n[DEV] sentence_fluency QWK: 0.665\n[DEV] conventions QWK: 0.714\n[DEV] prompt_adherence QWK: 0.672\n[DEV] language QWK: 0.657\n[DEV] narrativity QWK: 0.674\n------------------------\n[TEST] AVG QWK: 0.634\n[TEST] score QWK: 0.735\n[TEST] content QWK: 0.642\n[TEST] prompt_adherence QWK: 0.601\n[TEST] language QWK: 0.554\n[TEST] narrativity QWK: 0.637\n------------------------\n[BEST TEST] AVG QWK: 0.634, {epoch}: 14\n[BEST TEST] score QWK: 0.735\n[BEST TEST] content QWK: 0.642\n[BEST TEST] prompt_adherence QWK: 0.601\n[BEST TEST] language QWK: 0.554\n[BEST TEST] narrativity QWK: 0.637\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012087256647646427 || Val Loss:  0.011705697514116764\nEpoch 15/50\nTraining one epoch in 236.579 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 15\n[DEV] AVG QWK: 0.694\n[DEV] score QWK: 0.764\n[DEV] content QWK: 0.689\n[DEV] organization QWK: 0.72\n[DEV] word_choice QWK: 0.684\n[DEV] sentence_fluency QWK: 0.666\n[DEV] conventions QWK: 0.716\n[DEV] prompt_adherence QWK: 0.674\n[DEV] language QWK: 0.658\n[DEV] narrativity QWK: 0.676\n------------------------\n[TEST] AVG QWK: 0.636\n[TEST] score QWK: 0.736\n[TEST] content QWK: 0.647\n[TEST] prompt_adherence QWK: 0.605\n[TEST] language QWK: 0.554\n[TEST] narrativity QWK: 0.638\n------------------------\n[BEST TEST] AVG QWK: 0.636, {epoch}: 15\n[BEST TEST] score QWK: 0.736\n[BEST TEST] content QWK: 0.647\n[BEST TEST] prompt_adherence QWK: 0.605\n[BEST TEST] language QWK: 0.554\n[BEST TEST] narrativity QWK: 0.638\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012052223086357117 || Val Loss:  0.01167484000325203\nEpoch 16/50\nTraining one epoch in 236.174 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 16\n[DEV] AVG QWK: 0.695\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.691\n[DEV] organization QWK: 0.721\n[DEV] word_choice QWK: 0.686\n[DEV] sentence_fluency QWK: 0.668\n[DEV] conventions QWK: 0.716\n[DEV] prompt_adherence QWK: 0.675\n[DEV] language QWK: 0.659\n[DEV] narrativity QWK: 0.677\n------------------------\n[TEST] AVG QWK: 0.638\n[TEST] score QWK: 0.736\n[TEST] content QWK: 0.649\n[TEST] prompt_adherence QWK: 0.607\n[TEST] language QWK: 0.559\n[TEST] narrativity QWK: 0.641\n------------------------\n[BEST TEST] AVG QWK: 0.638, {epoch}: 16\n[BEST TEST] score QWK: 0.736\n[BEST TEST] content QWK: 0.649\n[BEST TEST] prompt_adherence QWK: 0.607\n[BEST TEST] language QWK: 0.559\n[BEST TEST] narrativity QWK: 0.641\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.012021055445075035 || Val Loss:  0.011647297069430351\nEpoch 17/50\nTraining one epoch in 236.010 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 17\n[DEV] AVG QWK: 0.696\n[DEV] score QWK: 0.765\n[DEV] content QWK: 0.692\n[DEV] organization QWK: 0.722\n[DEV] word_choice QWK: 0.687\n[DEV] sentence_fluency QWK: 0.669\n[DEV] conventions QWK: 0.718\n[DEV] prompt_adherence QWK: 0.676\n[DEV] language QWK: 0.66\n[DEV] narrativity QWK: 0.678\n------------------------\n[TEST] AVG QWK: 0.641\n[TEST] score QWK: 0.737\n[TEST] content QWK: 0.651\n[TEST] prompt_adherence QWK: 0.611\n[TEST] language QWK: 0.561\n[TEST] narrativity QWK: 0.646\n------------------------\n[BEST TEST] AVG QWK: 0.641, {epoch}: 17\n[BEST TEST] score QWK: 0.737\n[BEST TEST] content QWK: 0.651\n[BEST TEST] prompt_adherence QWK: 0.611\n[BEST TEST] language QWK: 0.561\n[BEST TEST] narrativity QWK: 0.646\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011993175372481346 || Val Loss:  0.011622537858784199\nEpoch 18/50\nTraining one epoch in 235.683 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 18\n[DEV] AVG QWK: 0.697\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.693\n[DEV] organization QWK: 0.723\n[DEV] word_choice QWK: 0.688\n[DEV] sentence_fluency QWK: 0.671\n[DEV] conventions QWK: 0.718\n[DEV] prompt_adherence QWK: 0.677\n[DEV] language QWK: 0.662\n[DEV] narrativity QWK: 0.679\n------------------------\n[TEST] AVG QWK: 0.642\n[TEST] score QWK: 0.739\n[TEST] content QWK: 0.652\n[TEST] prompt_adherence QWK: 0.612\n[TEST] language QWK: 0.559\n[TEST] narrativity QWK: 0.648\n------------------------\n[BEST TEST] AVG QWK: 0.642, {epoch}: 18\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.652\n[BEST TEST] prompt_adherence QWK: 0.612\n[BEST TEST] language QWK: 0.559\n[BEST TEST] narrativity QWK: 0.648\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01196807250380516 || Val Loss:  0.011600159108638763\nEpoch 19/50\nTraining one epoch in 235.962 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 19\n[DEV] AVG QWK: 0.698\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.694\n[DEV] organization QWK: 0.724\n[DEV] word_choice QWK: 0.689\n[DEV] sentence_fluency QWK: 0.672\n[DEV] conventions QWK: 0.719\n[DEV] prompt_adherence QWK: 0.678\n[DEV] language QWK: 0.662\n[DEV] narrativity QWK: 0.68\n------------------------\n[TEST] AVG QWK: 0.643\n[TEST] score QWK: 0.737\n[TEST] content QWK: 0.652\n[TEST] prompt_adherence QWK: 0.615\n[TEST] language QWK: 0.562\n[TEST] narrativity QWK: 0.648\n------------------------\n[BEST TEST] AVG QWK: 0.643, {epoch}: 19\n[BEST TEST] score QWK: 0.737\n[BEST TEST] content QWK: 0.652\n[BEST TEST] prompt_adherence QWK: 0.615\n[BEST TEST] language QWK: 0.562\n[BEST TEST] narrativity QWK: 0.648\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011945372447371483 || Val Loss:  0.011579809710383415\nEpoch 20/50\nTraining one epoch in 235.630 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 20\n[DEV] AVG QWK: 0.699\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.695\n[DEV] organization QWK: 0.724\n[DEV] word_choice QWK: 0.69\n[DEV] sentence_fluency QWK: 0.673\n[DEV] conventions QWK: 0.72\n[DEV] prompt_adherence QWK: 0.679\n[DEV] language QWK: 0.663\n[DEV] narrativity QWK: 0.681\n------------------------\n[TEST] AVG QWK: 0.645\n[TEST] score QWK: 0.739\n[TEST] content QWK: 0.652\n[TEST] prompt_adherence QWK: 0.616\n[TEST] language QWK: 0.565\n[TEST] narrativity QWK: 0.65\n------------------------\n[BEST TEST] AVG QWK: 0.645, {epoch}: 20\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.652\n[BEST TEST] prompt_adherence QWK: 0.616\n[BEST TEST] language QWK: 0.565\n[BEST TEST] narrativity QWK: 0.65\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01192475389689207 || Val Loss:  0.011561237275600433\nEpoch 21/50\nTraining one epoch in 235.729 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 21\n[DEV] AVG QWK: 0.7\n[DEV] score QWK: 0.766\n[DEV] content QWK: 0.696\n[DEV] organization QWK: 0.725\n[DEV] word_choice QWK: 0.691\n[DEV] sentence_fluency QWK: 0.674\n[DEV] conventions QWK: 0.721\n[DEV] prompt_adherence QWK: 0.68\n[DEV] language QWK: 0.664\n[DEV] narrativity QWK: 0.682\n------------------------\n[TEST] AVG QWK: 0.645\n[TEST] score QWK: 0.739\n[TEST] content QWK: 0.653\n[TEST] prompt_adherence QWK: 0.617\n[TEST] language QWK: 0.566\n[TEST] narrativity QWK: 0.651\n------------------------\n[BEST TEST] AVG QWK: 0.645, {epoch}: 21\n[BEST TEST] score QWK: 0.739\n[BEST TEST] content QWK: 0.653\n[BEST TEST] prompt_adherence QWK: 0.617\n[BEST TEST] language QWK: 0.566\n[BEST TEST] narrativity QWK: 0.651\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01190592534840107 || Val Loss:  0.011544202454388142\nEpoch 22/50\nTraining one epoch in 235.618 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 22\n[DEV] AVG QWK: 0.7\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.696\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.691\n[DEV] sentence_fluency QWK: 0.674\n[DEV] conventions QWK: 0.721\n[DEV] prompt_adherence QWK: 0.681\n[DEV] language QWK: 0.664\n[DEV] narrativity QWK: 0.682\n------------------------\n[TEST] AVG QWK: 0.646\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.655\n[TEST] prompt_adherence QWK: 0.617\n[TEST] language QWK: 0.567\n[TEST] narrativity QWK: 0.652\n------------------------\n[BEST TEST] AVG QWK: 0.646, {epoch}: 22\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.655\n[BEST TEST] prompt_adherence QWK: 0.617\n[BEST TEST] language QWK: 0.567\n[BEST TEST] narrativity QWK: 0.652\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011888687498867512 || Val Loss:  0.011528512462973595\nEpoch 23/50\nTraining one epoch in 235.644 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 23\n[DEV] AVG QWK: 0.701\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.697\n[DEV] organization QWK: 0.726\n[DEV] word_choice QWK: 0.691\n[DEV] sentence_fluency QWK: 0.675\n[DEV] conventions QWK: 0.722\n[DEV] prompt_adherence QWK: 0.682\n[DEV] language QWK: 0.665\n[DEV] narrativity QWK: 0.683\n------------------------\n[TEST] AVG QWK: 0.646\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.655\n[TEST] prompt_adherence QWK: 0.616\n[TEST] language QWK: 0.569\n[TEST] narrativity QWK: 0.652\n------------------------\n[BEST TEST] AVG QWK: 0.646, {epoch}: 23\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.655\n[BEST TEST] prompt_adherence QWK: 0.616\n[BEST TEST] language QWK: 0.569\n[BEST TEST] narrativity QWK: 0.652\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011872845701873302 || Val Loss:  0.011514011770486832\nEpoch 24/50\nTraining one epoch in 235.764 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 24\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.767\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.692\n[DEV] sentence_fluency QWK: 0.676\n[DEV] conventions QWK: 0.723\n[DEV] prompt_adherence QWK: 0.682\n[DEV] language QWK: 0.666\n[DEV] narrativity QWK: 0.684\n------------------------\n[TEST] AVG QWK: 0.647\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.655\n[TEST] prompt_adherence QWK: 0.617\n[TEST] language QWK: 0.569\n[TEST] narrativity QWK: 0.653\n------------------------\n[BEST TEST] AVG QWK: 0.647, {epoch}: 24\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.655\n[BEST TEST] prompt_adherence QWK: 0.617\n[BEST TEST] language QWK: 0.569\n[BEST TEST] narrativity QWK: 0.653\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01185822207480669 || Val Loss:  0.011500569991767406\nEpoch 25/50\nTraining one epoch in 235.583 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 25\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.698\n[DEV] organization QWK: 0.727\n[DEV] word_choice QWK: 0.692\n[DEV] sentence_fluency QWK: 0.676\n[DEV] conventions QWK: 0.723\n[DEV] prompt_adherence QWK: 0.683\n[DEV] language QWK: 0.666\n[DEV] narrativity QWK: 0.684\n------------------------\n[TEST] AVG QWK: 0.648\n[TEST] score QWK: 0.741\n[TEST] content QWK: 0.657\n[TEST] prompt_adherence QWK: 0.617\n[TEST] language QWK: 0.57\n[TEST] narrativity QWK: 0.653\n------------------------\n[BEST TEST] AVG QWK: 0.648, {epoch}: 25\n[BEST TEST] score QWK: 0.741\n[BEST TEST] content QWK: 0.657\n[BEST TEST] prompt_adherence QWK: 0.617\n[BEST TEST] language QWK: 0.57\n[BEST TEST] narrativity QWK: 0.653\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01184470858424902 || Val Loss:  0.011488072574138641\nEpoch 26/50\nTraining one epoch in 235.207 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 26\n[DEV] AVG QWK: 0.702\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.693\n[DEV] sentence_fluency QWK: 0.676\n[DEV] conventions QWK: 0.724\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.667\n[DEV] narrativity QWK: 0.685\n------------------------\n[TEST] AVG QWK: 0.648\n[TEST] score QWK: 0.741\n[TEST] content QWK: 0.658\n[TEST] prompt_adherence QWK: 0.619\n[TEST] language QWK: 0.571\n[TEST] narrativity QWK: 0.652\n------------------------\n[BEST TEST] AVG QWK: 0.648, {epoch}: 26\n[BEST TEST] score QWK: 0.741\n[BEST TEST] content QWK: 0.658\n[BEST TEST] prompt_adherence QWK: 0.619\n[BEST TEST] language QWK: 0.571\n[BEST TEST] narrativity QWK: 0.652\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011832158081233501 || Val Loss:  0.011476409621536732\nEpoch 27/50\nTraining one epoch in 235.619 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 27\n[DEV] AVG QWK: 0.703\n[DEV] score QWK: 0.768\n[DEV] content QWK: 0.699\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.677\n[DEV] conventions QWK: 0.725\n[DEV] prompt_adherence QWK: 0.684\n[DEV] language QWK: 0.667\n[DEV] narrativity QWK: 0.685\n------------------------\n[TEST] AVG QWK: 0.648\n[TEST] score QWK: 0.741\n[TEST] content QWK: 0.657\n[TEST] prompt_adherence QWK: 0.619\n[TEST] language QWK: 0.572\n[TEST] narrativity QWK: 0.652\n------------------------\n[BEST TEST] AVG QWK: 0.648, {epoch}: 27\n[BEST TEST] score QWK: 0.741\n[BEST TEST] content QWK: 0.657\n[BEST TEST] prompt_adherence QWK: 0.619\n[BEST TEST] language QWK: 0.572\n[BEST TEST] narrativity QWK: 0.652\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011820475570857525 || Val Loss:  0.011465498246252537\nEpoch 28/50\nTraining one epoch in 235.800 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 28\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.7\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.694\n[DEV] sentence_fluency QWK: 0.678\n[DEV] conventions QWK: 0.725\n[DEV] prompt_adherence QWK: 0.685\n[DEV] language QWK: 0.668\n[DEV] narrativity QWK: 0.686\n------------------------\n[TEST] AVG QWK: 0.649\n[TEST] score QWK: 0.741\n[TEST] content QWK: 0.657\n[TEST] prompt_adherence QWK: 0.621\n[TEST] language QWK: 0.574\n[TEST] narrativity QWK: 0.653\n------------------------\n[BEST TEST] AVG QWK: 0.649, {epoch}: 28\n[BEST TEST] score QWK: 0.741\n[BEST TEST] content QWK: 0.657\n[BEST TEST] prompt_adherence QWK: 0.621\n[BEST TEST] language QWK: 0.574\n[BEST TEST] narrativity QWK: 0.653\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011809584684669971 || Val Loss:  0.011455276980996132\nEpoch 29/50\nTraining one epoch in 235.586 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 29\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.7\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.695\n[DEV] sentence_fluency QWK: 0.679\n[DEV] conventions QWK: 0.725\n[DEV] prompt_adherence QWK: 0.686\n[DEV] language QWK: 0.668\n[DEV] narrativity QWK: 0.686\n------------------------\n[TEST] AVG QWK: 0.65\n[TEST] score QWK: 0.74\n[TEST] content QWK: 0.658\n[TEST] prompt_adherence QWK: 0.624\n[TEST] language QWK: 0.574\n[TEST] narrativity QWK: 0.652\n------------------------\n[BEST TEST] AVG QWK: 0.65, {epoch}: 29\n[BEST TEST] score QWK: 0.74\n[BEST TEST] content QWK: 0.658\n[BEST TEST] prompt_adherence QWK: 0.624\n[BEST TEST] language QWK: 0.574\n[BEST TEST] narrativity QWK: 0.652\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011799401603639126 || Val Loss:  0.011445678770542145\nEpoch 30/50\nTraining one epoch in 235.605 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 30\n[DEV] AVG QWK: 0.704\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.728\n[DEV] word_choice QWK: 0.695\n[DEV] sentence_fluency QWK: 0.679\n[DEV] conventions QWK: 0.725\n[DEV] prompt_adherence QWK: 0.686\n[DEV] language QWK: 0.668\n[DEV] narrativity QWK: 0.687\n------------------------\n[TEST] AVG QWK: 0.65\n[TEST] score QWK: 0.741\n[TEST] content QWK: 0.659\n[TEST] prompt_adherence QWK: 0.626\n[TEST] language QWK: 0.573\n[TEST] narrativity QWK: 0.653\n------------------------\n[BEST TEST] AVG QWK: 0.65, {epoch}: 30\n[BEST TEST] score QWK: 0.741\n[BEST TEST] content QWK: 0.659\n[BEST TEST] prompt_adherence QWK: 0.626\n[BEST TEST] language QWK: 0.573\n[BEST TEST] narrativity QWK: 0.653\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011789841577410698 || Val Loss:  0.01143663376569748\nEpoch 31/50\nTraining one epoch in 235.578 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 31\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.695\n[DEV] sentence_fluency QWK: 0.679\n[DEV] conventions QWK: 0.725\n[DEV] prompt_adherence QWK: 0.687\n[DEV] language QWK: 0.669\n[DEV] narrativity QWK: 0.687\n------------------------\n[TEST] AVG QWK: 0.652\n[TEST] score QWK: 0.741\n[TEST] content QWK: 0.659\n[TEST] prompt_adherence QWK: 0.629\n[TEST] language QWK: 0.575\n[TEST] narrativity QWK: 0.654\n------------------------\n[BEST TEST] AVG QWK: 0.652, {epoch}: 31\n[BEST TEST] score QWK: 0.741\n[BEST TEST] content QWK: 0.659\n[BEST TEST] prompt_adherence QWK: 0.629\n[BEST TEST] language QWK: 0.575\n[BEST TEST] narrativity QWK: 0.654\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011780889704823494 || Val Loss:  0.011428109370172024\nEpoch 32/50\nTraining one epoch in 235.393 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 32\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.701\n[DEV] organization QWK: 0.729\n[DEV] word_choice QWK: 0.695\n[DEV] sentence_fluency QWK: 0.681\n[DEV] conventions QWK: 0.725\n[DEV] prompt_adherence QWK: 0.686\n[DEV] language QWK: 0.669\n[DEV] narrativity QWK: 0.687\n------------------------\n[TEST] AVG QWK: 0.652\n[TEST] score QWK: 0.741\n[TEST] content QWK: 0.66\n[TEST] prompt_adherence QWK: 0.629\n[TEST] language QWK: 0.576\n[TEST] narrativity QWK: 0.655\n------------------------\n[BEST TEST] AVG QWK: 0.652, {epoch}: 32\n[BEST TEST] score QWK: 0.741\n[BEST TEST] content QWK: 0.66\n[BEST TEST] prompt_adherence QWK: 0.629\n[BEST TEST] language QWK: 0.576\n[BEST TEST] narrativity QWK: 0.655\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011772463098168373 || Val Loss:  0.0114200534299016\nEpoch 33/50\nTraining one epoch in 235.357 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 33\n[DEV] AVG QWK: 0.705\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.73\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.682\n[DEV] conventions QWK: 0.726\n[DEV] prompt_adherence QWK: 0.687\n[DEV] language QWK: 0.67\n[DEV] narrativity QWK: 0.688\n------------------------\n[TEST] AVG QWK: 0.653\n[TEST] score QWK: 0.742\n[TEST] content QWK: 0.659\n[TEST] prompt_adherence QWK: 0.63\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.654\n------------------------\n[BEST TEST] AVG QWK: 0.653, {epoch}: 33\n[BEST TEST] score QWK: 0.742\n[BEST TEST] content QWK: 0.659\n[BEST TEST] prompt_adherence QWK: 0.63\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.654\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01176450029015541 || Val Loss:  0.011412427760660648\nEpoch 34/50\nTraining one epoch in 235.640 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 34\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.769\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.73\n[DEV] word_choice QWK: 0.697\n[DEV] sentence_fluency QWK: 0.682\n[DEV] conventions QWK: 0.727\n[DEV] prompt_adherence QWK: 0.687\n[DEV] language QWK: 0.67\n[DEV] narrativity QWK: 0.688\n------------------------\n[TEST] AVG QWK: 0.653\n[TEST] score QWK: 0.743\n[TEST] content QWK: 0.658\n[TEST] prompt_adherence QWK: 0.633\n[TEST] language QWK: 0.577\n[TEST] narrativity QWK: 0.655\n------------------------\n[BEST TEST] AVG QWK: 0.653, {epoch}: 34\n[BEST TEST] score QWK: 0.743\n[BEST TEST] content QWK: 0.658\n[BEST TEST] prompt_adherence QWK: 0.633\n[BEST TEST] language QWK: 0.577\n[BEST TEST] narrativity QWK: 0.655\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011756997555494308 || Val Loss:  0.011405202560126781\nEpoch 35/50\nTraining one epoch in 235.241 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 35\n[DEV] AVG QWK: 0.706\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.73\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.683\n[DEV] conventions QWK: 0.727\n[DEV] prompt_adherence QWK: 0.687\n[DEV] language QWK: 0.67\n[DEV] narrativity QWK: 0.689\n------------------------\n[TEST] AVG QWK: 0.654\n[TEST] score QWK: 0.743\n[TEST] content QWK: 0.659\n[TEST] prompt_adherence QWK: 0.635\n[TEST] language QWK: 0.578\n[TEST] narrativity QWK: 0.656\n------------------------\n[BEST TEST] AVG QWK: 0.654, {epoch}: 35\n[BEST TEST] score QWK: 0.743\n[BEST TEST] content QWK: 0.659\n[BEST TEST] prompt_adherence QWK: 0.635\n[BEST TEST] language QWK: 0.578\n[BEST TEST] narrativity QWK: 0.656\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011749903671443462 || Val Loss:  0.011398342438042164\nEpoch 36/50\nTraining one epoch in 235.273 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 36\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.702\n[DEV] organization QWK: 0.73\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.683\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.688\n[DEV] language QWK: 0.671\n[DEV] narrativity QWK: 0.689\n------------------------\n[TEST] AVG QWK: 0.655\n[TEST] score QWK: 0.745\n[TEST] content QWK: 0.659\n[TEST] prompt_adherence QWK: 0.636\n[TEST] language QWK: 0.578\n[TEST] narrativity QWK: 0.656\n------------------------\n[BEST TEST] AVG QWK: 0.655, {epoch}: 36\n[BEST TEST] score QWK: 0.745\n[BEST TEST] content QWK: 0.659\n[BEST TEST] prompt_adherence QWK: 0.636\n[BEST TEST] language QWK: 0.578\n[BEST TEST] narrativity QWK: 0.656\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011743173934519291 || Val Loss:  0.011391831561923027\nEpoch 37/50\nTraining one epoch in 235.501 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 37\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.703\n[DEV] organization QWK: 0.731\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.683\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.671\n[DEV] narrativity QWK: 0.689\n------------------------\n[TEST] AVG QWK: 0.656\n[TEST] score QWK: 0.745\n[TEST] content QWK: 0.661\n[TEST] prompt_adherence QWK: 0.636\n[TEST] language QWK: 0.58\n[TEST] narrativity QWK: 0.657\n------------------------\n[BEST TEST] AVG QWK: 0.656, {epoch}: 37\n[BEST TEST] score QWK: 0.745\n[BEST TEST] content QWK: 0.661\n[BEST TEST] prompt_adherence QWK: 0.636\n[BEST TEST] language QWK: 0.58\n[BEST TEST] narrativity QWK: 0.657\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011736792512238026 || Val Loss:  0.011385630816221237\nEpoch 38/50\nTraining one epoch in 235.389 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 38\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.703\n[DEV] organization QWK: 0.731\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.683\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.671\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.656\n[TEST] score QWK: 0.746\n[TEST] content QWK: 0.662\n[TEST] prompt_adherence QWK: 0.636\n[TEST] language QWK: 0.581\n[TEST] narrativity QWK: 0.657\n------------------------\n[BEST TEST] AVG QWK: 0.656, {epoch}: 38\n[BEST TEST] score QWK: 0.746\n[BEST TEST] content QWK: 0.662\n[BEST TEST] prompt_adherence QWK: 0.636\n[BEST TEST] language QWK: 0.581\n[BEST TEST] narrativity QWK: 0.657\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01173072587698698 || Val Loss:  0.01137972716242075\nEpoch 39/50\nTraining one epoch in 235.562 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 39\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.703\n[DEV] organization QWK: 0.731\n[DEV] word_choice QWK: 0.698\n[DEV] sentence_fluency QWK: 0.684\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.671\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.657\n[TEST] score QWK: 0.746\n[TEST] content QWK: 0.661\n[TEST] prompt_adherence QWK: 0.635\n[TEST] language QWK: 0.583\n[TEST] narrativity QWK: 0.657\n------------------------\n[BEST TEST] AVG QWK: 0.657, {epoch}: 39\n[BEST TEST] score QWK: 0.746\n[BEST TEST] content QWK: 0.661\n[BEST TEST] prompt_adherence QWK: 0.635\n[BEST TEST] language QWK: 0.583\n[BEST TEST] narrativity QWK: 0.657\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011724979616701603 || Val Loss:  0.011374088935554028\nEpoch 40/50\nTraining one epoch in 235.726 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 40\n[DEV] AVG QWK: 0.707\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.704\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.699\n[DEV] sentence_fluency QWK: 0.684\n[DEV] conventions QWK: 0.728\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.671\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.657\n[TEST] score QWK: 0.746\n[TEST] content QWK: 0.661\n[TEST] prompt_adherence QWK: 0.637\n[TEST] language QWK: 0.584\n[TEST] narrativity QWK: 0.657\n------------------------\n[BEST TEST] AVG QWK: 0.657, {epoch}: 40\n[BEST TEST] score QWK: 0.746\n[BEST TEST] content QWK: 0.661\n[BEST TEST] prompt_adherence QWK: 0.637\n[BEST TEST] language QWK: 0.584\n[BEST TEST] narrativity QWK: 0.657\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01171949040144682 || Val Loss:  0.011368714272975922\nEpoch 41/50\nTraining one epoch in 235.937 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 41\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.704\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.699\n[DEV] sentence_fluency QWK: 0.685\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.689\n[DEV] language QWK: 0.672\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.657\n[TEST] score QWK: 0.746\n[TEST] content QWK: 0.661\n[TEST] prompt_adherence QWK: 0.637\n[TEST] language QWK: 0.585\n[TEST] narrativity QWK: 0.657\n------------------------\n[BEST TEST] AVG QWK: 0.657, {epoch}: 41\n[BEST TEST] score QWK: 0.746\n[BEST TEST] content QWK: 0.661\n[BEST TEST] prompt_adherence QWK: 0.637\n[BEST TEST] language QWK: 0.585\n[BEST TEST] narrativity QWK: 0.657\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011714262887835503 || Val Loss:  0.011363578028976917\nEpoch 42/50\nTraining one epoch in 235.718 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 42\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.704\n[DEV] organization QWK: 0.732\n[DEV] word_choice QWK: 0.699\n[DEV] sentence_fluency QWK: 0.685\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.69\n[DEV] language QWK: 0.672\n[DEV] narrativity QWK: 0.69\n------------------------\n[TEST] AVG QWK: 0.657\n[TEST] score QWK: 0.746\n[TEST] content QWK: 0.662\n[TEST] prompt_adherence QWK: 0.636\n[TEST] language QWK: 0.586\n[TEST] narrativity QWK: 0.657\n------------------------\n[BEST TEST] AVG QWK: 0.657, {epoch}: 42\n[BEST TEST] score QWK: 0.746\n[BEST TEST] content QWK: 0.662\n[BEST TEST] prompt_adherence QWK: 0.636\n[BEST TEST] language QWK: 0.586\n[BEST TEST] narrativity QWK: 0.657\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011709269136190414 || Val Loss:  0.01135866716504097\nEpoch 43/50\nTraining one epoch in 235.310 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 43\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.77\n[DEV] content QWK: 0.704\n[DEV] organization QWK: 0.733\n[DEV] word_choice QWK: 0.699\n[DEV] sentence_fluency QWK: 0.685\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.69\n[DEV] language QWK: 0.673\n[DEV] narrativity QWK: 0.691\n------------------------\n[TEST] AVG QWK: 0.658\n[TEST] score QWK: 0.746\n[TEST] content QWK: 0.662\n[TEST] prompt_adherence QWK: 0.636\n[TEST] language QWK: 0.587\n[TEST] narrativity QWK: 0.658\n------------------------\n[BEST TEST] AVG QWK: 0.658, {epoch}: 43\n[BEST TEST] score QWK: 0.746\n[BEST TEST] content QWK: 0.662\n[BEST TEST] prompt_adherence QWK: 0.636\n[BEST TEST] language QWK: 0.587\n[BEST TEST] narrativity QWK: 0.658\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011704509146511555 || Val Loss:  0.011353963054716587\nEpoch 44/50\nTraining one epoch in 235.360 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 44\n[DEV] AVG QWK: 0.708\n[DEV] score QWK: 0.771\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.733\n[DEV] word_choice QWK: 0.699\n[DEV] sentence_fluency QWK: 0.686\n[DEV] conventions QWK: 0.729\n[DEV] prompt_adherence QWK: 0.69\n[DEV] language QWK: 0.672\n[DEV] narrativity QWK: 0.691\n------------------------\n[TEST] AVG QWK: 0.658\n[TEST] score QWK: 0.747\n[TEST] content QWK: 0.662\n[TEST] prompt_adherence QWK: 0.638\n[TEST] language QWK: 0.587\n[TEST] narrativity QWK: 0.658\n------------------------\n[BEST TEST] AVG QWK: 0.658, {epoch}: 44\n[BEST TEST] score QWK: 0.747\n[BEST TEST] content QWK: 0.662\n[BEST TEST] prompt_adherence QWK: 0.638\n[BEST TEST] language QWK: 0.587\n[BEST TEST] narrativity QWK: 0.658\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011699962429702282 || Val Loss:  0.011349461041390896\nEpoch 45/50\nTraining one epoch in 235.295 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 45\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.771\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.733\n[DEV] word_choice QWK: 0.699\n[DEV] sentence_fluency QWK: 0.686\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.673\n[DEV] narrativity QWK: 0.691\n------------------------\n[TEST] AVG QWK: 0.659\n[TEST] score QWK: 0.747\n[TEST] content QWK: 0.662\n[TEST] prompt_adherence QWK: 0.638\n[TEST] language QWK: 0.588\n[TEST] narrativity QWK: 0.659\n------------------------\n[BEST TEST] AVG QWK: 0.659, {epoch}: 45\n[BEST TEST] score QWK: 0.747\n[BEST TEST] content QWK: 0.662\n[BEST TEST] prompt_adherence QWK: 0.638\n[BEST TEST] language QWK: 0.588\n[BEST TEST] narrativity QWK: 0.659\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011695584282279015 || Val Loss:  0.011345148086547852\nEpoch 46/50\nTraining one epoch in 235.622 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 46\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.771\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.733\n[DEV] word_choice QWK: 0.699\n[DEV] sentence_fluency QWK: 0.686\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.691\n[DEV] language QWK: 0.673\n[DEV] narrativity QWK: 0.691\n------------------------\n[TEST] AVG QWK: 0.659\n[TEST] score QWK: 0.748\n[TEST] content QWK: 0.662\n[TEST] prompt_adherence QWK: 0.64\n[TEST] language QWK: 0.588\n[TEST] narrativity QWK: 0.658\n------------------------\n[BEST TEST] AVG QWK: 0.659, {epoch}: 46\n[BEST TEST] score QWK: 0.748\n[BEST TEST] content QWK: 0.662\n[BEST TEST] prompt_adherence QWK: 0.64\n[BEST TEST] language QWK: 0.588\n[BEST TEST] narrativity QWK: 0.658\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011691414751112461 || Val Loss:  0.011341002769768238\nEpoch 47/50\nTraining one epoch in 235.281 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 47\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.771\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.734\n[DEV] word_choice QWK: 0.699\n[DEV] sentence_fluency QWK: 0.686\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.692\n[DEV] language QWK: 0.673\n[DEV] narrativity QWK: 0.691\n------------------------\n[TEST] AVG QWK: 0.66\n[TEST] score QWK: 0.748\n[TEST] content QWK: 0.662\n[TEST] prompt_adherence QWK: 0.639\n[TEST] language QWK: 0.591\n[TEST] narrativity QWK: 0.658\n------------------------\n[BEST TEST] AVG QWK: 0.66, {epoch}: 47\n[BEST TEST] score QWK: 0.748\n[BEST TEST] content QWK: 0.662\n[BEST TEST] prompt_adherence QWK: 0.639\n[BEST TEST] language QWK: 0.591\n[BEST TEST] narrativity QWK: 0.658\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01168740913271904 || Val Loss:  0.011337039060890675\nEpoch 48/50\nTraining one epoch in 235.232 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 48\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.771\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.733\n[DEV] word_choice QWK: 0.7\n[DEV] sentence_fluency QWK: 0.686\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.692\n[DEV] language QWK: 0.673\n[DEV] narrativity QWK: 0.692\n------------------------\n[TEST] AVG QWK: 0.66\n[TEST] score QWK: 0.748\n[TEST] content QWK: 0.664\n[TEST] prompt_adherence QWK: 0.64\n[TEST] language QWK: 0.591\n[TEST] narrativity QWK: 0.658\n------------------------\n[BEST TEST] AVG QWK: 0.66, {epoch}: 48\n[BEST TEST] score QWK: 0.748\n[BEST TEST] content QWK: 0.664\n[BEST TEST] prompt_adherence QWK: 0.64\n[BEST TEST] language QWK: 0.591\n[BEST TEST] narrativity QWK: 0.658\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.01168358139693737 || Val Loss:  0.0113332225009799\nEpoch 49/50\nTraining one epoch in 235.464 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 49\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.771\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.734\n[DEV] word_choice QWK: 0.7\n[DEV] sentence_fluency QWK: 0.687\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.692\n[DEV] language QWK: 0.673\n[DEV] narrativity QWK: 0.692\n------------------------\n[TEST] AVG QWK: 0.66\n[TEST] score QWK: 0.748\n[TEST] content QWK: 0.665\n[TEST] prompt_adherence QWK: 0.641\n[TEST] language QWK: 0.591\n[TEST] narrativity QWK: 0.658\n------------------------\n[BEST TEST] AVG QWK: 0.66, {epoch}: 49\n[BEST TEST] score QWK: 0.748\n[BEST TEST] content QWK: 0.665\n[BEST TEST] prompt_adherence QWK: 0.641\n[BEST TEST] language QWK: 0.591\n[BEST TEST] narrativity QWK: 0.658\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011679892428219318 || Val Loss:  0.011329558677971363\nEpoch 50/50\nTraining one epoch in 235.364 s\n\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\n\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step\nCURRENT EPOCH: 50\n[DEV] AVG QWK: 0.709\n[DEV] score QWK: 0.771\n[DEV] content QWK: 0.705\n[DEV] organization QWK: 0.734\n[DEV] word_choice QWK: 0.7\n[DEV] sentence_fluency QWK: 0.687\n[DEV] conventions QWK: 0.73\n[DEV] prompt_adherence QWK: 0.693\n[DEV] language QWK: 0.673\n[DEV] narrativity QWK: 0.692\n------------------------\n[TEST] AVG QWK: 0.66\n[TEST] score QWK: 0.748\n[TEST] content QWK: 0.664\n[TEST] prompt_adherence QWK: 0.641\n[TEST] language QWK: 0.59\n[TEST] narrativity QWK: 0.659\n------------------------\n[BEST TEST] AVG QWK: 0.66, {epoch}: 50\n[BEST TEST] score QWK: 0.748\n[BEST TEST] content QWK: 0.664\n[BEST TEST] prompt_adherence QWK: 0.641\n[BEST TEST] language QWK: 0.59\n[BEST TEST] narrativity QWK: 0.659\n--------------------------------------------------------------------------------------------------------------------------\nTrain Loss:  0.011676359921693802 || Val Loss:  0.011326038278639317\n[BEST TEST] AVG QWK: 0.66, {epoch}: 50\n[BEST TEST] score QWK: 0.748\n[BEST TEST] content QWK: 0.664\n[BEST TEST] prompt_adherence QWK: 0.641\n[BEST TEST] language QWK: 0.59\n[BEST TEST] narrativity QWK: 0.659\n--------------------------------------------------------------------------------------------------------------------------\nModel saved as 'trained_model/protact_model_prompt_5_seed_32.h5'\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}